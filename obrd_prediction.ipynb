{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:27:45.648198Z","iopub.status.busy":"2023-09-01T19:27:45.647261Z","iopub.status.idle":"2023-09-01T19:27:45.690264Z","shell.execute_reply":"2023-09-01T19:27:45.688729Z","shell.execute_reply.started":"2023-09-01T19:27:45.648159Z"},"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-09-02T19:02:28.700414Z","iopub.status.busy":"2023-09-02T19:02:28.699975Z","iopub.status.idle":"2023-09-02T19:02:28.708411Z","shell.execute_reply":"2023-09-02T19:02:28.706247Z","shell.execute_reply.started":"2023-09-02T19:02:28.700380Z"},"trusted":true},"outputs":[],"source":["# avoids time consuming code blocks from running; Hyperparameter tuning, Cross Validation, etc.\n","RUN_CELL = False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:37:35.482927Z","iopub.status.busy":"2023-09-01T19:37:35.482494Z","iopub.status.idle":"2023-09-01T19:40:07.747981Z","shell.execute_reply":"2023-09-01T19:40:07.746486Z","shell.execute_reply.started":"2023-09-01T19:37:35.482897Z"},"trusted":true},"outputs":[],"source":["# takes too long to run in Kaggle\n","# pip install torch_scatter\n","# pip install torch-geometric"]},{"cell_type":"markdown","metadata":{},"source":["#### Library Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:40:41.316180Z","iopub.status.busy":"2023-09-01T19:40:41.315590Z","iopub.status.idle":"2023-09-01T19:40:54.378491Z","shell.execute_reply":"2023-09-01T19:40:54.376724Z","shell.execute_reply.started":"2023-09-01T19:40:41.316125Z"},"trusted":true},"outputs":[],"source":["# Basic Libraries\n","import numpy as np\n","import pandas as pd\n","import math\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Scipy & NetworkX\n","from scipy.optimize import linear_sum_assignment\n","from scipy.spatial.distance import pdist, squareform\n","import networkx as nx\n","\n","# Torch & Torch Geometric\n","# import torch\n","# import torch.nn as nn\n","# import torch.nn.functional as F\n","# from torch.optim import Adam\n","# from torch.nn import BCEWithLogitsLoss\n","# from torch_geometric.data import Data, DataLoader, Batch\n","# from torch_geometric.nn import GCNConv, GATConv, global_mean_pool, Set2Set\n","# from torch_scatter import scatter_mean, scatter_add\n","\n","# Sklearn\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold, KFold\n","from sklearn.metrics import make_scorer, log_loss, accuracy_score, confusion_matrix, classification_report\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from boruta import BorutaPy\n","from imblearn.over_sampling import SMOTE\n","\n","# TensorFlow & Keras\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, regularizers, initializers\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# XGBoost\n","import xgboost as xgb\n","from xgboost import XGBClassifier\n","\n","# PIL for Image Handling\n","from PIL import Image"]},{"cell_type":"markdown","metadata":{},"source":["-------------------------------------------------------------------------------------------------------------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{},"source":["# **Predicting Offensive Rebounds in Basketball: A Location-Based Approach**\n","\n","Basketball is a fast-paced sport, rich in strategies and opportunities for data analysis. One critical moment that can shift the momentum of a game is the rebound after a missed shot. The ability to anticipate and secure an offensive rebound can create additional opportunities to score, making it a valuable skill on the court. The challenge presented here is to leverage the on-court location data of players to predict the probability of a team securing an offensive rebound after a shot miss.\n","\n","## Dataset Overview\n","\n","The datasets provided for this challenge come in two flavors:\n","\n","1. *Play-by-Play Data (PBP)*: This dataset captures play-level details. It records the team names, and for the training set, whether a rebound is offensive or defensive.\n","\n","2. *Location Data (Locs)*: This is the centerpiece of the challenge. For each play, it records the on-court coordinates of each player **at the moment a shot is taken**. This dataset differentiates between the shooter, the offensive players, and the defensive players.\n","\n","A critical note is that all the shots considered in both the training and test sets are misses, which are then rebounded either offensively or defensively.\n","\n","## Objective\n","\n","Given this data, the task is to predict the likelihood of an offensive rebound post a missed shot. The prediction will be based on the positions of the players at the time of the shot.\n","\n","## My Approach\n","\n","In my exploration of this problem, I have undertaken a comprehensive approach to feature engineering and model testing:\n","\n","1. <u>Distance Features</u>:           Calculated distances between key players and positions to gauge the immediate opportunity or challenge in securing a rebound.\n","\n","2. <u>Angle Features</u>:              Considered angles to understand players' relative positions to the basket.\n","\n","3. <u>Box-Out Responsibility</u>:      Paired players based on potential matchups, considering 'boxing out' in rebound scenarios.\n","\n","4. <u>Complex Feature Engineering</u>   Developed features using the results of EDA and basketball domain knowledge.\n","\n","4. <u>Hyperparameter Tuning</u>:        Tuning hyperparameters using gridsearch crossvalidation.\n","\n","5. <u>Building an Ensemble</u>:         Combining the prediction power of several diverse ML algorithms to leverage the strengths of each model.\n","\n","6. <u>Model Exploration</u>:           Beyond traditional algorithms, I experimented with Graph Neural Networks (GNNs) and Convolutional Neural Networks (CNNs) to capture the spatial relationships between players.\n","\n","As we delve into this notebook, you will witness a step-by-step breakdown of these strategies, supported by visualizations, model evaluations, and insights. By leveraging both domain knowledge and advanced data techniques, my objective is to provide an in-depth and accurate model for predicting offensive rebounds in basketball.\n","\n","Let's dive in.\n","\n","## Table of Contents\n","\n","1. **[Exploratory Data Analysis & Data Preprocessing](#Exploratory-Data-Analysis-&-Data-Preprocessing)**\n","   \n","2. **[Baseline Model](#Baseline-Model)**\n","\n","3. **[Complex Feature Engineering](#Complex-Feature-Engineering)**\n","\n","4. **[Model Experimentation](#Model-Experimentation)**\n","\n","5. **[Stacking Classifier for Model Ensembling](#Stacking-Classifier-for-Model-Ensembling)**\n","\n","6. **[Feature Selection with Baruta Algorithm](#Feature-Selection-with-Baruta-Algorithm)**\n","\n","7. **[Oversampling Offensive Rebound Examples](#Oversampling-Offensive-Rebound-Examples)**\n","\n","8. **[Convolutional Neural Network (CNN) for Spatial Analysis](#Convolutional-Neural-Network-(CNN)-for-Spatial-Analysis)**\n","\n","9. **[Graph Neural Networks (GNNs) for Spatial Analysis](#Graph-Neural-Networks-(GNNs)-for-Spatial-Analysis)**\n","\n","10. **[Conclusion](#Conclusion)**\n"]},{"cell_type":"markdown","metadata":{},"source":["-------------------------------------------------------------------------------------------------------------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{},"source":["# **Exploratory Data Analysis & Data Preprocessing**\n","\n","In this section, we strive to deeply understand our dataset and derive insights that will be critical for our modeling phase. Our data revolves around basketball play-by-play events, focusing particularly on shots that are missed and subsequently rebounded.\n","\n","#### EDA Structure:\n","\n","1. *Univariate Analysis*:\n","We'll start by examining the distribution of key variables, such as shot locations and the target variable (offensive or defensive rebound).\n","\n","2. *Bivariate Analysis*:\n","We'll then delve into relationships between variables. For instance, does the location of the shooter influence the probability of an offensive rebound? How does player positioning relate to rebound outcomes?\n","\n","3. *Feature Engineering Insights*:\n","While our main feature engineering phase comes after EDA, our initial exploration can guide us in constructing meaningful features. For instance, player distance from the basket might emerge as a potential predictor.\n","\n","4. *Missing Data and Outliers*:\n","We'll identify any missing values and decide on imputation strategies. Similarly, outliers, if any, will be flagged, and we'll determine how to handle them.\n","\n","5. *Visual Exploration*:\n","Throughout the EDA, we'll make extensive use of visual tools: scatter plots to understand player positioning, histograms for distributions, and heatmaps.\n","\n","By the end of this section, we'll have a comprehensive understanding of our data's characteristics, potential challenges, and areas of opportunity for our predictive modeling phase.\n"]},{"cell_type":"markdown","metadata":{},"source":["-------------------------------------------------------------------------------------------------------------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{},"source":["#### Examining the Available Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:42:45.521143Z","iopub.status.busy":"2023-09-01T19:42:45.520665Z","iopub.status.idle":"2023-09-01T19:42:45.935286Z","shell.execute_reply":"2023-09-01T19:42:45.933112Z","shell.execute_reply.started":"2023-09-01T19:42:45.521106Z"},"id":"BMw7hYs0brOa","trusted":true},"outputs":[],"source":["# loading in each dataset\n","train_locs = pd.read_csv('/data/train_locs.csv')\n","train_pbp = pd.read_csv('/data/train_pbp.csv')\n","test_locs = pd.read_csv('/data/test_locs.csv')\n","test_pbp = pd.read_csv('/data/test_pbp.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:42:52.469094Z","iopub.status.busy":"2023-09-01T19:42:52.468676Z","iopub.status.idle":"2023-09-01T19:42:52.479040Z","shell.execute_reply":"2023-09-01T19:42:52.476944Z","shell.execute_reply.started":"2023-09-01T19:42:52.469067Z"},"id":"0uFeFzQLbrOe","trusted":true},"outputs":[],"source":["training_data = train_locs.copy()\n","testing_data = test_locs.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:42:56.671342Z","iopub.status.busy":"2023-09-01T19:42:56.670880Z","iopub.status.idle":"2023-09-01T19:42:56.702421Z","shell.execute_reply":"2023-09-01T19:42:56.701678Z","shell.execute_reply.started":"2023-09-01T19:42:56.671307Z"},"id":"98D--8MSGKpa","outputId":"02e09761-952f-46c0-c5a6-cc27bac24cf7","trusted":true},"outputs":[],"source":["# displaying the raw data\n","training_data.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:42:59.465604Z","iopub.status.busy":"2023-09-01T19:42:59.465208Z","iopub.status.idle":"2023-09-01T19:42:59.481142Z","shell.execute_reply":"2023-09-01T19:42:59.478798Z","shell.execute_reply.started":"2023-09-01T19:42:59.465574Z"},"trusted":true},"outputs":[],"source":["train_pbp.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:42:59.876139Z","iopub.status.busy":"2023-09-01T19:42:59.875290Z","iopub.status.idle":"2023-09-01T19:42:59.891539Z","shell.execute_reply":"2023-09-01T19:42:59.889968Z","shell.execute_reply.started":"2023-09-01T19:42:59.876056Z"},"trusted":true},"outputs":[],"source":["test_pbp.head(3)"]},{"cell_type":"markdown","metadata":{},"source":["#### PBP Data Observations\n","\n","Test Set Sampling: \n","  - The test set appears randomly sampled, so the training set plays do not all occur prior to the test set plays.\n","\n","Data Leakage Concerns: \n","  - This sampling approach precludes the use of team or conference offensive rebounding percentages as features due to **data leakage concerns**.\n","\n","Model Objective: \n","  - The goal of this investigation is to provide a generalizable framework for offensive rebounding that can later be adjusted for team behavior.\n","    - To be useful in evaluating **shot quality** across a season in an unbiased manner, team tendencies cannot be part of the equation.\n","\n","Model Utility: \n","  - The model can thus be used as an anchor to evaluate team offensive rebounding performance against expectation.\n","  - Player shot selection can be evaluated fairly, making it useful for NBA scouting. Cason Wallace, for example, might otherwise be attributed an unreasonably high shot quality for a long range shot because Oscar Tshiebwe happens to be his teammate and this fact leads to a higher chance of an offensive rebound.\n","\n","Model Limitations: \n","  - A team's season long tendencies to get back on defense or attack the offensive glass would be a strong feature in predicting rebounds.\n","  - One popular approach discussed in this [KenPom article](https://theathletic.com/789794/2019/01/29/kenpom-offensive-rebounding-is-at-an-all-time-low-what-are-teams-really-missing-out-on/) is to prioritize getting back on defense after a shot because transition opportunities are incredibly efficient.\n","      - If we were to include team offensive rebounding rate, the model would capture these tendencies or the general strength of a team's rebounders.\n","      - As discussed, however, this would be poor data science practice, because it would require the use of future data points in predicting past outcomes.\n"]},{"cell_type":"markdown","metadata":{"id":"BP6XiszQDIHe"},"source":["#### Creating Binary Shooter and Offense Columns\n","- These new columns capture the important details about each player as the number in the annotation code does not indicate position or have any significance."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:01.435858Z","iopub.status.busy":"2023-09-01T19:43:01.435405Z","iopub.status.idle":"2023-09-01T19:43:01.715343Z","shell.execute_reply":"2023-09-01T19:43:01.714182Z","shell.execute_reply.started":"2023-09-01T19:43:01.435825Z"},"id":"5yaYSWvCfGFD","trusted":true},"outputs":[],"source":["# assign 1 if the player is on the offensive team and 0 if on the defensive team\n","training_data['offense'] = training_data['annotation_code'].apply(lambda x: 0 if 'd' in x else 1)\n","testing_data['offense'] = testing_data['annotation_code'].apply(lambda x: 0 if 'd' in x else 1)\n","# assign 1 if the player is the shooter (based on 'annotation_code' containing 's') and 0 otherwise.\n","training_data['shooter'] = training_data['annotation_code'].apply(lambda x: 1 if 's' in x else 0)\n","testing_data['shooter'] = testing_data['annotation_code'].apply(lambda x: 1 if 's' in x else 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:02.103206Z","iopub.status.busy":"2023-09-01T19:43:02.101726Z","iopub.status.idle":"2023-09-01T19:43:02.122819Z","shell.execute_reply":"2023-09-01T19:43:02.120431Z","shell.execute_reply.started":"2023-09-01T19:43:02.103120Z"},"id":"DWKevr81HqWv","outputId":"aab10b85-d25c-44d0-c6a6-35a5082b84df","trusted":true},"outputs":[],"source":["# ensuring the columns are added\n","training_data.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["### **Calculating Shooter's Distance from the Basket**\n","\n","#### Challenge:\n","\n","Given the dynamic nature of a basketball game, players can take shots aiming at either of the two baskets. Our dataset provides the shooter's coordinates on the court at the time of the shot. An immediate challenge arises: determining which basket the player is targeting. This information is pivotal in accurately computing the shooter's distance from the intended basket.\n","\n","#### Plan of Attack:\n","\n","1. *Baskets' Coordinates*: \n","    - Left Hoop: Located at `(4,25)`.\n","    - Right Hoop: Located at `(90,25)`.\n","    \n","    These will act as reference points for our distance calculations.\n","\n","2. *Initial Hypothesis*:\n","    Since players predominantly aim for the basket closer to them, a simple initial approach could be to calculate the distance to both baskets and assume the player is targeting the nearer one.\n","\n","3. *Team Side Information*:\n","    Since we may have access to multiple data points per game we can take samples at the beginning and end of games to verify the direction of the shot.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:02.478919Z","iopub.status.busy":"2023-09-01T19:43:02.478587Z","iopub.status.idle":"2023-09-01T19:43:02.487873Z","shell.execute_reply":"2023-09-01T19:43:02.485983Z","shell.execute_reply.started":"2023-09-01T19:43:02.478897Z"},"trusted":true},"outputs":[],"source":["# define the coordinates of the hoop\n","hoop_coordinates = np.array([[4, 25], [90, 25]])\n","\n","# calculate the distance of each shot from the basket\n","def calculate_shooter_distance_from_hoop(row):\n","    shot_coordinates = np.array([row['court_x'], row['court_y']])\n","    distance = np.linalg.norm(shot_coordinates - hoop_coordinates, axis=1)\n","    if distance[0] < distance[1]:\n","        # 0 for hoop at (4, 25)\n","        hoop = 0\n","    else:\n","        # 1 for hoop at (90, 25)\n","        hoop = 1\n","    return pd.Series([np.min(distance), hoop])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:02.663586Z","iopub.status.busy":"2023-09-01T19:43:02.663066Z","iopub.status.idle":"2023-09-01T19:43:13.696346Z","shell.execute_reply":"2023-09-01T19:43:13.693652Z","shell.execute_reply.started":"2023-09-01T19:43:02.663548Z"},"trusted":true},"outputs":[],"source":["# keeping only rows for the shooter in each play\n","shooter_data_train = training_data.loc[training_data.annotation_code == 's']\n","shooter_data_test = testing_data.loc[testing_data.annotation_code == 's']\n","# hoop at x = 4 is 0, x = 90 is 1\n","shooter_data_train[['shooter_dist_from_hoop', 'which_hoop']] = shooter_data_train.apply(calculate_shooter_distance_from_hoop, axis=1)\n","shooter_data_test[['shooter_dist_from_hoop', 'which_hoop']] = shooter_data_test.apply(calculate_shooter_distance_from_hoop, axis=1)\n","# splitting id so that we can group by game\n","shooter_data_train['game_number'] = shooter_data_train['id'].str.split('-').str[0]\n","shooter_data_train['play_number'] = shooter_data_train['id'].str.split('-').str[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:13.700337Z","iopub.status.busy":"2023-09-01T19:43:13.699818Z","iopub.status.idle":"2023-09-01T19:43:13.719817Z","shell.execute_reply":"2023-09-01T19:43:13.717977Z","shell.execute_reply.started":"2023-09-01T19:43:13.700299Z"},"trusted":true},"outputs":[],"source":["# ensuring columns are added\n","shooter_data_train.head(3)"]},{"cell_type":"markdown","metadata":{},"source":["#### Checking # of Plays per Game"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:13.722602Z","iopub.status.busy":"2023-09-01T19:43:13.721899Z","iopub.status.idle":"2023-09-01T19:43:13.781322Z","shell.execute_reply":"2023-09-01T19:43:13.779250Z","shell.execute_reply.started":"2023-09-01T19:43:13.722565Z"},"trusted":true},"outputs":[],"source":["# finding the number of plays per game\n","shooter_data_train.groupby('game_number').count().head()"]},{"cell_type":"markdown","metadata":{},"source":["#### Key Findings\n","- Given the limited play sequences in certain games (such as 1 for game 1000), finding ground truth 'which_hoop' values may be impossible.\n","- An implicit assumption is made here that the basket closest to the shot is the one being shot at. While this may generally hold true, exceptions can arise. Such instances, though infrequent, can introduce outliers.\n","    - One possible exception might be if there were a deflection near the end of the shot clock and a player successfully drew iron from behind half court after retrieving the deflection.\n","    - End of half shots will most likely not result in a rebound because time will expire, so those instances will not be in our dataset unless a player shoots too early which is very uncommon (more on this later).\n","- These anomalies might skew the analysis and should be approached with caution."]},{"cell_type":"markdown","metadata":{},"source":["#### Null Values Check"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:13.785772Z","iopub.status.busy":"2023-09-01T19:43:13.784960Z","iopub.status.idle":"2023-09-01T19:43:13.819214Z","shell.execute_reply":"2023-09-01T19:43:13.817687Z","shell.execute_reply.started":"2023-09-01T19:43:13.785738Z"},"trusted":true},"outputs":[],"source":["# quick check for null values - Complete Dataset!\n","shooter_data_train.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["## **Univariate Analysis**"]},{"cell_type":"markdown","metadata":{},"source":["#### Shot Location Frequencies (Frequency Distributions, Heatmap)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:13.822246Z","iopub.status.busy":"2023-09-01T19:43:13.821665Z","iopub.status.idle":"2023-09-01T19:43:14.797045Z","shell.execute_reply":"2023-09-01T19:43:14.796187Z","shell.execute_reply.started":"2023-09-01T19:43:13.822209Z"},"trusted":true},"outputs":[],"source":["fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n","\n","sns.histplot(shooter_data_train['court_x'], kde=True, ax=axes[0])\n","axes[0].set_title('Distribution of Shot Locations (court_x)')\n","axes[0].set_xlabel('court_x')\n","axes[0].set_ylabel('Frequency')\n","\n","sns.histplot(shooter_data_train['court_y'], kde=True, ax=axes[1])\n","axes[1].set_title('Distribution of Shot Locations (court_y)')\n","axes[1].set_xlabel('court_y')\n","axes[1].set_ylabel('Frequency')\n","\n","\n","plt.tight_layout() # Adjusts the plots so that they fit well\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:14.798814Z","iopub.status.busy":"2023-09-01T19:43:14.798355Z","iopub.status.idle":"2023-09-01T19:43:15.115843Z","shell.execute_reply":"2023-09-01T19:43:15.114275Z","shell.execute_reply.started":"2023-09-01T19:43:14.798789Z"},"trusted":true},"outputs":[],"source":["# define grid size for binning\n","grid_size = 2\n","\n","# use numpy's histogram2d to bin the data\n","hist, xedges, yedges = np.histogram2d(shooter_data_train['court_x'], shooter_data_train['court_y'], bins=(int(94/grid_size), int(50/grid_size)))\n","\n","# plot heatmap\n","plt.figure(figsize=(10, 7))\n","plt.imshow(hist.T, origin='lower', cmap='YlGnBu', extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])\n","plt.colorbar(label='Number of Shots')\n","plt.title('Heatmap of Shot Locations')\n","plt.xlabel('court_x')\n","plt.ylabel('court_y')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Distribution of Shot Locations Analysis:\n","*Trends Observed*: \n","- There are very few shots taken (and missed) from mid-court.\n","- The highest concentration of shots are near the basket.\n","- Mid-range shots are the least common shots.\n","- Interestingly, there are more shots missed on the left side of the basket up close on one side of the court.\n","    - This can be assumed not to be a trend worth investigating given what we know about basketball; the hoop that a team is shooting at will have no meaningful influence over shot selection.\n","    - This sheds light on the limitations of the size of the dataset, meaning we must be careful not to overfit the data in model experimentation."]},{"cell_type":"markdown","metadata":{},"source":["### **Frequency of Offensive vs. Defensive Rebounds**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:15.118073Z","iopub.status.busy":"2023-09-01T19:43:15.117703Z","iopub.status.idle":"2023-09-01T19:43:15.163183Z","shell.execute_reply":"2023-09-01T19:43:15.161149Z","shell.execute_reply.started":"2023-09-01T19:43:15.118047Z"},"trusted":true},"outputs":[],"source":["# merging the target variable to examing rebounding distribution\n","shooter_data_train = shooter_data_train.merge(train_pbp[['id', 'is_oreb']], on='id')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:15.166852Z","iopub.status.busy":"2023-09-01T19:43:15.166300Z","iopub.status.idle":"2023-09-01T19:43:15.406283Z","shell.execute_reply":"2023-09-01T19:43:15.404989Z","shell.execute_reply.started":"2023-09-01T19:43:15.166812Z"},"trusted":true},"outputs":[],"source":["oreb_counts = shooter_data_train['is_oreb'].value_counts(normalize=True)  # normalize will give the fraction\n","oreb_counts_percentage = (oreb_counts * 100).round(2)  # convert to percentage and round off to two decimal points\n","\n","ax = oreb_counts_percentage.plot(kind='bar')\n","plt.title('Defensive vs Offensive Rebounds')\n","plt.xlabel('Offensive Rebounds (0 for no, 1 for yes)')\n","plt.ylabel('Percentage Frequency')\n","\n","# annotate bars with their percentage values\n","for index, value in enumerate(oreb_counts_percentage):\n","    ax.text(index, value + 1, str(value) + '%', ha='center')  # \"+ 1\" to position text above bars slightly\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Rebound Type Frequencies Analysis:\n","*Trends Observed*: \n","- We have an imbalanced dataset as most rebounds (`71.81%`) are defensive rebounds as expected.\n","- It could be beneficial to experiment with oversampling offensive rebound examples to allow the model to more effectively learn the circumstances in offensive rebounds.\n","    - The random nature of the ball's bounce off of the rim may limit the advantages of oversampling.\n","    - Offensive rebounds are often the result of a lucky bounce even when the offense is not in advantageous positioning."]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["## **Bivariate Analysis**"]},{"cell_type":"markdown","metadata":{},"source":["#### Shooting Position vs Offensive Rebounds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:15.408684Z","iopub.status.busy":"2023-09-01T19:43:15.407654Z","iopub.status.idle":"2023-09-01T19:43:15.800905Z","shell.execute_reply":"2023-09-01T19:43:15.799717Z","shell.execute_reply.started":"2023-09-01T19:43:15.408655Z"},"trusted":true},"outputs":[],"source":["# define the grid size for binning\n","grid_size = 4\n","\n","# histogram for shots resulting in offensive rebounds\n","oreb_hist, xedges, yedges = np.histogram2d(\n","    shooter_data_train[shooter_data_train['is_oreb'] == 1]['court_x'], \n","    shooter_data_train[shooter_data_train['is_oreb'] == 1]['court_y'], \n","    bins=(94//grid_size, 50//grid_size)\n",")\n","\n","# histogram for all shots\n","all_shots_hist, _, _ = np.histogram2d(\n","    shooter_data_train['court_x'], \n","    shooter_data_train['court_y'], \n","    bins=(94//grid_size, 50//grid_size)\n",")\n","\n","# calculate the percentage of offensive rebounds in each bin\n","percentage_oreb = np.where(all_shots_hist != 0, (oreb_hist / all_shots_hist) * 100, 0)\n","\n","# plot heatmap\n","plt.figure(figsize=(12, 7))\n","plt.imshow(percentage_oreb.T, origin='lower', aspect='auto', cmap='viridis', \n","           extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]], vmin=0, vmax=100)\n","plt.colorbar(label='Percentage of Offensive Rebounds')\n","plt.title('Percentage of Offensive Rebounds based on Shooting Position')\n","plt.xlabel('Court X Position')\n","plt.ylabel('Court Y Position')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Shooting Position vs Offensive Rebounding Heatmap Analysis:\n","*Trends Observed*: \n","- It seems mid range jumpshots tend to be the worst shots for obtaining an offensive rebound (inefficient for yet another reason).\n","- There are small pockets of the court that have extremely high offensive rebounding rates, but referring back to our heatmap from before, these pockets have small samples."]},{"cell_type":"markdown","metadata":{},"source":["### **Shot Distance from Hoop vs Offensive Rebounds**:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:15.806868Z","iopub.status.busy":"2023-09-01T19:43:15.806089Z","iopub.status.idle":"2023-09-01T19:43:16.584712Z","shell.execute_reply":"2023-09-01T19:43:16.583551Z","shell.execute_reply.started":"2023-09-01T19:43:15.806831Z"},"trusted":true},"outputs":[],"source":["# categorize each shot into the corresponding zones based on shot distance\n","\n","# define the shot distance bins cut by 1 foot\n","shot_distance_bins = [x for x in range(0, 51, 1)]\n","\n","# update the zone_labels accordingly\n","zone_labels = [f'{dist}-{dist+1}' for dist in shot_distance_bins[:-1]]\n","zone_labels[-1] = f'{shot_distance_bins[-2]}+'\n","shooter_data_train['shot_distance_zone'] = pd.cut(shooter_data_train['shooter_dist_from_hoop'], bins=shot_distance_bins, labels=zone_labels, right=False)\n","\n","# calculate the offensive rebound percentage and sample size for each shot distance zone\n","oreb_by_zone = shooter_data_train.groupby('shot_distance_zone')['is_oreb'].mean()\n","sample_size_by_zone = shooter_data_train['shot_distance_zone'].value_counts().reindex(zone_labels, fill_value=0)\n","\n","# create the bar graph\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x=oreb_by_zone.index, y=oreb_by_zone.values, color='skyblue')\n","plt.title('Offensive Rebound Percentage by Shot Distance')\n","plt.xlabel('Shot Distance Zone (feet)')\n","plt.ylabel('Offensive Rebound Percentage')\n","plt.xticks(rotation=45, ha='right')\n","\n","# add sample size annotations to the bars\n","for index, value in enumerate(oreb_by_zone.values):\n","    plt.text(index, value, f'n={sample_size_by_zone.iloc[index]}', ha='center', va='bottom', fontweight='bold', rotation='vertical')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Shot Distance from Hoop vs. Offensive Rebounds Analysis:\n","*Trends Observed*: \n","- More evidence that mid range jumpshots tend to be the worst shots for obtaining an offensive rebound.\n","    - There is a clear dip in offensive rebounding rate for shots from 17-21 feet.\n","- Shots very close to the basket may be more likely to be offensive rebounded because the shooter could be in good position to rebound or they may have broken down the defense and drawn help away from a rim crasher.\n","- Shots greater than 21 feet have a higher rebound rate than shots from 17-21 feet in the training data.\n","    - This may be because longer shots lead to longer rebounds.\n","\n","Binning shot distances into zones may be beneficial because similar shots types are likely taken in each zone, so shot distance may have a complex relationship with offensive rebounding."]},{"cell_type":"markdown","metadata":{},"source":["#### *Proposed Shot Zone Bins:* 0-7, 7-11, 11-17, 17-21, 21+"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:16.586366Z","iopub.status.busy":"2023-09-01T19:43:16.586057Z","iopub.status.idle":"2023-09-01T19:43:16.893948Z","shell.execute_reply":"2023-09-01T19:43:16.892832Z","shell.execute_reply.started":"2023-09-01T19:43:16.586342Z"},"trusted":true},"outputs":[],"source":["# categorize each shot into the corresponding zones based on shot distance\n","\n","# define the shot distance bins\n","shot_distance_bins = [0, 7, 11, 17, 21, np.inf]\n","\n","# define the zone labels accordingly\n","zone_labels = ['0-7', '7-11', '11-17', '17-21', '21+']\n","\n","shooter_data_train['shot_distance_zone'] = pd.cut(shooter_data_train['shooter_dist_from_hoop'], bins=shot_distance_bins, labels=zone_labels, right=False)\n","\n","# calculate the offensive rebound percentage and sample size for each shot distance zone\n","oreb_by_zone = shooter_data_train.groupby('shot_distance_zone')['is_oreb'].mean()\n","sample_size_by_zone = shooter_data_train['shot_distance_zone'].value_counts()\n","\n","# create the bar graph\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x=oreb_by_zone.index, y=oreb_by_zone.values, color='skyblue')\n","plt.title('Offensive Rebound Percentage by Shot Distance')\n","plt.xlabel('Shot Distance Zone (feet)')\n","plt.ylabel('Offensive Rebound Percentage')\n","plt.xticks(rotation=45, ha='right')\n","\n","# add sample size annotations to the bars\n","for index, value in enumerate(oreb_by_zone.values):\n","    plt.text(index, value, f'n={sample_size_by_zone[oreb_by_zone.index[index]]}', ha='center', va='bottom', fontweight='bold')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Shot Distance from Hoop Frequency Distribution Analysis (1/2):\n","The zones are fairly distinct in offensive rebounding percentage, but some sample sizes are small, so it is important to experiment with different bins.\n","- For use in modeling experimentation later on, I create dataframes that one-hot-encode the plays based on these 5 bins."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:16.896361Z","iopub.status.busy":"2023-09-01T19:43:16.895311Z","iopub.status.idle":"2023-09-01T19:43:16.925543Z","shell.execute_reply":"2023-09-01T19:43:16.923213Z","shell.execute_reply.started":"2023-09-01T19:43:16.896331Z"},"trusted":true},"outputs":[],"source":["# categorize 'shooter_dist_from_hoop' column into corresponding zones\n","shooter_data_train['shot_distance_zone'] = pd.cut(shooter_data_train['shooter_dist_from_hoop'], bins=shot_distance_bins, labels=zone_labels)\n","shooter_data_test['shot_distance_zone'] = pd.cut(shooter_data_test['shooter_dist_from_hoop'], bins=shot_distance_bins, labels=zone_labels)\n","\n","\n","# perform One-Hot Encoding for the 'shot_distance_zone' column\n","df_encoded_5bins_train = pd.get_dummies(shooter_data_train, columns=['shot_distance_zone'])\n","df_encoded_5bins_test = pd.get_dummies(shooter_data_test, columns=['shot_distance_zone'])"]},{"cell_type":"markdown","metadata":{},"source":["#### *Alternative Shot Zone Bins:* 0-11, 11-21, 21+"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:16.928393Z","iopub.status.busy":"2023-09-01T19:43:16.927722Z","iopub.status.idle":"2023-09-01T19:43:17.205713Z","shell.execute_reply":"2023-09-01T19:43:17.203275Z","shell.execute_reply.started":"2023-09-01T19:43:16.928346Z"},"trusted":true},"outputs":[],"source":["# categorize each shot into the corresponding zones based on shot distance\n","\n","# define the shot distance bins\n","shot_distance_bins = [0, 11, 21, np.inf]\n","\n","# define the zone labels accordingly\n","zone_labels = ['0-11', '11-21', '21+']\n","\n","shooter_data_train['shot_distance_zone'] = pd.cut(shooter_data_train['shooter_dist_from_hoop'], bins=shot_distance_bins, labels=zone_labels, right=False)\n","\n","# calculate the offensive rebound percentage and sample size for each shot distance zone\n","oreb_by_zone = shooter_data_train.groupby('shot_distance_zone')['is_oreb'].mean()\n","sample_size_by_zone = shooter_data_train['shot_distance_zone'].value_counts()\n","\n","# create the bar graph\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x=oreb_by_zone.index, y=oreb_by_zone.values, color='skyblue')\n","plt.title('Offensive Rebound Percentage by Shot Distance')\n","plt.xlabel('Shot Distance Zone (feet)')\n","plt.ylabel('Offensive Rebound Percentage')\n","plt.xticks(rotation=45, ha='right')\n","\n","# add sample size annotations to the bars\n","for index, value in enumerate(oreb_by_zone.values):\n","    plt.text(index, value, f'n={sample_size_by_zone[oreb_by_zone.index[index]]}', ha='center', va='bottom', fontweight='bold')\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Shot Distance from Hoop Frequency Distribution Analysis (2/2):\n","These zones are more generalized, potentially benefiting the model by minimizing noise. They categorize shots as close range, mid-range, and long range.\n","\n","- The relationship between player proximity to the basket and offensive rebounding might vary across these zones. This is because longer shots tend to result in longer rebounds."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:17.208549Z","iopub.status.busy":"2023-09-01T19:43:17.207965Z","iopub.status.idle":"2023-09-01T19:43:17.234451Z","shell.execute_reply":"2023-09-01T19:43:17.232012Z","shell.execute_reply.started":"2023-09-01T19:43:17.208491Z"},"trusted":true},"outputs":[],"source":["# categorize 'shooter_dist_from_hoop' column into corresponding zones\n","shooter_data_train['shot_distance_zone'] = pd.cut(shooter_data_train['shooter_dist_from_hoop'], bins=shot_distance_bins, labels=zone_labels)\n","shooter_data_test['shot_distance_zone'] = pd.cut(shooter_data_test['shooter_dist_from_hoop'], bins=shot_distance_bins, labels=zone_labels)\n","\n","\n","# perform One-Hot Encoding for the 'shot_distance_zone' column\n","df_encoded_3bins_train = pd.get_dummies(shooter_data_train, columns=['shot_distance_zone'])\n","df_encoded_3bins_test = pd.get_dummies(shooter_data_test, columns=['shot_distance_zone'])"]},{"cell_type":"markdown","metadata":{},"source":["#### Calculating Distance of Defenders, Offensive Players from the basket\n","- These features will inform the spacing of the court at the time of the shot.\n","- If the defense is further out, it may make it harder to box out and there may be more lanes for offensive players to crash the boards."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:17.237680Z","iopub.status.busy":"2023-09-01T19:43:17.237232Z","iopub.status.idle":"2023-09-01T19:43:17.245623Z","shell.execute_reply":"2023-09-01T19:43:17.243937Z","shell.execute_reply.started":"2023-09-01T19:43:17.237647Z"},"trusted":true},"outputs":[],"source":["def calculate_distance_from_hoop(row):\n","    # define the coordinates of the hoop\n","    hoop_coordinates = np.array([[4.0, 25.0], [90.0, 25.0]]) \n","    def_coordinates = np.array([row['court_x'], row['court_y']])\n","    \n","    # calculate the distance\n","    distance = np.linalg.norm(def_coordinates - hoop_coordinates[int(row['which_hoop'])])\n","    return distance"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:17.248538Z","iopub.status.busy":"2023-09-01T19:43:17.247996Z","iopub.status.idle":"2023-09-01T19:43:17.380635Z","shell.execute_reply":"2023-09-01T19:43:17.379435Z","shell.execute_reply.started":"2023-09-01T19:43:17.248471Z"},"trusted":true},"outputs":[],"source":["# merging the information we have learned about which hoop is being shot at back to the training set\n","training_data = training_data.merge(shooter_data_train[['id', 'which_hoop']], left_on='id', right_on='id')\n","testing_data = testing_data.merge(shooter_data_test[['id', 'which_hoop']], left_on='id', right_on='id')"]},{"cell_type":"markdown","metadata":{},"source":["#### Pivoting the Data\n","- Ensuring there is a column for each offensive and defensive player's distance to the basket.\n","- We sort the players by their proximity to the basket.\n","- We calculate the mean distance as well to give a general sense of player proximity to the rim.\n","- These features may be limited in their value because they do not give a sense of where the individual players are located in relation to each other."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:17.382584Z","iopub.status.busy":"2023-09-01T19:43:17.382164Z","iopub.status.idle":"2023-09-01T19:43:17.392197Z","shell.execute_reply":"2023-09-01T19:43:17.391185Z","shell.execute_reply.started":"2023-09-01T19:43:17.382553Z"},"trusted":true},"outputs":[],"source":["def process_defender_distances(df, offense):\n","    \"\"\"\n","    Processes the input dataframe for players, calculates their distances from the hoop,\n","    ranks them by distance, and pivots the data to create features for the closest \n","    players to the hoop.\n","    \n","    Parameters:\n","    - df (pandas.DataFrame): Input dataframe with player data.\n","    - offense (int): 1 for offense 0 for defense.\n","    \n","    Returns:\n","    - pandas.DataFrame: Processed dataframe with ranked distances.\n","    \"\"\"\n","    \n","    # filter dataframe for team\n","    distance = df.loc[df.offense == offense].copy()\n","    \n","    # variable for prefix\n","    prefix = 'off' if offense == 1 else 'def'\n","\n","    # calculate player distance from hoop\n","    distance[f'{prefix}_distance'] = distance.apply(calculate_distance_from_hoop, axis=1)\n","    \n","    # rank the players within each play (id) by distance from the hoop\n","    distance['rank'] = distance.groupby('id')[f'{prefix}_distance'].rank(method='first')\n","\n","    # calculating mean distance from the hoop; groupby will resort by id the same way the rank calc does\n","    mean_dists = distance.groupby('id')[f'{prefix}_distance'].mean()\n","    \n","    # pivot the DataFrame to get features for closest_def_to_hoop, second_closest_def_to_hoop, and so on\n","    df_pivot = distance.pivot_table(index='id', columns='rank', values=f'{prefix}_distance').add_prefix(prefix + '_').reset_index()\n","    \n","    # rename the columns to be more descriptive\n","    df_pivot.columns = ['id'] + [f'closest_{prefix}_to_hoop', f'second_closest_{prefix}_to_hoop', f'third_closest_{prefix}_to_hoop', f'fourth_closest_{prefix}_to_hoop', f'fifth_closest_{prefix}_to_hoop']\n","    \n","    # fill missing values (if any) with a specific value, e.g., -1\n","    df_pivot.fillna(-1, inplace=True)\n","\n","    # inserting mean values as a column\n","    df_pivot[f'{prefix}_distance_mean'] = mean_dists.values\n","    \n","    return df_pivot\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:17.393945Z","iopub.status.busy":"2023-09-01T19:43:17.393385Z","iopub.status.idle":"2023-09-01T19:43:26.743775Z","shell.execute_reply":"2023-09-01T19:43:26.742059Z","shell.execute_reply.started":"2023-09-01T19:43:17.393913Z"},"trusted":true},"outputs":[],"source":["# Pivots the data so there is one row per play\n","def_pivot = process_defender_distances(training_data, 0)\n","off_pivot = process_defender_distances(training_data, 1)\n","def_pivot_test = process_defender_distances(testing_data, 0)\n","off_pivot_test = process_defender_distances(testing_data, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:26.748581Z","iopub.status.busy":"2023-09-01T19:43:26.748145Z","iopub.status.idle":"2023-09-01T19:43:26.765120Z","shell.execute_reply":"2023-09-01T19:43:26.763032Z","shell.execute_reply.started":"2023-09-01T19:43:26.748554Z"},"trusted":true},"outputs":[],"source":["def_pivot.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:26.767473Z","iopub.status.busy":"2023-09-01T19:43:26.767012Z","iopub.status.idle":"2023-09-01T19:43:26.792752Z","shell.execute_reply":"2023-09-01T19:43:26.790659Z","shell.execute_reply.started":"2023-09-01T19:43:26.767438Z"},"trusted":true},"outputs":[],"source":["off_pivot.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:26.796266Z","iopub.status.busy":"2023-09-01T19:43:26.795793Z","iopub.status.idle":"2023-09-01T19:43:26.851190Z","shell.execute_reply":"2023-09-01T19:43:26.848537Z","shell.execute_reply.started":"2023-09-01T19:43:26.796227Z"},"trusted":true},"outputs":[],"source":["# combining the player distance dataframe on play id\n","pivot_train = def_pivot.merge(off_pivot, on='id')\n","pivot_test = def_pivot_test.merge(off_pivot_test, on='id')\n","pivot_train = pivot_train.merge(train_pbp[['id', 'is_oreb']], on='id')"]},{"cell_type":"markdown","metadata":{},"source":["### **Exploring Player Distance vs Offensive Rebounding**"]},{"cell_type":"markdown","metadata":{},"source":["#### Correlation to Offensive Rebounding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:26.857961Z","iopub.status.busy":"2023-09-01T19:43:26.857553Z","iopub.status.idle":"2023-09-01T19:43:26.885109Z","shell.execute_reply":"2023-09-01T19:43:26.884028Z","shell.execute_reply.started":"2023-09-01T19:43:26.857935Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame(pivot_train.corr()['is_oreb'])"]},{"cell_type":"markdown","metadata":{},"source":["#### Correlation Chart Analysis\n","The second closest offensive player has the highest absolute correlation to offensive rebounding (`-.128`), followed by the offensive mean (`-.111`), the third closest off player (`-.105`), and the closest offensive player (`-.093`).\n","- This trend may indicate that having multiple rebounders near the basket is crucial to securing an offensive rebound.\n","\n","Each defender distance has a negative correlation with offensive rebounding, suggesting that defenders are actually further from the basket when they secure defensive rebounds as opposed to when there is an offensive rebound.\n","- This trend may be due to the fact that the area of the floor with the highest offensive rebounding percentage is up close shots, so defenders are likely drawn inward to contest the shot.\n","- It is unlikely that being further from the rim is beneficial to defensive rebounding, so this is an important note.\n","- Defender distance can still be a valuable feature when the model considers its relationship with shot distance zones.\n","\n","Another important note is that player distance to the basket likely does not have a linear relationship with offensive rebounding. A player 2 feet from the basket will not necessarily have a better rebounding chance than a player 4 feet from the basket because rebounds will bounce away from the hoop."]},{"cell_type":"markdown","metadata":{},"source":["#### Visualizing Player Distance vs Offensive Rebounding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:26.886757Z","iopub.status.busy":"2023-09-01T19:43:26.886355Z","iopub.status.idle":"2023-09-01T19:43:27.251938Z","shell.execute_reply":"2023-09-01T19:43:27.250175Z","shell.execute_reply.started":"2023-09-01T19:43:26.886724Z"},"trusted":true},"outputs":[],"source":["# calculating mean distance for each player by offensive and defensive rebounds\n","grouped = pivot_train.groupby('is_oreb').mean()[['closest_def_to_hoop', 'second_closest_def_to_hoop',\n","       'third_closest_def_to_hoop', 'fourth_closest_def_to_hoop',\n","       'fifth_closest_def_to_hoop', 'closest_off_to_hoop',\n","       'second_closest_off_to_hoop', 'third_closest_off_to_hoop',\n","       'fourth_closest_off_to_hoop', 'fifth_closest_off_to_hoop', 'def_distance_mean', 'off_distance_mean']]\n","# flipping the dataframe\n","grouped.transpose().plot(kind='bar', figsize=(12, 7))\n","plt.title('Average Distance by Player Role vs. Offensive Rebounds')\n","plt.ylabel('Average Distance from Hoop')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Average Distance by Player Role vs Offensive Rebounds Analysis:\n","\n","1. Distance of Closest Defender:\n","    - For plays where an offensive rebound (`is_oreb=1`) occurred, the closest defender tends to be slightly closer to the hoop (`6.37` feet) as compared to plays where there was no offensive rebound (`6.73` feet). \n","    - *Insight*: This requires some further investigation and how shot_distance_zone plays a role.\n","\n","2. Other Defenders:\n","    - A similar trend continues for the `second`, `third`, `fourth`, and `fifth` closest defenders. They all tend to be closer to the hoop during successful offensive rebounds than during defensive rebounds.\n","    - *Insight*: The positioning of the entire defense close to the hoop seems to correlate with higher offensive rebound success.\n","\n","3. Distance of Closest Offensive Player:\n","    - When an offensive rebound is successful, the closest offensive player is on average closer to the hoop (`7.91` feet) than in unsuccessful attempts (`8.95` feet).\n","    - *Insight*: Being closer to the hoop increases the chances of grabbing an offensive rebound. Offensive strategies might benefit from ensuring that at least one player is near the hoop during shots.\n","\n","4. Other Offensive Players:\n","    - Just like with defenders, other offensive players (`second` to `fifth` closest) are generally closer to the hoop in plays with successful offensive rebounds.\n","    - *Insight*: It seems that having multiple offensive players close to the hoop enhances the team's chance of securing an offensive rebound. This could suggest the importance of aggressive offensive positioning during shooting attempts.\n","\n","5. Overall Defensive vs. Offensive Presence:\n","    - Comparing the mean distances, defenders are generally closer to the hoop than offensive players. However, the gap is smaller in successful offensive rebound scenarios.\n","    - *Insight*: Defensive teams often position themselves between the offensive players and the hoop. However, reducing the distance gap between offensive players and defenders appears to be a key factor in successful offensive rebounds.\n","\n","Having multiple players near the basket is important to the offense's chance at securing an offensive rebound.\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualizing Offensive Rebounding Success vs Mean Defender Distance in each Shot Distance Zone\n","- Here, we investigate the hypothesis that defender distance correlates negatively with offensive rebounding because they will naturally be closer to the basket on shots from close range which result in more offensive rebounds."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:27.254112Z","iopub.status.busy":"2023-09-01T19:43:27.253719Z","iopub.status.idle":"2023-09-01T19:43:27.261027Z","shell.execute_reply":"2023-09-01T19:43:27.260011Z","shell.execute_reply.started":"2023-09-01T19:43:27.254079Z"},"trusted":true},"outputs":[],"source":["# to see all columns in dfs\n","pd.set_option('display.max_columns', None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:27.262927Z","iopub.status.busy":"2023-09-01T19:43:27.262402Z","iopub.status.idle":"2023-09-01T19:43:27.301182Z","shell.execute_reply":"2023-09-01T19:43:27.299948Z","shell.execute_reply.started":"2023-09-01T19:43:27.262896Z"},"trusted":true},"outputs":[],"source":["# merging shot distanc zone info\n","def_mean_vis_data = pivot_train.merge(df_encoded_5bins_train[['id', 'shot_distance_zone_0-7', 'shot_distance_zone_7-11', 'shot_distance_zone_11-17', 'shot_distance_zone_17-21', 'shot_distance_zone_21+']], on='id')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:27.304152Z","iopub.status.busy":"2023-09-01T19:43:27.302540Z","iopub.status.idle":"2023-09-01T19:43:27.742843Z","shell.execute_reply":"2023-09-01T19:43:27.741511Z","shell.execute_reply.started":"2023-09-01T19:43:27.304092Z"},"trusted":true},"outputs":[],"source":["# melt the dataframe for shot zones to get them in a single column\n","df_melted = def_mean_vis_data.melt(id_vars=['def_distance_mean', 'is_oreb'], \n","                    value_vars=['shot_distance_zone_0-7', 'shot_distance_zone_7-11', 'shot_distance_zone_11-17', 'shot_distance_zone_17-21', 'shot_distance_zone_21+'],\n","                    var_name='shot_zone', value_name='zone_value')\n","\n","# filter only the rows where zone_value is 1\n","df_melted = df_melted[df_melted['zone_value'] == 1]\n","\n","plt.figure(figsize=(12, 7))\n","\n","# create the boxplot\n","sns.boxplot(x='shot_zone', y='def_distance_mean', hue='is_oreb', data=df_melted, palette=\"Set2\")\n","plt.title('Comparison of Average Defender Distance by Shot Zone and Rebound Type')\n","plt.ylabel('Average Defender Distance')\n","plt.xlabel('Shot Zone')\n","plt.xticks(rotation=45)\n","plt.legend(title='Offensive Rebound')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Box Plot Takeaways\n","- This plot helped identify a potential outlier with a defensive rebound occuring with an average defender distance from the hoop of ~80 ft which seems highly unlikely (Potential Roscoe Smith situation).\n","- Outliers in average defender distance are likely unsuccessful shot attempts on fast break opportunities; Average defender distance > 20 is a probable fast break.\n","- Let's use a bar plot instead to better understand the relationship we are investigating. The outliers increase the y range such that it is difficult to compare defender distances.\n","\n","https://www.youtube.com/watch?v=MxsoHBnjOzY\n","\n","Roscoe doing Roscoe things"]},{"cell_type":"markdown","metadata":{},"source":["#### Defender Distance by Shot Zone vs Offensive Rebounding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:27.744780Z","iopub.status.busy":"2023-09-01T19:43:27.744388Z","iopub.status.idle":"2023-09-01T19:43:28.171629Z","shell.execute_reply":"2023-09-01T19:43:28.169118Z","shell.execute_reply.started":"2023-09-01T19:43:27.744745Z"},"trusted":true},"outputs":[],"source":["# create a new DataFrame to calculate the means\n","means_df = def_mean_vis_data.groupby(['is_oreb', 'shot_distance_zone_0-7', 'shot_distance_zone_7-11', 'shot_distance_zone_11-17', 'shot_distance_zone_17-21', 'shot_distance_zone_21+'])['def_distance_mean'].mean().reset_index()\n","\n","# create a 'shot_zone' column to store the zone labels based on the new zones\n","means_df['shot_zone'] = '0-7'\n","means_df.loc[means_df['shot_distance_zone_7-11'] == 1, 'shot_zone'] = '7-11'\n","means_df.loc[means_df['shot_distance_zone_11-17'] == 1, 'shot_zone'] = '11-17'\n","means_df.loc[means_df['shot_distance_zone_17-21'] == 1, 'shot_zone'] = '17-21'\n","means_df.loc[means_df['shot_distance_zone_21+'] == 1, 'shot_zone'] = '21+'\n","\n","g = sns.catplot(x='shot_zone', y='def_distance_mean', hue='is_oreb', data=means_df, kind='bar', palette=\"Set2\", height=7, aspect=2)\n","g.despine(left=True)\n","g.set_axis_labels(\"Shot Zone\", \"Average Defender Distance\")\n","\n","plt.title('Average Defender Distance by Shot Zone and Rebound Type')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Takeaways\n","The hypothesis that defender distance correlates negatively with offensive rebounding only because they will naturally be closer to the basket on shots from close range (which result in more offensive rebounds) does not appear to be the case. With the excpetion of long range shots (very narrowly, `15.16 ft` to `15.18 ft`), defenders distance to the rim is on average further for defensive rebounds than offensive, Let's dive into why defenders may be further from the basket on successful defensive rebounds:\n","- Successful Boxouts - When the defense is in control of the defensive boards, they will have successfully made contact with their boxout responsibility and pushed them away from the hoop.\n","- Compromised Defense - If defenders are on average closer to the hoop, this could be an indicator that a help defender was needed to impede an offensive threat from getting to the hoop. Naturally, this creates more opportune angles for offensive rebounders to position themselves for a missed shot.\n","\n","Feature engineering considerations: defender distance will be highly dependent on the offense's positioning, so it will be key to highlight their relative distance to the basket"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:28.175704Z","iopub.status.busy":"2023-09-01T19:43:28.175251Z","iopub.status.idle":"2023-09-01T19:43:28.200210Z","shell.execute_reply":"2023-09-01T19:43:28.198184Z","shell.execute_reply.started":"2023-09-01T19:43:28.175678Z"},"trusted":true},"outputs":[],"source":["df_encoded_3bins_train.head(3)"]},{"cell_type":"markdown","metadata":{},"source":["# **Baseline Model**\n","- I create a baseline model using only player distance from the hoop and shot distances zones to measure our model experimentation against later on."]},{"cell_type":"markdown","metadata":{},"source":["#### Merging Shot Distance Zone Data with Player Distances"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:28.273626Z","iopub.status.busy":"2023-09-01T19:43:28.273180Z","iopub.status.idle":"2023-09-01T19:43:28.324521Z","shell.execute_reply":"2023-09-01T19:43:28.322880Z","shell.execute_reply.started":"2023-09-01T19:43:28.273601Z"},"trusted":true},"outputs":[],"source":["# merging shot distance zones with distance data\n","df_encoded_train_5bins = df_encoded_5bins_train.merge(pivot_train.drop(columns='is_oreb'), on='id').drop(columns=['court_x', 'court_y', 'annotation_code', 'offense', 'shooter', \n","                                                                                                                'shooter_dist_from_hoop', 'which_hoop', 'game_number', 'play_number'], axis=1)\n","df_encoded_test_5bins = df_encoded_5bins_test.merge(pivot_test, on='id').drop(columns=['court_x', 'court_y', 'annotation_code', 'offense', 'shooter', 'shooter_dist_from_hoop', 'which_hoop'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:28.525951Z","iopub.status.busy":"2023-09-01T19:43:28.525469Z","iopub.status.idle":"2023-09-01T19:43:28.577398Z","shell.execute_reply":"2023-09-01T19:43:28.575763Z","shell.execute_reply.started":"2023-09-01T19:43:28.525916Z"},"trusted":true},"outputs":[],"source":["# merging shot distance zones with distance data\n","df_encoded_train_3bins = df_encoded_3bins_train.merge(pivot_train.drop(columns='is_oreb'), on='id').drop(columns=['court_x', 'court_y', 'annotation_code', 'offense', 'shooter', \n","                                                                                                                'shooter_dist_from_hoop', 'which_hoop', 'game_number', 'play_number'], axis=1)\n","df_encoded_test_3bins = df_encoded_3bins_test.merge(pivot_test, on='id').drop(columns=['court_x', 'court_y', 'annotation_code', 'offense', 'shooter', 'shooter_dist_from_hoop', 'which_hoop'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:28.710517Z","iopub.status.busy":"2023-09-01T19:43:28.709588Z","iopub.status.idle":"2023-09-01T19:43:28.734002Z","shell.execute_reply":"2023-09-01T19:43:28.731930Z","shell.execute_reply.started":"2023-09-01T19:43:28.710477Z"},"trusted":true},"outputs":[],"source":["df_encoded_train_5bins.head(3)"]},{"cell_type":"markdown","metadata":{},"source":["#### Scaling the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:29.349120Z","iopub.status.busy":"2023-09-01T19:43:29.348612Z","iopub.status.idle":"2023-09-01T19:43:29.359100Z","shell.execute_reply":"2023-09-01T19:43:29.356893Z","shell.execute_reply.started":"2023-09-01T19:43:29.349088Z"},"trusted":true},"outputs":[],"source":["def scale_distances(df, df_test, zones):\n","    # using a StandardScaler (instead of MinMax) to reduce the impact of outliers\n","    scaler = StandardScaler()\n","\n","    data = df.copy()\n","    data_test = df_test.copy()\n","    # extract the continuous features from the DataFrame\n","    continuous_features = data.iloc[:, zones + 2:]  # the continuous features start from the number of zones + 2\n","    continuous_features_test = data_test.iloc[:, zones + 1:] # test does not have target variable, so 1 index less\n","\n","    # fit and transform the continuous features using the StandardScaler\n","    # fitting on the train set only\n","    scaled_continuous_features = scaler.fit_transform(continuous_features)\n","    scaled_continuous_features_test = scaler.transform(continuous_features_test)\n","\n","    # convert the scaled_continuous_features back to a DataFrame with the original column names\n","    scaled_continuous_df = pd.DataFrame(scaled_continuous_features, columns=continuous_features.columns)\n","    scaled_continuous_df_test = pd.DataFrame(scaled_continuous_features_test, columns=continuous_features_test.columns)\n","\n","    # concatenate the scaled continuous features with the categorical features\n","    data = pd.concat([data.iloc[:, :zones + 2:], scaled_continuous_df], axis=1)\n","    data_test = pd.concat([data_test.iloc[:, :zones + 1], scaled_continuous_df_test], axis=1)\n","    return data, data_test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:29.713515Z","iopub.status.busy":"2023-09-01T19:43:29.713113Z","iopub.status.idle":"2023-09-01T19:43:29.744573Z","shell.execute_reply":"2023-09-01T19:43:29.743725Z","shell.execute_reply.started":"2023-09-01T19:43:29.713481Z"},"trusted":true},"outputs":[],"source":["# scaling dataframes\n","X_dist_3bins, X_test_dist_3bins = scale_distances(df_encoded_train_3bins, df_encoded_test_3bins, 3)\n","X_dist_5bins, X_test_dist_5bins = scale_distances(df_encoded_train_5bins, df_encoded_test_5bins, 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:30.074794Z","iopub.status.busy":"2023-09-01T19:43:30.074344Z","iopub.status.idle":"2023-09-01T19:43:30.097812Z","shell.execute_reply":"2023-09-01T19:43:30.096512Z","shell.execute_reply.started":"2023-09-01T19:43:30.074767Z"},"trusted":true},"outputs":[],"source":["X_dist_5bins.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:30.318658Z","iopub.status.busy":"2023-09-01T19:43:30.318278Z","iopub.status.idle":"2023-09-01T19:43:30.328593Z","shell.execute_reply":"2023-09-01T19:43:30.327088Z","shell.execute_reply.started":"2023-09-01T19:43:30.318630Z"},"trusted":true},"outputs":[],"source":["# finalizing X and y by removing id and the target from X\n","y_dist = X_dist_3bins['is_oreb']\n","X_dist_3 = X_dist_3bins.drop(columns=['id', 'is_oreb'])\n","X_dist_5 = X_dist_5bins.drop(columns=['id', 'is_oreb'])"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Choice\n","\n","For our analysis on the relationship between player positions, shot distances, and the likelihood of offensive rebounds, I opted for the XGBoost algorithm. XGBoost, which stands for eXtreme Gradient Boosting, is renowned for its efficiency and performance, frequently standing out in machine learning competitions. The key reasons for this choice include:\n","\n","1. *Ensemble Learning*: XGBoost operates on the gradient boosting framework, which builds an ensemble of weak prediction models, typically decision trees. This ensemble approach is especially adept at tackling complex datasets like ours, where interactions between features (like player positions and shot distances) are nuanced.\n","\n","2. *Regularization*: Unlike many other tree-based algorithms, XGBoost incorporates L1 (Lasso Regression) and L2 (Ridge Regression) regularization. This ensures that our model doesn't overfit to the training data, a common concern when working with intricate sports datasets that contain multifaceted relationships like we have already encountered in EDA.\n","\n","3. *Flexibility*: XGBoost can be easily integrated with other machine learning frameworks and is amenable to a range of hyperparameter tuning options. This flexibility ensures we can optimize the model for our specific task and dataset.\n","\n","In summary, given the intricacies of our basketball analysis and the inherent challenges in predicting rebounds, XGBoost emerged as a natural choice due to its robustness, efficiency, and adaptability."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:31.152050Z","iopub.status.busy":"2023-09-01T19:43:31.150982Z","iopub.status.idle":"2023-09-01T19:43:40.142071Z","shell.execute_reply":"2023-09-01T19:43:40.141109Z","shell.execute_reply.started":"2023-09-01T19:43:31.151985Z"},"trusted":true},"outputs":[],"source":["# create the XGBoost model\n","model = xgb.XGBClassifier(learning_rate=0.1, n_estimators=100, objective='binary:logistic', \n","                          eval_metric='logloss', max_depth=3, min_child_weight=5)\n","\n","# perform cross-validation\n","cross_val_scores = cross_val_score(model, X_dist_3, y_dist, cv=5, scoring='neg_log_loss')\n","\n","# since cross_val_score returns negative log loss values, we take the negative to get the positive log loss\n","log_loss_scores = -cross_val_scores\n","\n","# print the average log loss across all folds\n","print('Average Log Loss:', log_loss_scores.mean())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:40.144687Z","iopub.status.busy":"2023-09-01T19:43:40.143832Z","iopub.status.idle":"2023-09-01T19:43:49.555949Z","shell.execute_reply":"2023-09-01T19:43:49.553692Z","shell.execute_reply.started":"2023-09-01T19:43:40.144644Z"},"trusted":true},"outputs":[],"source":["# create the XGBoost model\n","model = xgb.XGBClassifier(learning_rate=0.1, n_estimators=100, objective='binary:logistic', \n","                          eval_metric='logloss', max_depth=3, min_child_weight=5)\n","\n","# perform cross-validation\n","cross_val_scores = cross_val_score(model, X_dist_5, y_dist, cv=5, scoring='neg_log_loss')\n","\n","# since cross_val_score returns negative log loss values, we take the negative to get the positive log loss\n","log_loss_scores = -cross_val_scores\n","\n","# print the average log loss across all folds\n","print('Average Log Loss:', log_loss_scores.mean())"]},{"cell_type":"markdown","metadata":{},"source":["#### Analyzing XGBoost Model Performance Across Different Shot Distance Zones\n","\n","When building a predictive model, especially in sports analytics where the granularity of data can offer rich insights, it's essential to experiment with how we segment or categorize our features. In basketball, the shot distance, given its evident influence on player positions and strategies, serves as an ideal feature for such experimentation.\n","\n","##### Results:\n","\n","- *3 Shot Distance Zones*: This broader categorization yielded an Average Log Loss of `0.58115`.\n","- *5 Shot Distance Zones*: A more detailed categorization resulted in a slightly better Average Log Loss of `0.58099`.\n","\n","##### Discussion:\n","\n","The difference in performance between the two categorizations is marginal. This could suggest a few points:\n","\n","1. The addition of two more shot distance zones offers only a slight enhancement in our model's predictive accuracy. \n","2. The improvement in the 5-zone model might be attributed to capturing more intricate relationships in the data. However, the near-identical performance indicates our XGBoost model might already be capturing most of the variance with just the three zones.\n","3. Given the negligible difference in Log Loss, we should weigh the benefits of a finer granularity against its potential costs in terms of complexity and interpretability.\n","\n","##### Recommendations:\n","\n","While the model with 5 shot distance zones marginally outperforms its counterpart, we should consider the broader implications. Simpler models, like the 3-zone one, could be preferable for their ease of interpretation, especially when speaking with stakeholders less familiar with data intricacies; discussing shots as short-range, mid-range, and long-range may be easier to understand. However, if the primary goal is to maximize predictive accuracy, then every small advantage, such as that provided by the 5-zone model, becomes valuable.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:49.559038Z","iopub.status.busy":"2023-09-01T19:43:49.557697Z","iopub.status.idle":"2023-09-01T19:43:51.804479Z","shell.execute_reply":"2023-09-01T19:43:51.802582Z","shell.execute_reply.started":"2023-09-01T19:43:49.558961Z"},"trusted":true},"outputs":[],"source":["model = xgb.XGBClassifier(learning_rate=0.1, n_estimators=100, objective='binary:logistic', eval_metric='logloss', max_depth=3, min_child_weight=3)\n","model.fit(X_dist_5, y_dist)"]},{"cell_type":"markdown","metadata":{},"source":["#### Feature Importances in Predicting Offensive Rebounds\n","\n","- In the realm of basketball analytics, understanding feature importances not only aids in model interpretability but also provides deeper insights into on-court dynamics and strategies. The XGBoost model has provided the following feature importances for predicting offensive rebounds:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:51.807722Z","iopub.status.busy":"2023-09-01T19:43:51.807198Z","iopub.status.idle":"2023-09-01T19:43:51.814957Z","shell.execute_reply":"2023-09-01T19:43:51.813130Z","shell.execute_reply.started":"2023-09-01T19:43:51.807690Z"},"trusted":true},"outputs":[],"source":["def plot_feat_importances(columns, feature_importances):\n","    # Plot the importances\n","    plt.figure(figsize=(10, len(columns)/2))  # Adjust the figure size\n","    plt.title('Feature Importances')\n","    plt.barh(columns, feature_importances)\n","    plt.xlabel('Importance')\n","    plt.ylabel('Feature')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:43:51.817345Z","iopub.status.busy":"2023-09-01T19:43:51.817024Z","iopub.status.idle":"2023-09-01T19:43:52.125885Z","shell.execute_reply":"2023-09-01T19:43:52.124805Z","shell.execute_reply.started":"2023-09-01T19:43:51.817319Z"},"trusted":true},"outputs":[],"source":["plot_feat_importances(X_dist_5.columns, model.feature_importances_)"]},{"cell_type":"markdown","metadata":{},"source":["\n","\n","#### Key Feature Importance Insights:\n","\n","1. Shot Distance Zones:\n","    - **`0-7 feet` (0.0841)**: This zone, closest to the basket, is crucial in predicting offensive rebounds, likely due to many shots and subsequent rebound opportunities occurring here.\n","    - **`7-11 feet` (0.0413)** and **`11-17 feet`(0.0570)**: These mid-range distances show moderate importance. The decrease in importance from the closest zone may indicate fewer shots from this area or different rebound dynamics.\n","    - **`17-21 feet` (0.0138)**: Reduced importance here may reflect fewer shot attempts from this distance.\n","    - **`21+ feet` (0.0828)**: Despite being farther, this zone's importance is nearly on par with the closest zone, suggesting the long rebounds from 3-pointers play a significant role.\n","\n","2. Defensive Players' Distance to Hoop:\n","    - The distances of the individual defensive players (ranging from **0.0346 to 0.0522**) show similar levels of importance. This underscores the team aspect of defensive rebounding, where positioning of all players matters.\n","    - **`Defensive Mean Distance` (0.0379)**: The average distance of defenders showcases their collective positioning, and its significance might indicate the defensive setup during shots.\n","\n","3. Offensive Players' Distance to Hoop:\n","    - **`Second Closest Offensive Player to Hoop` (0.1430)**: This stands out as the most influential feature. It indicates that while the closest offensive player is vital, having a second player nearby is crucial for securing offensive rebounds.\n","    - **`Offensive Mean Distance` (0.1357)**: This emphasizes the collective effort on the offensive boards, suggesting a balanced offensive rebounding approach is fruitful.\n","    - Other offensive players' distances also hold relevance, with values around **0.036 to 0.0606**, highlighting the importance of team positioning.\n"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["# **Complex Feature Engineering**\n","- To this point we have constructed a high performing model using distances of shots and players from the basket. The next step will be to incorporate angles and relative positions to get a better sense of how well teams are positioned for rebounds at the time of a shot. There will be in depth explanations of the rationale for each feature engineered. Feature importance scores and visualizations will be the primary tools for assessing the effectiveness of each feature."]},{"cell_type":"markdown","metadata":{},"source":["## **Assigning Boxout Responsibilities**\n","\n","*Offensive Rebounding Player Assignment Algorithm*\n","\n","Understanding which players are most likely to box out one another is crucial to understanding the chances of an offensive rebound. If an offensive player is in front of a defensive player, this cannot be captured by a distance to the hoop metric without knowing which players will be competing with each other for position. To optimally choose which offensive player a defensive rebounder should box out, I will use the distance from defensive player to the offensive player and the betweenness centrality of the offensive player. Offensive players closer to the hoop will be prioritized by using betweenness centrality because there will be edges connecting offensive players to the hoop with weights reflecting the inverse of their distance.\n","\n","This algorithm is designed to optimize the assignment of defensive players to their respective offensive players during a basketball game to enhance the team's chances of securing a defensive rebound.\n","\n","Step 1: Creating a Spatial Graph\n","\n","The algorithm starts by constructing a spatial graph that represents the relationships between offensive players and the hoop (basket). Each player and the hoop are represented as nodes in the graph, and weighted edges are added between offensive players and the hoop as well as offensive players and other offensive players based on their spatial proximity. This graph reflects the players' positioning on the court and helps identify the best offensive players to box out for each defender.\n","\n","Step 2: Betweenness Centrality\n","\n","The algorithm then calculates a measure called 'betweenness centrality' for each offensive player in the graph. This metric quantifies how often an offensive player lies on the shortest path between other offensive players and the hoop. High betweenness centrality indicates that a player is in a critical position on the court, and boxing out such players becomes crucial for effective rebounding. In basketball terms, offensive players with high betweenness centrality are in critical positions that can impact the overall offensive flow and create more scoring opportunities. Therefore, these players become important targets for defensive players to box out and prevent them from securing offensive rebounds.\n","\n","Step 3: Optimizing Player Assignments\n","\n","Next, the algorithm aims to optimize the assignment of defensive players to offensive players. To achieve this, it creates a cost matrix that considers both the distance between defensive and offensive players and the offensive players' betweenness centrality. The Hungarian algorithm is then employed to find the best possible player assignments that prioritize players with higher betweenness centrality while minimizing the distances to the boxout responsibility.\n","\n","Step 4: Iterative Refinement\n","\n","To further improve the assignments, the algorithm iteratively updates the player assignments and optimizes the betweenness centrality and distances. This iterative refinement process enhances the quality of player matchups, ensuring that no defensive player is left without a specific offensive player to box out.\n","\n","Step 5: Assigning Remaining Defenders\n","\n","After the iterations, there may still be some defenders without an offensive player assigned to them. To address this, the algorithm finds the closest unassigned offensive player for each remaining defender based on the distances."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:44:43.031531Z","iopub.status.busy":"2023-09-01T19:44:43.031006Z","iopub.status.idle":"2023-09-01T19:44:43.065045Z","shell.execute_reply":"2023-09-01T19:44:43.062829Z","shell.execute_reply.started":"2023-09-01T19:44:43.031495Z"},"trusted":true},"outputs":[],"source":["def calculate_distance(point1, point2):\n","    \"\"\"\n","    Calculates the Euclidean distance between two points.\n","    \n","    Parameters:\n","        - point1 (numpy array): The coordinates of the first point.\n","        - point2 (numpy array): The coordinates of the second point.\n","        \n","    Returns:\n","        - float: The Euclidean distance between point1 and point2.\n","    \"\"\"\n","    return np.linalg.norm(point1 - point2)\n","\n","def construct_graph(offensive_players_, hoop, distances):\n","    \"\"\"\n","    Constructs a graph where nodes represent offensive players and the basketball hoop, \n","    and edges represent the inverse of the distance between them.\n","    \n","    Parameters:\n","        - offensive_players_ (list of numpy arrays): List of coordinates for the offensive players.\n","        - hoop (numpy array): The coordinates of the basketball hoop.\n","        - distances (dict): A dictionary containing pairwise distances between points.\n","        \n","    Returns:\n","        - NetworkX Graph: A graph constructed based on the provided distances.\n","    \"\"\"\n","    graph = nx.Graph()\n","    for player1 in offensive_players_:\n","        for player2 in offensive_players_:\n","            if not np.array_equal(player1, player2):\n","                distance = calculate_distance(player1, player2)\n","                graph.add_edge(tuple(player1), tuple(player2), weight=1.0 / distance)\n","        distance_to_hoop = distances[(tuple(player1), tuple(hoop))]\n","        graph.add_edge(tuple(player1), tuple(hoop), weight=1.0 / distance_to_hoop)\n","    \n","    return graph\n","\n","def calculate_betweenness_centralities(graph):\n","    \"\"\"\n","    Calculates the betweenness centrality for all nodes in a graph.\n","    \n","    Parameters:\n","        - graph (NetworkX Graph): A graph for which to compute the betweenness centrality.\n","        \n","    Returns:\n","        - dict: A dictionary with nodes as keys and betweenness centralities as values.\n","    \"\"\"\n","    return nx.betweenness_centrality(graph, weight='weight')\n","\n","def calculate_cost_matrix(defenders_, offensive_players_, distances, betweenness_centralities):\n","    \"\"\"\n","    Calculates a cost matrix based on distance and betweenness centrality.\n","    \n","    Parameters:\n","        - defenders_ (list of numpy arrays): List of coordinates for the defenders.\n","        - offensive_players_ (list of numpy arrays): List of coordinates for the offensive players.\n","        - distances (dict): A dictionary containing pairwise distances between points.\n","        - betweenness_centralities (dict): A dictionary of nodes and their respective betweenness centrality.\n","        \n","    Returns:\n","        - numpy array: A matrix representing the cost of assigning defenders to offensive players.\n","    \"\"\"\n","    num_defenders = len(defenders_)\n","    num_offensive_players = len(offensive_players_)\n","    cost_matrix = np.zeros((num_defenders, num_offensive_players))\n","\n","    for i, defender in enumerate(defenders_):\n","        for j, offensive_player in enumerate(offensive_players_):\n","            distance_cost = distances[(tuple(defender), tuple(offensive_player))]\n","            betweenness_cost = -betweenness_centralities[tuple(offensive_player)]\n","            # betweenness centralities are between 0 and 1, so multiplying by a factor of 5 to emphasize its cost\n","            cost_matrix[i, j] = distance_cost + betweenness_cost\n","\n","    return cost_matrix\n","\n","def assign_offensive_players(defenders_, offensive_players_, hoop, num_iterations=5):\n","    \"\"\"\n","    Assigns each defender to an offensive player based on distance and betweenness centrality, \n","    using the linear_sum_assignment algorithm.\n","    \n","    Parameters:\n","        - defenders_ (list of numpy arrays): List of coordinates for the defenders.\n","        - offensive_players_ (list of numpy arrays): List of coordinates for the offensive players.\n","        - hoop (numpy array): The coordinates of the basketball hoop.\n","        - num_iterations (int, optional): The number of times to iterate over the assignment process. \n","          Defaults to 5.\n","          \n","    Returns:\n","        - dict: A dictionary mapping each defender to an assigned offensive player.\n","        - dict: A dictionary to store betweenness centralities for each iteration.\n","    \"\"\"\n","    distances = {}\n","    for defender in defenders_:\n","        for offensive_player in offensive_players_:\n","            distances[(tuple(defender), tuple(offensive_player))] = calculate_distance(defender, offensive_player)\n","        distances[(tuple(defender), tuple(hoop))] = calculate_distance(defender, hoop)\n","\n","    for offensive_player in offensive_players_:\n","        distances[(tuple(offensive_player), tuple(hoop))] = calculate_distance(offensive_player, hoop)\n","\n","    assignments = {}\n","    centralities_store = {} # a dictionary to store betweenness centralities for each iteration\n","    unassigned_defenders = list(defenders_)\n","\n","    for _ in range(num_iterations):\n","        graph = construct_graph(offensive_players_, hoop, distances)\n","        betweenness_centralities = calculate_betweenness_centralities(graph)\n","        centralities_store.update(betweenness_centralities)  # store the betweenness centralities\n","\n","        cost_matrix = calculate_cost_matrix(defenders_, offensive_players_, distances, betweenness_centralities)\n","        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n","\n","        for i, j in zip(row_ind, col_ind):\n","            defender = tuple(defenders_[i])\n","            offensive_player = tuple(offensive_players_[j])\n","            assignments[defender] = offensive_player\n","            if any(np.array_equal(defender, a) for a in unassigned_defenders):\n","                unassigned_defenders = [x for x in unassigned_defenders if not (x == defender).all()]\n","\n","    for defender in unassigned_defenders:\n","        min_distance = float('inf')\n","        closest_offensive_player = None\n","        for offensive_player in offensive_players_:\n","            distance = distances[(tuple(defender), tuple(offensive_player))]\n","            if distance < min_distance:\n","                min_distance = distance\n","                closest_offensive_player = tuple(offensive_player)\n","        assignments[tuple(defender)] = closest_offensive_player\n","\n","    return assignments, centralities_store\n","\n","# example usage:\n","defenders = np.array([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4]])\n","offensive_players = np.array([[5, 0], [6, 1], [7, 2], [8, 3], [9, 4]])\n","hoop = np.array([10, 5])\n","\n","assignments = assign_offensive_players(defenders, offensive_players, hoop)\n","print(assignments)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:44:46.044205Z","iopub.status.busy":"2023-09-01T19:44:46.043766Z","iopub.status.idle":"2023-09-01T19:44:46.062502Z","shell.execute_reply":"2023-09-01T19:44:46.060601Z","shell.execute_reply.started":"2023-09-01T19:44:46.044175Z"},"trusted":true},"outputs":[],"source":["# making copies of the dataset to be used in assigning responsibilities\n","copy_training_data = training_data.copy()\n","copy_testing_data = testing_data.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:44:46.928262Z","iopub.status.busy":"2023-09-01T19:44:46.927912Z","iopub.status.idle":"2023-09-01T19:44:46.938470Z","shell.execute_reply":"2023-09-01T19:44:46.936488Z","shell.execute_reply.started":"2023-09-01T19:44:46.928236Z"},"trusted":true},"outputs":[],"source":["def assign_responsibilities(data):\n","    \"\"\"\n","    For each play instance, assigns each defender to an offensive player based on \n","    distance and betweenness centrality. Also appends the offensive player coordinates \n","    and betweenness centrality to the defender's data.\n","    \n","    Parameters:\n","        - data (pandas DataFrame): A dataframe containing the following columns:\n","          * 'id': A unique identifier for each play instance.\n","          * 'offense': Binary column where 1 indicates an offensive player and 0 indicates a defender.\n","          * 'court_x', 'court_y': The x and y coordinates of players on the court.\n","          * 'which_hoop': Binary column where 0 indicates one hoop and 1 indicates the other.\n","          \n","    Returns:\n","        - pandas DataFrame: A modified version of the input dataframe that includes:\n","          * 'off_x', 'off_y': The x and y coordinates of the assigned offensive player.\n","          * 'betweenness_centrality': The betweenness centrality of the assigned offensive player.\n","    \"\"\"\n","    grouped_data = data.groupby('id')\n","    assignments_list = []\n","    centralities_list = []\n","    list_of_ids = []\n","\n","    for id, group in grouped_data:\n","        defenders_ = group[group['offense'] == 0][['court_x', 'court_y']].values\n","        offensive_players_ = group[group['offense'] == 1][['court_x', 'court_y']].values\n","        hoop = [4, 25] if group['which_hoop'].iloc[0] == 0 else [90, 25]\n","        assignments, centralities = assign_offensive_players(defenders_, offensive_players_, hoop)\n","        assignments_list.append(assignments)\n","        centralities_list.append(centralities)\n","        list_of_ids.append(id)\n","\n","    assignments_dict = dict(zip(list_of_ids, assignments_list))\n","    centralities_dict = dict(zip(list_of_ids, centralities_list))\n","    \n","    def_data = data.loc[data.offense == 0]\n","    off_coords = def_data.apply(lambda row: assignments_dict[row['id']][(row['court_x'], row['court_y'])], axis=1)\n","    def_data[['off_x', 'off_y']] = off_coords.apply(pd.Series)\n","    def_data['betweenness_centrality'] = def_data.apply(lambda row: centralities_dict[row['id']][(row['off_x'], row['off_y'])], axis=1)\n","\n","    return def_data"]},{"cell_type":"markdown","metadata":{},"source":["This code block takes ~5 minutes to run on CPU. CSV data is provided for convenience."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# paired player datasets built\n","if RUN_CELL:\n","    def_training_data = assign_responsibilities(copy_training_data)\n","    def_testing_data = assign_responsibilities(copy_testing_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:45:15.918203Z","iopub.status.busy":"2023-09-01T19:45:15.917662Z","iopub.status.idle":"2023-09-01T19:45:16.565393Z","shell.execute_reply":"2023-09-01T19:45:16.563073Z","shell.execute_reply.started":"2023-09-01T19:45:15.918161Z"},"trusted":true},"outputs":[],"source":["def_training_data = pd.read_csv('/data/def_training_data.csv').drop('Unnamed: 0', axis=1)\n","def_testing_data = pd.read_csv('/data/def_testing_data.csv').drop('Unnamed: 0', axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# def_training_data.to_csv('def_training_data.csv')\n","# def_testing_data.to_csv('def_testing_data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:45:23.327863Z","iopub.status.busy":"2023-09-01T19:45:23.327351Z","iopub.status.idle":"2023-09-01T19:45:23.922490Z","shell.execute_reply":"2023-09-01T19:45:23.920318Z","shell.execute_reply.started":"2023-09-01T19:45:23.327834Z"},"trusted":true},"outputs":[],"source":["# cleaning the dataset\n","# court_x/y are the defensive players coordinates after the responsibility assignments\n","def_training_data.rename(columns={'court_x': 'def_x', 'court_y': 'def_y'}, inplace=True)\n","def_testing_data.rename(columns={'court_x': 'def_x', 'court_y': 'def_y'}, inplace=True)\n","# merging the original location data to know which pairing's offensive player is the shooter\n","def_training_data = def_training_data.merge(train_locs, left_on=['id', 'off_x', 'off_y'], right_on=['id', 'court_x', 'court_y'])\n","def_testing_data = def_testing_data.merge(test_locs, left_on=['id', 'off_x', 'off_y'], right_on=['id', 'court_x', 'court_y'])\n","# court_x/y are from the recently joined train_locs and have the same values as the off_x/y\n","def_training_data.drop(columns=['court_x', 'court_y'], inplace=True)\n","def_testing_data.drop(columns=['court_x', 'court_y'], inplace=True)\n","# assigning the annotation codes as either defensive or offensive \n","def_training_data.rename(columns={'annotation_code_x': 'annotation_code_def', 'annotation_code_y': 'annotation_code_off'}, inplace=True)\n","def_testing_data.rename(columns={'annotation_code_x': 'annotation_code_def', 'annotation_code_y': 'annotation_code_off'}, inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualizing an Example Play's Responsibility Pairings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:45:38.991685Z","iopub.status.busy":"2023-09-01T19:45:38.991185Z","iopub.status.idle":"2023-09-01T19:45:39.399651Z","shell.execute_reply":"2023-09-01T19:45:39.398082Z","shell.execute_reply.started":"2023-09-01T19:45:38.991646Z"},"trusted":true},"outputs":[],"source":["# sample data\n","df = pd.DataFrame(def_training_data[0:5]) \n","\n","# load the images\n","court_image = Image.open('/images/court_dims.png')\n","\n","# plot the basketball court\n","plt.figure(figsize=(10, 5))\n","plt.imshow(court_image, extent=[0, 94, 0, 50])  # Extent based on court dimensions\n","\n","\n","# plotting the coordinates and connecting the pairs of players with lines\n","plt.scatter(df['off_x'], df['off_y'], color='blue', label='Offensive Players')\n","plt.scatter(df['def_x'], df['def_y'], color='red', label='Defenders')\n","\n","# connect the pairs of players with lines\n","for i, row in df.iterrows():\n","    plt.plot([row['off_x'], row['def_x']], [row['off_y'], row['def_y']], color='gray', linestyle='dotted')\n","\n","# putting a green x over the shooter\n","shooter_row = df[df['annotation_code_off'] == 's'].iloc[0]\n","plt.scatter(shooter_row['off_x'], shooter_row['off_y'], color='green', marker='x', s=100, label='Shooter')\n","\n","plt.xlabel('X-coordinate')\n","plt.ylabel('Y-coordinate')\n","plt.title('Coordinates and Connections on Basketball Court')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Observations and Limitations of Boxout Responsibilities\n","*Observations*:\n","- With this play, the algorithm seems to have done a good job in assigning reponsibilities as the players are logically matched to close by and important to box out players.\n","- In this example, the offensive player on the left block is in an advantageous rebound positioning.\n","- The goal of the next section will be to capture these types of advantages by leveraging the player pairing coordinate data.\n","\n","*Potential Limitations*:\n","- Although the process for pairing players follows a logical set of steps, there is no guarantee that the pairings match player behavior.\n","    - The dataset at hand does not have access to key factors in boxout decision making like the size of players and temporal information like their speed, acceleration, or direction. Players may choose to box out larger players that are seen as bigger threats if it meant veering from the most logical boxout pairing based on spacing alone. If a player is darting towards the rim, they would also be a prioritized threat as compared to a player fading away from the rim for a shot. \n","    - Players may make judgement errors in deciding which player to box out. \n","    - Many players will not need to be boxed out at all because they are getting back on defense to guard against transition opportunities. This would lead to more defensive players available to help clear out offensive rebounding threats.\n","\n","Despite these limitations, the pairings will have utility because they inform how clear the path to the basket is for each offensive player."]},{"cell_type":"markdown","metadata":{},"source":["## **Using Responsibilities to Build Features**\n","- Now that we know which offensive player each defensive player is responsible for boxing out, there are a host of new ways to develop features based on angles (between pairs of players and the hoop) and distances (from hoop to player and player to player)"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualizing Player Pairing Relative Angles"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:51:31.233975Z","iopub.status.busy":"2023-09-01T19:51:31.233634Z","iopub.status.idle":"2023-09-01T19:51:32.029140Z","shell.execute_reply":"2023-09-01T19:51:32.027648Z","shell.execute_reply.started":"2023-09-01T19:51:31.233951Z"},"trusted":true},"outputs":[],"source":["\n","def calculate_angle(x1, y1, vx, vy, x2, y2):\n","    '''\n","    Calculate the angle (in degrees) formed between two points and a vertex.\n","\n","    Given two points (x1, y1) and (x2, y2), this function computes the angle \n","    between these two points with respect to a vertex (vx, vy). The result is \n","    always an acute angle (less than or equal to 90 degrees).\n","\n","    Parameters:\n","    - x1, y1: Coordinates of the first point.\n","    - vx, vy: Coordinates of the vertex.\n","    - x2, y2: Coordinates of the second point.\n","\n","    Returns:\n","    - float: The acute angle (in degrees) between the two points with the vertex as the reference.\n","    '''\n","    ang = math.degrees(math.atan2(y2 - vy, x2 - vx) - math.atan2(y1 - vy, x1 - vx))\n","    # adjust the angle to be between 0 and 180 degrees\n","    ang = abs(ang) % 360\n","    if ang > 180:\n","        return 360 - ang\n","    else:\n","        return ang\n","\n","\n","def plot_triangle(hoop, defender, offensive_player, angle):\n","    # load the images\n","    court_image = Image.open('/images/court_dims.png')\n","\n","    # plot the basketball court\n","    plt.figure(figsize=(10, 5))\n","    plt.imshow(court_image, extent=[0, 94, 0, 50])  # Extent based on court dimensions\n","    \n","    # plot hoop, defender, and offensive player\n","    plt.plot(hoop[0], hoop[1], 'ro', label='Hoop')\n","    plt.plot(defender[0], defender[1], 'go', label='Defender')\n","    plt.plot(offensive_player[0], offensive_player[1], 'bo', label='Offensive Player')\n","\n","    # connect lines to form the triangle\n","    plt.plot([defender[0], hoop[0]], [defender[1], hoop[1]], 'r--')\n","    plt.plot([defender[0], offensive_player[0]], [defender[1], offensive_player[1]], 'b--')\n","\n","    # add angle text\n","    angle_text = f'Angle: {angle:.2f} degrees'\n","    plt.text(defender[0], defender[1], angle_text, ha='right', va='bottom', fontsize=12)\n","\n","    plt.xlabel('X-coordinate')\n","    plt.ylabel('Y-coordinate')\n","    plt.legend()\n","    plt.title('Triangle Visualization')\n","    plt.axis('equal')\n","    plt.show()\n","    \n","# Example 1: Offensive player in front of the defender (good position for a rebound)\n","hoop = (90, 25)\n","defender = (70, 40)\n","offensive_player = (75, 45)\n","angle = calculate_angle(hoop[0], hoop[1], defender[0], defender[1], offensive_player[0], offensive_player[1])\n","plot_triangle(hoop, defender, offensive_player, angle)\n","\n","# Example 2: Offensive player behind the defender (good position for the offensive player)\n","hoop = (90, 25)\n","defender = (70, 40)\n","offensive_player = (68, 30)\n","angle = calculate_angle(hoop[0], hoop[1], defender[0], defender[1], offensive_player[0], offensive_player[1])\n","plot_triangle(hoop, defender, offensive_player, angle)\n","\n","# # Example 3: Offensive player to the left of the defender\n","# hoop = (90, 25)\n","# defender = (70, 40)\n","# offensive_player = (65, 45)\n","# angle = calculate_angle(hoop[0], hoop[1], defender[0], defender[1], offensive_player[0], offensive_player[1])\n","# plot_triangle(hoop, defender, offensive_player, angle)\n","\n","# # Example 4: Offensive player to the right of the defender\n","# hoop = (90, 25)\n","# defender = (70, 40)\n","# offensive_player = (75, 35)\n","# angle = calculate_angle(hoop[0], hoop[1], defender[0], defender[1], offensive_player[0], offensive_player[1])\n","# plot_triangle(hoop, defender, offensive_player, angle)"]},{"cell_type":"markdown","metadata":{},"source":["#### Rebounding Angles and Their Implications:\n","\n","In our visual analysis, we've delineated the dynamics of offensive and defensive player positioning:\n","\n","1. *Offensive Advantage with Lower Angles:* As the angle decreases, the offensive player is in a more favorable position to secure a rebound. A lower angle signifies the offensive player is in front of their defender and positioned to have a clear path to the ball.\n","\n","2. *Defensive Dominance with Higher Angles:* Conversely, a higher angle hints at the defensive player's ability to successfully box out their assignment. The greater the angle, the more likely the defensive player can impede the offensive player's path to the rebound.\n","\n","3. *Relevance of Distance Between Players:* The distance between the players is another important factor in the likelihood of a successful boxout. If the defender is closer, they may be less likely to get juked as they can more easily close the gap and initiate contact.\n","\n","4. *Feature Engineering Potential:* Understanding these angles and distances and their implications provides a strong foundation for crafting impactful features that can boost the model's predictive capability.\n","\n","Features to include: \n","- Angle with defense as vertex (hoop defender shooter)\n","- Distance between defenders and offensive players\n","- Area of the triangle formed by off/def/hoop\n","\n","Considerations for boxout angle, offensive rebounding relationship: Generally speaking, if the defender is between his man and the basket, that player is more likely to get the rebound. This may not necessarily hold true in situations up close to the basket. There is such thing as being too deep under the basket because the ball will usually bounce at least a few feet off the rim. If an offensive player is right on their back, they may be in a more opportune position to get the rebound."]},{"cell_type":"markdown","metadata":{},"source":["#### Cleaning Paired Player Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:51:39.300294Z","iopub.status.busy":"2023-09-01T19:51:39.299803Z","iopub.status.idle":"2023-09-01T19:51:39.455921Z","shell.execute_reply":"2023-09-01T19:51:39.454996Z","shell.execute_reply.started":"2023-09-01T19:51:39.300251Z"},"trusted":true},"outputs":[],"source":["# creating binary shooter column\n","def_training_data['shooter'] = def_training_data['annotation_code_off'].apply(lambda x: 1 if x == 's' else 0)\n","def_testing_data['shooter'] = def_testing_data['annotation_code_off'].apply(lambda x: 1 if x == 's' else 0)\n","# calculating hoop coordinates\n","def_training_data['hoop_x'] = def_training_data['which_hoop'].apply(lambda x: 90 if x == 1 else 4)\n","def_training_data['hoop_y'] = 25\n","def_testing_data['hoop_x'] = def_testing_data['which_hoop'].apply(lambda x: 90 if x == 1 else 4)\n","def_testing_data['hoop_y'] = 25"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualizing Shooter Angles"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:51:41.492601Z","iopub.status.busy":"2023-09-01T19:51:41.491095Z","iopub.status.idle":"2023-09-01T19:51:41.785214Z","shell.execute_reply":"2023-09-01T19:51:41.783654Z","shell.execute_reply.started":"2023-09-01T19:51:41.492555Z"},"trusted":true},"outputs":[],"source":["# Dummy data\n","shooter_x = np.random.rand() * 94\n","shooter_y = np.random.rand() * 50\n","rebounder_x = np.random.rand() * 94\n","rebounder_y = np.random.rand() * 50\n","\n","hoop_y = 25  # center of the court\n","hoop_x = 90 if shooter_x > 47 else 4\n","\n","angle_shooter_rebounder = calculate_angle(shooter_x, shooter_y, hoop_x, hoop_y, rebounder_x, rebounder_y)\n","\n","# plotting\n","plt.figure(figsize=(10, 5))\n","plt.imshow(court_image, extent=[0, 94, 0, 50]) \n","plt.xlim(0, 94)\n","plt.ylim(0, 50)\n","\n","# plot positions\n","plt.scatter([shooter_x, rebounder_x], [shooter_y, rebounder_y], color=['red', 'blue'])\n","plt.scatter(hoop_x, hoop_y, color='black', s=100)\n","\n","# annotate points\n","plt.text(shooter_x + 2, shooter_y, 'Shooter', fontsize=12)\n","plt.text(rebounder_x - 6.5, rebounder_y, 'Rebounder', fontsize=12)\n","plt.text(hoop_x + 2, hoop_y, 'Hoop', fontsize=12)\n","\n","# draw lines to visualize the angle\n","plt.plot([shooter_x, hoop_x], [shooter_y, hoop_y], 'r--')\n","plt.plot([rebounder_x, hoop_x], [rebounder_y, hoop_y], 'b--')\n","\n","# display the angle\n","plt.text(hoop_x + 8, hoop_y, f'Angle: {angle_shooter_rebounder:.2f} degrees', fontsize=12)\n","\n","plt.title('Angle Between Shooter, Hoop, and Rebounder')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Shooter Angles and Their Implications\n","There are several important angles to understand when it comes to the shooter's position.\n","\n","1. *Angle from shooter to the hoop to the rebounder*:\n","\n","Missed shots bounce randomly off the rim, however there is a general tendency for shots to bounce to the weakside (or with an equal and opposite force). In terms of physics, the behavior of a basketball rebounding off the rim can be understood through the principle of angle of incidence equalling angle of reflection. This is particularly true in nearly elastic collisions, where the ball's angle of approach to the rim will generally match its angle of departure. Having that said, a larger angle may make the rebounder more likely to obtain a rebound, depending on where the shot is taken from. From the corner, the larger angle may be desirable, while from straight-on a smaller angle may be desirable.\n","\n","2. *Angle from shooter to hoop to mid-court*:\n","\n","This angle will capture whether a shot is in the corner or in front of the rim. Higher amounts of players near the basket on the weakside for a corner shot may lead to a better offensive rebounding chance. Weakside presence may conversely be less important for a shot from the top of the key.\n","\n","3. *Feature Engineering Potential:*\n","\n","Understanding these angles will help us engineer features that capture where the ball is likely to bounce based on where it is shot on the court.\n","\n","Features to include: \n","- Angle from shooter to hoop to rebounder\n","- Angle from shooter to hoop to mid-court\n","- Sum of weakside off/def players within 10 feet of the basket\n","- Binary corner variable"]},{"cell_type":"markdown","metadata":{},"source":["## **Feature Descriptions for Basketball Analytics in Offensive Rebounding Prediction**\n","In basketball analytics, the calculation of player dynamics on the court helps teams make informed decisions. With the goal of capturing these dynamics, we delve into various features representing player interactions, positions, and game moments.\n","\n","#### Distances\n","- `def_distance_to_hoop`: Distance from each defensive player to the hoop.  \n","  - **Significance**: Defender distances influence over defensive rebounding success is highly dependent on the relative positioning of offensive players.\n","\n","- `off_distance_to_hoop`: Distance from each offensive player to the hoop.  \n","  - **Significance**: Players closer to the hoop are more likely to successfully rebound.\n","\n","- `distance_def_off`: Euclidean distance between defensive and offensive players.  \n","  - **Significance**: Greater distance may offer offensive players more room to secure a rebound or evade a defender's boxout attempt.\n","\n","- `shot_distance`: Distance from the shooter to the hoop.  \n","  - **Significance**: Longer shots generally lead to longer rebounds, affecting who is likely to retrieve them.\n","\n","- `distance_def_shooter`: Distance from each defensive player to the shooter.  \n","  - **Significance**: Defensive players closer to the shooter may be less likely to secure a rebound due to momentum away from the hoop.\n","\n","#### Geometric Features\n","- `triangle_area`: Area of the triangle formed by the shooter, defender, and an offensive player.  \n","  - **Significance**: Larger areas might indicate more space for offensive players to maneuver for a rebound.\n","\n","- `off_spacing`: Area formed by offensive players around the hoop.\n","  - **Significance**: More area could indicate the offense is further from the hoop and the floor is well spaced.\n","  \n","- `def_spacing`: Area formed by defensive players around the hoop.\n","  - **Significance**: More area could indicate better spacing, leaving the defense vulnerable to long rebounds.\n","\n","#### Angles\n","- `shooter_angle`: Angle formed by the shooter, the basket, and mid-court.\n","  - **Significance**: The shooter's angle will inform where the best positioning will be to secure a rebound\n","\n","- `rebound_angle_defense`, `rebound_angle_offense`: Angle between each defensive player, the basket, and the shooter.  \n","  - **Significance**: Depending on the shooter's angle, the size of the angle will determine the best rebound position (large angles are good for corner shots that will more often bounce to the weakside).\n","\n","- `degrees_from_optimal_angle_defense`, `degrees_from_optimal_angle_offense`: Difference in degrees for a players location and the ball's path for an equal and opposite angle from the shooter.  \n","  - **Significance**: Players along the optimal angle will be more likely to have the ball bounce towards them.\n","\n","#### Interaction Features\n","- `dist_interaction`: Combines `def_distance_to_hoop` and `distance_def_off`.  \n","  - **Significance**: An interaction term that may capture nuanced spatial relationships affecting rebounding chances.\n","\n","#### Zone Information\n","- `zone_def`: Zone where the defensive player is during the shot.\n","  - One of three values: opposite (45 degrees surrounding optimal angle), front-rim (the ball is more likely to hit the front rim and bounce back towards the shooter), or no-man's-land (player is in neither zone).\n","  - https://grantland.com/features/how-rebounds-work/#:~:text=As%20you%20can%20see%2C%20more,just%20beyond%20the%20restricted%20area.\n","  - **Significance**: Being in an optimal zone may offer better chances to secure a rebound.\n","\n","- `zone_off`: Similar to `zone_def`, but for offensive players.  \n","  - **Significance**: Offensive players in optimal zones may have a higher chance of rebounding.\n","\n","#### Positioning and Count Metrics\n","- `def_within_10ft`, `off_within_10ft`, `def_within_10ft_weakside`, `off_within_10ft_weakside`, `weakside_diff`:\n","  - **Significance**: These features indicate player positioning relative to the hoop and could influence rebound outcomes.\n","\n","- `def_front_rim_10ft_count`, `off_front_rim_10ft_count`, `def_opposite_10ft_count`, `off_opposite_10ft_count`:\n","  - **Significance**: Metrics are more specific than weak/strong side.\n","\n","#### Box-out Metrics\n","- `boxout_position`, `log_boxout_angle`, `contextual_boxout_position`:  \n","  - **Significance**: These features quantify how effectively players are positioned for box-outs, a crucial part of rebounding.\n","  - *Boxout Position Feature:* The positioning during a boxout is vital for securing rebounds. The formula used for `boxout_position` is:\n","  $$ \\text{Boxout Position} = \\log_{10}\\left( \\text{off\\_distance\\_to\\_hoop}^{1.35} + \\text{boxout\\_angle} \\right) $$\n","\n","  The exponentiation of `off_distance_to_hoop` aims to prioritize the distance of an offensive player to the basket. This indicates that the further the offensive player is from the basket, the higher their potential to successfully box out. The exponent value `1.35` was derived after iterative experimentation for optimal model performance.\n","\n","  - *Log Transformed Features:* To normalize and capture non-linear relationships, features like `boxout_angle` are log-transformed. This helps in stabilizing the variance and making the data more suitable for machine learning models.\n","\n","\n","#### Aggregate Features\n","These are generated based on the groupby on 'id', and they provide aggregated metrics for most of the above features for each play.\n","  - **Significance**: Aggregate features can encapsulate the general behavior or tendency of players or events, providing a macro view that can be predictive.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:51:44.312444Z","iopub.status.busy":"2023-09-01T19:51:44.311871Z","iopub.status.idle":"2023-09-01T19:51:44.353215Z","shell.execute_reply":"2023-09-01T19:51:44.351002Z","shell.execute_reply.started":"2023-09-01T19:51:44.312380Z"},"trusted":true},"outputs":[],"source":["# distance function\n","def calculate_dist(x1, y1, x2, y2):\n","    return np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","\n","# function to calculate area of a triangle\n","def triangle_area(x1, y1, x2, y2, x3, y3):\n","    return 0.5 * abs(x1*(y2-y3) + x2*(y3-y1) + x3*(y1-y2))\n","\n","def angle_from_sideline(player_x, player_y, hoop_x, hoop_y):\n","    # calculate the angle using the hoop as the vertex\n","    sideline = [hoop_x, 0]  # x-coordinate of hoop and 0 for y (sideline)\n","    return calculate_angle(sideline[0], sideline[1], hoop_x, hoop_y, player_x, player_y)\n","\n","def determine_zone(player_x, player_y, shooter_x, shooter_y, hoop_x, hoop_y):\n","    # calculate the angle of the shot with respect to the hoop and baseline\n","    shot_angle = angle_from_sideline(shooter_x, shooter_y, hoop_x, hoop_y)\n","    \n","    # invert the shot's y value to get the opposite direction\n","    opposite_angle = angle_from_sideline(shooter_x, 50 - shooter_y, hoop_x, hoop_y)\n","    \n","    # calculate player's angle with respect to the hoop and baseline\n","    player_angle = angle_from_sideline(player_x, player_y, hoop_x, hoop_y)\n","    \n","    # calculate the bounds for the optimal region (45-degree slice)\n","    left_bound_optimal = (opposite_angle - 22.5) % 360\n","    right_bound_optimal = (opposite_angle + 22.5) % 360\n","\n","    # check if player is in the optimal region\n","    if left_bound_optimal < right_bound_optimal:\n","        if left_bound_optimal <= player_angle <= right_bound_optimal:\n","            return 'opposite'\n","    else:  # If the optimal region wraps around the 0/360 boundary\n","        if player_angle >= left_bound_optimal or player_angle <= right_bound_optimal:\n","            return 'opposite'\n","    \n","    # calculate the bounds for the second optimal region (22.5 degrees to the left and right of shooter)\n","    left_bound_second_optimal = (shot_angle - 22.5) % 360\n","    right_bound_second_optimal = (shot_angle + 22.5) % 360\n","\n","    # check if player is in the second optimal region\n","    if left_bound_second_optimal < right_bound_second_optimal:\n","        if left_bound_second_optimal <= player_angle <= right_bound_second_optimal:\n","            return 'front-rim'\n","    else:  # if the second optimal region wraps around the 0/360 boundary\n","        if player_angle >= left_bound_second_optimal or player_angle <= right_bound_second_optimal:\n","            return 'front-rim'\n","\n","    # if player is not in any of the optimal regions\n","    return 'no-mans-land'\n","\n","def calc_dist_angle_features(the_data):\n","    data = the_data.copy()\n","    # calculate player distances to the hoop\n","    data['def_distance_to_hoop'] = data.apply(lambda x: calculate_dist(x.def_x, x.def_y, x.hoop_x, x.hoop_y), axis=1)\n","    data['off_distance_to_hoop'] = data.apply(lambda x: calculate_dist(x.off_x, x.off_y, x.hoop_x, x.hoop_y), axis=1)\n","\n","    # distances between players\n","    data['distance_def_off'] = data.apply(lambda x: calculate_dist(x.def_x, x.def_y, x.off_x, x.off_y), axis=1)\n","\n","    # shooter coordinates for each play\n","    shooter_coords = data[data['shooter'] == 1][['id', 'off_x', 'off_y']].set_index('id')\n","\n","    # shot distance\n","    data['shot_distance'] = data.apply(lambda x: calculate_dist(x.hoop_x, x.hoop_y, shooter_coords.loc[x['id'], 'off_x'], shooter_coords.loc[x['id'], 'off_y']), axis=1)\n","\n","    # calculating the distance of each defensive player to the shooter\n","    data['distance_def_shooter'] = data.apply(lambda x: calculate_dist(x.def_x, x.def_y, shooter_coords.loc[x['id'], 'off_x'], shooter_coords.loc[x['id'], 'off_y']), axis=1)\n","\n","    # area of triangle formed by shooter, defender, and offensive player\n","    data['triangle_area'] = data.apply(lambda x: triangle_area(x.def_x, x.def_y, x.off_x, x.off_y, shooter_coords.loc[x['id'], 'off_x'], shooter_coords.loc[x['id'], 'off_y']), axis=1)\n","\n","    # angle between each player the basket and the shooter\n","    data['rebound_angle_defense'] = data.apply(lambda x: calculate_angle(shooter_coords.loc[x['id'], 'off_x'], shooter_coords.loc[x['id'], 'off_y'], x.hoop_x, x.hoop_y, x.def_x, x.def_y), axis=1)\n","    data['rebound_angle_offense'] = data.apply(lambda x: calculate_angle(shooter_coords.loc[x['id'], 'off_x'], shooter_coords.loc[x['id'], 'off_y'], x.hoop_x, x.hoop_y, x.off_x, x.off_y), axis=1)\n","\n","    # angle formed by the basket the defender and their assigned box out responsibility\n","    data['boxout_angle'] = data.apply(lambda x: calculate_angle(x.hoop_x, x.hoop_y, x.def_x, x.def_y, x.off_x, x.off_y), axis=1)\n","\n","    # interaction features\n","    data['dist_interaction'] = data['def_distance_to_hoop'] * data['distance_def_off']\n","\n","    # feature to decide how many players are within 10 feet of the hoop\n","    data['def_within_10ft'] = data['def_distance_to_hoop'] < 10\n","    data['off_within_10ft'] = data['off_distance_to_hoop'] < 10\n","\n","    # features to help better understand where the shot is taken from\n","    data['shooter_angle'] = data.apply(lambda x: calculate_angle(shooter_coords.loc[x['id'], 'off_x'], shooter_coords.loc[x['id'], 'off_y'], x.hoop_x, 25, 47, 25), axis=1)\n","    data['corner'] = data.apply(lambda x: 1 if x['shooter_angle'] > 45 else 0, axis=1)\n","\n","    # calculating the optimal rebound angle, hypothesized to be the weakside at the same angle from mid court\n","    data['optimal_angle'] = data.apply(lambda x: calculate_angle(shooter_coords.loc[x['id'], 'off_x'], 50 - shooter_coords.loc[x['id'], 'off_y'], x.hoop_x, 25, 47, 25), axis=1)\n","\n","    data['degrees_from_optimal_angle_offense'] = data.apply(lambda x: calculate_angle(shooter_coords.loc[x['id'], 'off_x'], 50 - shooter_coords.loc[x['id'], 'off_y'], x.hoop_x, 25, x.off_x, x.off_y), axis=1)\n","    data['degrees_from_optimal_angle_defense'] = data.apply(lambda x: calculate_angle(shooter_coords.loc[x['id'], 'off_x'], 50 - shooter_coords.loc[x['id'], 'off_y'], x.hoop_x, 25, x.def_x, x.def_y), axis=1)\n","\n","    # feature to decide how many players are within 10 feet on the opposit side of the court as the shot is taken (56% of missed shots will bounce to the weak side)\n","    data['shooter_top_half'] = data.apply(lambda x: shooter_coords.loc[x['id'], 'off_y'] > 25, axis=1) \n","    data['def_within_10ft_weakside'] = (data['def_distance_to_hoop'] < 10) & \\\n","                                  np.where(data['shooter_top_half'], data['def_y'] < 25, data['def_y'] > 25)\n","    data['off_within_10ft_weakside'] = (data['off_distance_to_hoop'] < 10) & \\\n","                                  np.where(data['shooter_top_half'], data['off_y'] < 25, data['off_y'] > 25)\n","\n","    data['def_within_10ft_weakside'] = data['def_within_10ft_weakside'].apply(int)\n","    data['off_within_10ft_weakside'] = data['off_within_10ft_weakside'].apply(int)\n","    \n","    data['weakside_diff'] = data['def_within_10ft_weakside'] - data['off_within_10ft_weakside']\n","    data.drop(columns='shooter_top_half', inplace=True)\n","\n","    # boxout position calculation\n","    data['boxout_position'] = np.log10((data['off_distance_to_hoop']**1.35) + (data['boxout_angle']))\n","\n","    # categorizing rebound positioning based on shot angle\n","    data['zone_def'] = data.apply(lambda x: determine_zone(x.def_x, x.def_y, shooter_coords.loc[x['id'], 'off_x'], shooter_coords.loc[x['id'], 'off_y'], x.hoop_x, 25), axis=1)\n","    data['zone_off'] = data.apply(lambda x: determine_zone(x.off_x, x.off_y, shooter_coords.loc[x['id'], 'off_x'], shooter_coords.loc[x['id'], 'off_y'], x.hoop_x, 25), axis=1)\n","\n","    # log transformation\n","    data['log_boxout_angle'] = np.log1p(data['boxout_angle'])\n","\n","    # boxout position with relevativity of positioning to the shot\n","    data['contextual_boxout_position'] = data['boxout_position'] * np.log1p(data['degrees_from_optimal_angle_offense'])\n","\n","    # aggregate features\n","    agg_funcs = ['mean', 'min', 'max', 'std']\n","\n","    agg_dict = {'def_distance_to_hoop': agg_funcs, 'distance_def_off': agg_funcs, 'off_distance_to_hoop': agg_funcs, 'distance_def_shooter': agg_funcs, 'betweenness_centrality': ['mean', 'max', 'std'], \n","                                        'def_within_10ft': ['sum'], 'off_within_10ft': ['sum'], 'def_within_10ft_weakside': ['sum'], 'off_within_10ft_weakside': ['sum'], 'shooter_angle': ['max'], 'corner': ['max'], 'boxout_angle': agg_funcs, \n","                                        'boxout_position': agg_funcs, 'weakside_diff': ['sum'], 'log_boxout_angle': agg_funcs, 'contextual_boxout_position': agg_funcs, 'degrees_from_optimal_angle_offense': agg_funcs,\n","                                        'degrees_from_optimal_angle_defense': agg_funcs, 'shot_distance': ['mean']}\n","\n","    # aggregate data\n","    aggregates = data.groupby('id').agg(agg_dict)\n","\n","    # flatten the multi-level column index\n","    aggregates.columns = ['_'.join(col).strip() for col in aggregates.columns.values]\n","\n","    # merge aggregate features with original data\n","    data = data.merge(aggregates, on='id')\n","    return data, agg_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:51:45.046901Z","iopub.status.busy":"2023-09-01T19:51:45.046537Z","iopub.status.idle":"2023-09-01T19:51:45.057271Z","shell.execute_reply":"2023-09-01T19:51:45.054669Z","shell.execute_reply.started":"2023-09-01T19:51:45.046876Z"},"trusted":true},"outputs":[],"source":["def calculate_angle_spacing(x1, y1, vx, vy, x2, y2):\n","    ang = math.degrees(math.atan2(y2 - vy, x2 - vx) - math.atan2(y1 - vy, x1 - vx))\n","    \n","    if (vx == 4 and x1 < 4):\n","        if (y1 < 25):\n","            return ang + 360\n","        return ang\n","    elif (vx == 90 and x1 > 90):\n","        if (y1 > 25):\n","            return ang + 360\n","        return ang\n","\n","    # adjust for negative angles\n","    if ang < 0:\n","        ang += 360\n","    \n","    elif ang > 180:\n","        ang = 360 - ang\n","    return ang"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:51:45.738739Z","iopub.status.busy":"2023-09-01T19:51:45.738216Z","iopub.status.idle":"2023-09-01T19:51:45.748448Z","shell.execute_reply":"2023-09-01T19:51:45.746250Z","shell.execute_reply.started":"2023-09-01T19:51:45.738702Z"},"trusted":true},"outputs":[],"source":["def shoelace_area(coords):\n","    n = len(coords)\n","    area = 0.0\n","\n","    for i in range(n):\n","        j = (i + 1) % n\n","        area += coords[i][0] * coords[j][1]\n","        area -= coords[j][0] * coords[i][1]\n","\n","    area = abs(area) / 2.0\n","    return area"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:51:46.421324Z","iopub.status.busy":"2023-09-01T19:51:46.420459Z","iopub.status.idle":"2023-09-01T19:51:46.430813Z","shell.execute_reply":"2023-09-01T19:51:46.428434Z","shell.execute_reply.started":"2023-09-01T19:51:46.421298Z"},"trusted":true},"outputs":[],"source":["def sort_clockwise(coords, hoop):\n","    \"\"\"sort coordinates in clockwise order based on a centroid.\"\"\"\n","    sideline = [hoop[0], 0]  # x-coordinate of hoop and 0 for y\n","    return sorted(coords, key=lambda coord: calculate_angle_spacing(coord[0], coord[1], hoop[0], 25, sideline[0], sideline[1]))\n","\n","def hexagon_area(df, offense):\n","    column_name = 'off' if offense else 'def'\n","    coords = [(df[f'{column_name}_x'].iloc[i], df[f'{column_name}_y'].iloc[i]) for i in range(5)]\n","\n","    # centroid is the hoop position\n","    centroid = (df['hoop_x'].iloc[0], df['hoop_y'].iloc[0])\n","\n","    # sort coordinates clockwise around the hoop (centroid)\n","    coords = sort_clockwise(coords, centroid)\n","\n","    # append hoop position to the end\n","    coords.append(centroid)\n","\n","    return shoelace_area(coords)"]},{"cell_type":"markdown","metadata":{},"source":["This cell takes ~2 mins to run."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:51:48.894076Z","iopub.status.busy":"2023-09-01T19:51:48.893679Z","iopub.status.idle":"2023-09-01T19:54:32.796463Z","shell.execute_reply":"2023-09-01T19:54:32.795260Z","shell.execute_reply.started":"2023-09-01T19:51:48.894043Z"},"trusted":true},"outputs":[],"source":["def_training_data_with_feats, agg_dict_ = calc_dist_angle_features(def_training_data)\n","def_testing_data_with_feats, agg_dict_test = calc_dist_angle_features(def_testing_data)"]},{"cell_type":"markdown","metadata":{},"source":["This cell takes ~1 minute to run."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:55:19.402268Z","iopub.status.busy":"2023-09-01T19:55:19.401880Z","iopub.status.idle":"2023-09-01T19:56:24.965208Z","shell.execute_reply":"2023-09-01T19:56:24.962473Z","shell.execute_reply.started":"2023-09-01T19:55:19.402231Z"},"trusted":true},"outputs":[],"source":["def compute_aggregated_values(group):\n","    return pd.Series({\n","        'def_front_rim_10ft_count': ((group['zone_def'] == 'front-rim') & group['def_within_10ft']).sum(),\n","        'off_front_rim_10ft_count': ((group['zone_off'] == 'front-rim') & group['off_within_10ft']).sum(),\n","        'def_opposite_10ft_count': ((group['zone_def'] == 'opposite') & group['def_within_10ft']).sum(),\n","        'off_opposite_10ft_count': ((group['zone_off'] == 'opposite') & group['off_within_10ft']).sum()\n","    })\n","\n","players_in_relevant_areas = def_training_data_with_feats.groupby('id').apply(compute_aggregated_values).reset_index()\n","players_in_relevant_areas_test = def_testing_data_with_feats.groupby('id').apply(compute_aggregated_values).reset_index()"]},{"cell_type":"markdown","metadata":{},"source":["#### Calculating Spacing of Offense and Defense\n","- Inspired by ShotQuality's Twitter, I use the area created by each team (and the hoop) as a feature that captures spacing."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def calculate_spacing(data):\n","    play_ids = data['id'].unique()\n","    def_areas_dict_ = {}\n","    off_areas_dict_ = {}\n","\n","    for play in play_ids:\n","        play_df = data[data['id'] == play]\n","        def_areas_dict_[play] = hexagon_area(play_df, 0)\n","        off_areas_dict_[play] = hexagon_area(play_df, 1)\n","    return def_areas_dict_, off_areas_dict_"]},{"cell_type":"markdown","metadata":{},"source":["These cells take ~6 minutes to run. CSV is provided for convenience."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if RUN_CELL:\n","    def_areas_dict, off_areas_dict = calculate_spacing(def_training_data)\n","    def_areas_dict_test, off_areas_dict_test = calculate_spacing(def_testing_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[" if RUN_CELL:\n","    off_spacing = pd.DataFrame(list(off_areas_dict.items()), columns=['id', 'off_spacing'])\n","    def_spacing = pd.DataFrame(list(def_areas_dict.items()), columns=['id', 'def_spacing'])\n","    off_spacing_test = pd.DataFrame(list(off_areas_dict_test.items()), columns=['id', 'off_spacing'])\n","    def_spacing_test = pd.DataFrame(list(def_areas_dict_test.items()), columns=['id', 'def_spacing'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# off_spacing.to_csv('data/off_spacing.csv', index=False)\n","# def_spacing.to_csv('data/def_spacing.csv', index=False)\n","# off_spacing_test.to_csv('data/off_spacing_test.csv', index=False)\n","# def_spacing_test.to_csv('data/def_spacing_test.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:03:42.020368Z","iopub.status.busy":"2023-09-01T20:03:42.019964Z","iopub.status.idle":"2023-09-01T20:03:42.122671Z","shell.execute_reply":"2023-09-01T20:03:42.120967Z","shell.execute_reply.started":"2023-09-01T20:03:42.020335Z"},"trusted":true},"outputs":[],"source":["off_spacing = pd.read_csv('/data/off_spacing.csv')\n","def_spacing = pd.read_csv('/data/def_spacing.csv')\n","off_spacing_test = pd.read_csv('/data/off_spacing_test.csv')\n","def_spacing_test = pd.read_csv('/data/def_spacing_test.csv')"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualizing Spacing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:03:52.595780Z","iopub.status.busy":"2023-09-01T20:03:52.595447Z","iopub.status.idle":"2023-09-01T20:03:53.017519Z","shell.execute_reply":"2023-09-01T20:03:53.015606Z","shell.execute_reply.started":"2023-09-01T20:03:52.595757Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","# sample data\n","df = pd.DataFrame(def_training_data[def_training_data.id == '2-2'])\n","\n","# load the images\n","court_image = Image.open('/images/court_dims.png')\n","\n","# plot the basketball court\n","plt.figure(figsize=(10, 5))\n","plt.imshow(court_image, extent=[0, 94, 0, 50])  # Extent based on court dimensions\n","\n","# plotting the defender coordinates\n","plt.scatter(df['off_x'], df['off_y'], color='blue', label='Offense')\n","plt.scatter(df['def_x'], df['def_y'], color='red', label='Defenders')\n","\n","coords = [(df['off_x'].iloc[i], df['off_y'].iloc[i]) for i in range(5)]\n","def_coords = [(df['def_x'].iloc[i], df['def_y'].iloc[i]) for i in range(5)]\n","\n","# centroid is the hoop position\n","centroid = (df['hoop_x'].iloc[0], df['hoop_y'].iloc[0])\n","\n","# sort coordinates clockwise around the hoop (centroid)\n","coords = sort_clockwise(coords, centroid)\n","def_coords = sort_clockwise(def_coords, centroid)\n","\n","# centroid is the hoop position\n","centroid = (df['hoop_x'].iloc[0], df['hoop_y'].iloc[0])\n","\n","coords.append(centroid)\n","\n","def_coords.append(centroid)\n","\n","df_off = pd.DataFrame(coords, columns=['x', 'y'])\n","df_def = pd.DataFrame(def_coords, columns=['x', 'y'])\n","\n","# connect defenders with lines\n","# since we want to connect the defenders in a loop (5th to 1st), \n","# we create an extended list where the first defender is also at the end\n","offense_xs = df_off['x'].tolist() + [df_off['x'].iloc[0]]\n","offense_ys = df_off['y'].tolist() + [df_off['y'].iloc[0]]\n","defender_xs = df_def['x'].tolist() + [df_def['x'].iloc[0]]\n","defender_ys = df_def['y'].tolist() + [df_def['y'].iloc[0]]\n","\n","for i in range(len(df_off)):\n","    plt.plot([defender_xs[i], defender_xs[i+1]], [defender_ys[i], defender_ys[i+1]], color='gray')\n","for i in range(len(df_def)):\n","    plt.plot([offense_xs[i], offense_xs[i+1]], [offense_ys[i], offense_ys[i+1]], color='gray')\n","\n","shooter_row = df[df['annotation_code_off'] == 's'].iloc[0]\n","plt.scatter(shooter_row['off_x'], shooter_row['off_y'], color='green', marker='x', s=100, label='Shooter')\n","\n","plt.xlabel('X-coordinate')\n","plt.ylabel('Y-coordinate')\n","plt.title('Defender Positions and Connections on Basketball Court')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Spacing Calculation Logic\n","- Each player for a team is sorted by their angle to the baseline.\n","- Once sorted clockwise, the hoop connects to the first player, the first player connects to the second player, etc., etc. until a hexagon is formed.\n","- The area of this hexagon is calculated to provide an estimate of the spacing on the court.\n","- When the defense is spaced out, there are more lanes for offensive rebounders to attack."]},{"cell_type":"markdown","metadata":{},"source":["## **Pivoting the DataFrame for Player Insights**\n","\n","When analyzing basketball plays, understanding the spatial distribution of players on the court can provide significant insights. The position of each player, especially during key moments like a shot or potential rebound, can have an impact on the outcome of that play. Here, we're looking to pivot our dataframe to better capture and analyze the dynamics of each play.\n","\n","#### Player-Specific Features\n","- *Individual Player Features:* We want to capture each player's metrics independently. By sorting our data by the 'boxout_position', we ensure that, for each play, the most crucial offensive player (based on their boxout position) is consistently placed in the same column. This consistency is pivotal in reducing data noise and ensuring the features of the most pivotal player always align across plays. The most important player serces as an anchor to uphold permutation invariant sorting (Mehrasa). https://www.cs.sfu.ca/~mori/research/papers/mehrasa-sloan18.pdf\n","  \n","  We will achieve this individual representation by:\n","  - Sorting the data by `boxout_position` for each play (identified by `id`). \n","  - Assigning an order for each player pairing on the court for every play. This provides a consistent ordering mechanism.\n","\n","#### Aggregated Features for Court Positioning\n","To get a comprehensive view of the players' positioning, we're looking to generate aggregated features. These features will allow us to understand the overall dynamics of player positioning for each play, giving us metrics that are holistic rather than player-specific. For instance:\n","- *Mean:* Averages could tell us the typical distance between players or from the hoop, providing insights into defensive or offensive strategies.\n","- *Max/Min:* These could highlight outlier player positions which might be key strategic placements.\n","- *Standard Deviation (std):* This can show us how spread out players are. A high standard deviation might indicate a more scattered formation, while a low one could suggest a tighter, possibly defensive cluster.\n","- *Sum:* This can be particularly useful when looking at metrics like total players within 10 feet.\n","\n","By analyzing these aggregated features in conjunction with individual player metrics, we can gain a deeper understanding of team strategies, player importance, and play dynamics, allowing for more informed game analysis and decision-making.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:03:59.879260Z","iopub.status.busy":"2023-09-01T20:03:59.878790Z","iopub.status.idle":"2023-09-01T20:03:59.890002Z","shell.execute_reply":"2023-09-01T20:03:59.888676Z","shell.execute_reply.started":"2023-09-01T20:03:59.879231Z"},"trusted":true},"outputs":[],"source":["def pivot_plays(data, agg_dict):\n","    # first, sort the data by 'boxout_position' for each play (id)\n","    # this will help reduce noise in the dataset, the most important offensive player will always be in the same column and correspond to other features\n","    data = data.sort_values(by=['id', 'boxout_position']).reset_index(drop=True)\n","    \n","    # create a new column for pairing number (1,2,3,...) for each play\n","    data['pairing_order'] = data.groupby('id').cumcount() + 1\n","    \n","    # extract all the feature columns\n","    feature_cols = [\n","        'betweenness_centrality', 'def_distance_to_hoop', 'boxout_angle', 'dist_interaction', 'distance_def_off', 'distance_def_shooter', 'off_distance_to_hoop',\n","        'rebound_angle_defense', 'rebound_angle_offense', 'triangle_area', 'boxout_position', 'log_boxout_angle', 'contextual_boxout_position', 'degrees_from_optimal_angle_offense',\n","        'degrees_from_optimal_angle_defense'\n","    ]\n","    \n","    # pivot the dataframe based on the feature columns\n","    pivoted_data = data.pivot_table(index='id', columns='pairing_order', values=feature_cols, aggfunc='first')\n","\n","    # flatten the multi-level column index\n","    pivoted_data.columns = ['_'.join(map(str, col)).strip() for col in pivoted_data.columns.values]\n","\n","\n","    agg_cols = []\n","    for col, funcs in agg_dict.items():\n","        for func in funcs:\n","            agg_cols.append(f\"{col}_{func}\")\n","    # extract the aggregate columns\n","    aggregates = data.drop_duplicates(subset='id')[['id'] + agg_cols]\n","\n","    # merge the aggregate columns with the pivoted data\n","    result = pivoted_data.reset_index().merge(aggregates, on='id', how='left')\n","    \n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:00.897371Z","iopub.status.busy":"2023-09-01T20:04:00.897024Z","iopub.status.idle":"2023-09-01T20:04:01.564590Z","shell.execute_reply":"2023-09-01T20:04:01.562518Z","shell.execute_reply.started":"2023-09-01T20:04:00.897348Z"},"trusted":true},"outputs":[],"source":["# pivoting the data, so there is one record per play\n","def_pivoted = pivot_plays(def_training_data_with_feats, agg_dict_)\n","def_pivoted_test = pivot_plays(def_testing_data_with_feats, agg_dict_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:01.567191Z","iopub.status.busy":"2023-09-01T20:04:01.566813Z","iopub.status.idle":"2023-09-01T20:04:01.664517Z","shell.execute_reply":"2023-09-01T20:04:01.661549Z","shell.execute_reply.started":"2023-09-01T20:04:01.567162Z"},"trusted":true},"outputs":[],"source":["# merging spacing data\n","def_pivoted = def_pivoted.merge(off_spacing, on='id')\n","def_pivoted = def_pivoted.merge(def_spacing, on='id')\n","def_pivoted_test = def_pivoted_test.merge(off_spacing_test, on='id')\n","def_pivoted_test = def_pivoted_test.merge(def_spacing_test, on='id')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:01.745230Z","iopub.status.busy":"2023-09-01T20:04:01.744081Z","iopub.status.idle":"2023-09-01T20:04:01.794771Z","shell.execute_reply":"2023-09-01T20:04:01.792870Z","shell.execute_reply.started":"2023-09-01T20:04:01.745120Z"},"trusted":true},"outputs":[],"source":["# merging info about how many players are in advantageous regions for the given shot\n","def_pivoted = def_pivoted.merge(players_in_relevant_areas, on='id')\n","def_pivoted_test = def_pivoted_test.merge(players_in_relevant_areas_test, on='id')"]},{"cell_type":"markdown","metadata":{},"source":["## **Refining the Features**"]},{"cell_type":"markdown","metadata":{},"source":["#### Frequency Distributions for Features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:03.657878Z","iopub.status.busy":"2023-09-01T20:04:03.657383Z","iopub.status.idle":"2023-09-01T20:04:03.711739Z","shell.execute_reply":"2023-09-01T20:04:03.709234Z","shell.execute_reply.started":"2023-09-01T20:04:03.657842Z"},"trusted":true},"outputs":[],"source":["def_pivoted_copy = def_pivoted.merge(train_pbp[['id', 'is_oreb']], on='id')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:04.050591Z","iopub.status.busy":"2023-09-01T20:04:04.049976Z","iopub.status.idle":"2023-09-01T20:04:05.806461Z","shell.execute_reply":"2023-09-01T20:04:05.803661Z","shell.execute_reply.started":"2023-09-01T20:04:04.050546Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import matplotlib.colors as mcolors\n","\n","def plot_frequency_distributions(df, columns_to_plot, bin_size=None, text_rotation=90):\n","    for column in columns_to_plot:\n","        plt.figure(figsize=(10, 6))\n","\n","        if bin_size:\n","            binned_column = pd.cut(df[column], bins=np.arange(0, max(df[column]) + 2 * bin_size, bin_size), right=False)\n","            counts = df.groupby(binned_column).size()\n","            max_count = counts.max()\n","            palette = {bin: mcolors.to_hex(plt.get_cmap('coolwarm')(count / max_count)) for bin, count in counts.items()}\n","\n","            ax = sns.barplot(x=binned_column, y=df['is_oreb'], ci=None, palette=palette)\n","            \n","            # add legend for color-to-sample-size mapping\n","            norm = plt.Normalize(counts.min(), counts.max())\n","            sm = plt.cm.ScalarMappable(cmap=\"coolwarm\", norm=norm)\n","            sm.set_array([])\n","            plt.colorbar(sm, orientation='vertical', label='Sample Size')\n","            \n","            # add sample size text annotation\n","            for idx, p in enumerate(ax.patches):\n","                height = p.get_height()\n","                if pd.notnull(height):  # check for NaN\n","                    ax.text(p.get_x() + p.get_width()/2., height, f'n={counts.iloc[idx]}', fontsize=12, ha='center', va='bottom', rotation=text_rotation)\n","            \n","            # customize x-axis ticks\n","            bin_starts = [int(interval.left) for interval in counts.index.categories]\n","            bin_ends = [int(interval.right) for interval in counts.index.categories]\n","            all_ticks = bin_starts + [bin_ends[-1]]\n","            plt.xticks(np.arange(len(all_ticks)), all_ticks, rotation=45)\n","            \n","        else:\n","            ax = sns.barplot(x=column, y='is_oreb', data=df, ci=None)\n","        \n","        plt.title(f'Offensive Rebound Percentage vs {column}')\n","        plt.xlabel(f'{column} (Binned into {bin_size} units)' if bin_size else column)\n","        plt.ylabel('Offensive Rebound Percentage')\n","        plt.tight_layout()\n","        plt.show()\n","\n","\n","# list of columns to plot\n","columns_to_plot = ['closest_off_to_hoop', 'second_closest_off_to_hoop', 'third_closest_off_to_hoop']\n","\n","# call the function with a bin size of 2\n","plot_frequency_distributions(df_encoded_train_3bins, columns_to_plot, bin_size=2)"]},{"cell_type":"markdown","metadata":{},"source":["#### Offensive Rebound % vs Distance to Hoop Analysis\n","- When the second and third closest offensive players are within 8 feet, there is a significantly better chance of an offensive rebound (`39.28%`, `52.43%` respectively).\n","- The third closest player being less than 8 feet from the hoop obviously implies there are three offensive players within 8 feet which indicates a positional advantage.\n","- When the third closest player is within 8 feet, the offense actually has the advantage in retreiving the rebound in a 386 play sample.\n","- In looking at the entirety of the training data, there does not appear to be a disadvantage to being too close to the hoop; let's plot frequency distributions using only long range shots."]},{"cell_type":"markdown","metadata":{},"source":["#### Long Range Shot Distance to Hoop Frequency Distribution"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:06.725997Z","iopub.status.busy":"2023-09-01T20:04:06.725480Z","iopub.status.idle":"2023-09-01T20:04:08.515278Z","shell.execute_reply":"2023-09-01T20:04:08.512935Z","shell.execute_reply.started":"2023-09-01T20:04:06.725949Z"},"trusted":true},"outputs":[],"source":["plot_frequency_distributions(df_encoded_train_3bins.loc[df_encoded_train_5bins['shot_distance_zone_21+'] == 1], columns_to_plot, bin_size=2)"]},{"cell_type":"markdown","metadata":{},"source":["#### Long Range Shot Frequency Distribution Analysis\n","- Evident in the closest player visual, it does appear that a player can be too close to the rim.\n","- There is a greater offensive rebounding percentage when the nearest offensive player to the hoop is 4-6 feet from the hoop (n=1970) than when they are less than 4 feet from the hoop (n=693)."]},{"cell_type":"markdown","metadata":{},"source":["#### Number of Defenders Closer than X Closest Offensive Player"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:08.699795Z","iopub.status.busy":"2023-09-01T20:04:08.699260Z","iopub.status.idle":"2023-09-01T20:04:08.707498Z","shell.execute_reply":"2023-09-01T20:04:08.706313Z","shell.execute_reply.started":"2023-09-01T20:04:08.699754Z"},"trusted":true},"outputs":[],"source":["player_dists = df_encoded_train_3bins.copy()\n","player_dists_test = df_encoded_test_3bins.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:09.456346Z","iopub.status.busy":"2023-09-01T20:04:09.455896Z","iopub.status.idle":"2023-09-01T20:04:14.368116Z","shell.execute_reply":"2023-09-01T20:04:14.365955Z","shell.execute_reply.started":"2023-09-01T20:04:09.456314Z"},"trusted":true},"outputs":[],"source":["def count_closer_def_players(row, off_col):\n","    def_cols = ['closest_def_to_hoop', 'second_closest_def_to_hoop', 'third_closest_def_to_hoop', 'fourth_closest_def_to_hoop', 'fifth_closest_def_to_hoop']\n","    return sum(row[def_col] < row[off_col] for def_col in def_cols)\n","\n","player_dists['num_def_closer_than_closest_off'] = player_dists.apply(lambda row: count_closer_def_players(row, 'closest_off_to_hoop'), axis=1)\n","player_dists['num_def_closer_than_second_closest_off'] = player_dists.apply(lambda row: count_closer_def_players(row, 'second_closest_off_to_hoop'), axis=1)\n","player_dists['num_def_closer_than_third_closest_off'] = player_dists.apply(lambda row: count_closer_def_players(row, 'third_closest_off_to_hoop'), axis=1)\n","player_dists_test['num_def_closer_than_closest_off'] = player_dists_test.apply(lambda row: count_closer_def_players(row, 'closest_off_to_hoop'), axis=1)\n","player_dists_test['num_def_closer_than_second_closest_off'] = player_dists_test.apply(lambda row: count_closer_def_players(row, 'second_closest_off_to_hoop'), axis=1)\n","player_dists_test['num_def_closer_than_third_closest_off'] = player_dists_test.apply(lambda row: count_closer_def_players(row, 'third_closest_off_to_hoop'), axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualizing Frequency Distribution of Number of Defenders Closer than the Nearest Offensive Player to the Hoop"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:14.373280Z","iopub.status.busy":"2023-09-01T20:04:14.372111Z","iopub.status.idle":"2023-09-01T20:04:15.402624Z","shell.execute_reply":"2023-09-01T20:04:15.400693Z","shell.execute_reply.started":"2023-09-01T20:04:14.373225Z"},"trusted":true},"outputs":[],"source":["plot_frequency_distributions(player_dists, ['num_def_closer_than_closest_off', 'num_def_closer_than_second_closest_off', 'num_def_closer_than_third_closest_off'], bin_size=1, text_rotation=0)"]},{"cell_type":"markdown","metadata":{},"source":["\n","#### Number of Defenders Closer Frequency Distribution Analysis\n","- The charts make it clear that this is a good feature to keep. Basically, if there are fewer defensive players near the hoop compared to offensive players, the chances for an offensive rebound go up.\n","- In a small set of data (n=26), there's a `34%` chance of an offensive rebound when no defenders are closer to the hoop than the nearest offensive player. This is actually lower than when defenders are closer to the hoop than the third closest offensive player.\n","- This tells us we need to look more closely at these plays. We want to make sure our assumption that the shooter is shooting at the basket they are closest to holds true."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:15.405314Z","iopub.status.busy":"2023-09-01T20:04:15.404873Z","iopub.status.idle":"2023-09-01T20:04:15.418569Z","shell.execute_reply":"2023-09-01T20:04:15.416067Z","shell.execute_reply.started":"2023-09-01T20:04:15.405285Z"},"trusted":true},"outputs":[],"source":["outlier_non_offensive_rebounds = player_dists[(player_dists['num_def_closer_than_third_closest_off'] == 0) & (player_dists['is_oreb'] == 0)].id"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:35:13.222574Z","iopub.status.busy":"2023-09-01T20:35:13.222173Z","iopub.status.idle":"2023-09-01T20:35:13.640703Z","shell.execute_reply":"2023-09-01T20:35:13.639039Z","shell.execute_reply.started":"2023-09-01T20:35:13.222548Z"},"trusted":true},"outputs":[],"source":["# Sample data\n","df = def_training_data[def_training_data.id == '1419-4']\n","\n","# Load the images\n","court_image = Image.open('/images/court_dims.png')\n","\n","# Plot the basketball court\n","plt.figure(figsize=(10, 5))\n","plt.imshow(court_image, extent=[0, 94, 0, 50])  # Extent based on court dimensions\n","\n","\n","# Plotting the coordinates and connecting the pairs of players with lines\n","plt.scatter(df['off_x'], df['off_y'], color='blue', label='Offensive Players')\n","plt.scatter(df['def_x'], df['def_y'], color='red', label='Defenders')\n","\n","# Connect the pairs of players with lines\n","for i, row in df.iterrows():\n","    plt.plot([row['off_x'], row['def_x']], [row['off_y'], row['def_y']], color='gray', linestyle='dotted')\n","\n","shooter_row = df[df['annotation_code_off'] == 's'].iloc[0]\n","plt.scatter(shooter_row['off_x'], shooter_row['off_y'], color='green', marker='x', s=100, label='Shooter')\n","\n","plt.xlabel('X-coordinate')\n","plt.ylabel('Y-coordinate')\n","plt.title('Coordinates and Connections on Basketball Court')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Assessing the Potential Outlier\n","- Play `1419-4` appears to be a standard play where the player is shooting at the hoop nearest them.\n","- Though the offense is seemingly in great position for a rebound, the defenders' momentum may tell a different story.\n","- It is possible that the player behind the shooter blocks the shot, or the ball could have simply taken a funny bounce.\n","- Upon visualizing a few other such plays, they seem to be plausible court circumstances for defensive rebounds. The small sample does not represent the expected behavior.\n","- Gotta make wide open layups - maybe they were celebrating too early? https://www.youtube.com/watch?v=Zmz0qQp4OmI"]},{"cell_type":"markdown","metadata":{},"source":["#### Distinguishing Fast Breaks"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:49:08.342920Z","iopub.status.busy":"2023-09-01T20:49:08.342500Z","iopub.status.idle":"2023-09-01T20:49:08.882454Z","shell.execute_reply":"2023-09-01T20:49:08.881379Z","shell.execute_reply.started":"2023-09-01T20:49:08.342886Z"},"trusted":true},"outputs":[],"source":["sns.set_style(\"whitegrid\")\n","plt.figure(figsize=(10, 6))\n","\n","# histogram for the 'def_distance_mean' column\n","sns.histplot(def_pivoted['def_distance_to_hoop_max'], bins=30, kde=True)\n","\n","plt.title('Frequency Distribution of def_distance_to_hoop_max')\n","plt.xlabel('def_distance_max')\n","plt.ylabel('Frequency')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Criteria for Identifying Fast Breaks\n","- On a standard half court position with a set defense, the maximum defender distance from the basket likely not exceed 25 feet.\n","- `2066` out of the `30805` training examples have a defensive player greater than 25 feet from the basket.\n","- We deduce that these scenarios likely represent fast breaks. Thus, we'll use the 25-foot criteria from the basket as our benchmark to classify plays as fast breaks."]},{"cell_type":"markdown","metadata":{},"source":["#### Distinguishing Irregular Shots"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:49:13.424500Z","iopub.status.busy":"2023-09-01T20:49:13.424115Z","iopub.status.idle":"2023-09-01T20:49:13.954912Z","shell.execute_reply":"2023-09-01T20:49:13.952709Z","shell.execute_reply.started":"2023-09-01T20:49:13.424474Z"},"trusted":true},"outputs":[],"source":["sns.set_style(\"whitegrid\")\n","plt.figure(figsize=(10, 6))\n","\n","# histogram for the 'def_distance_mean' column\n","sns.histplot(def_pivoted['shooter_angle_max'], bins=30, kde=True)\n","\n","plt.title('Frequency Distribution of shooter_angle')\n","plt.xlabel('shooter_angle')\n","plt.ylabel('Frequency')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:15.566040Z","iopub.status.busy":"2023-09-01T20:04:15.565565Z","iopub.status.idle":"2023-09-01T20:04:15.590109Z","shell.execute_reply":"2023-09-01T20:04:15.589117Z","shell.execute_reply.started":"2023-09-01T20:04:15.566007Z"},"trusted":true},"outputs":[],"source":["len(def_pivoted[def_pivoted.shooter_angle_max > 92.5])"]},{"cell_type":"markdown","metadata":{},"source":["#### Criteria for Irregular Shots\n","\n","- *Behind the Basket*: Shots where the shooter angles exceed 90 degrees are considered to be taken from behind the basket.\n","- *Characteristics*: While these shots up to a certain point may resemble standard shots in terms of possibly hitting the rim or even scoring, they are inherently more challenging and atypical.\n","- *Data Insight*: Out of the training dataset, there are 58 instances where the shooter angle is greater than 92.5 degrees.\n","- *Feature Engineering*: Introducing a binary feature named `irregular_shot` could assist models in better handling these outliers.\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Distinguishing Corner Shots\n","- In this visualization, we will compare the offensive rebounding percentage for different shooting angles with and without weakside offensive rebounders.\n","    - The 'difference' in the chart is referring to:\n","        - OREB% with 1+ offensive player within 10 ft of the basket on the weakside minus OREB% with 0 offensive player within 10 ft of the basket on the weakside.\n","\n","    \n","- This will help us understand how weakside rebounder presence contributes to offensive rebounding success for shots from different areas of the court."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:17.113980Z","iopub.status.busy":"2023-09-01T20:04:17.113655Z","iopub.status.idle":"2023-09-01T20:04:17.492638Z","shell.execute_reply":"2023-09-01T20:04:17.491617Z","shell.execute_reply.started":"2023-09-01T20:04:17.113957Z"},"trusted":true},"outputs":[],"source":["def_pivoted_copy = def_pivoted[def_pivoted.shooter_angle_max < 90].merge(train_pbp[['id', 'is_oreb']], on='id')\n","\n","# bin the shooter angle\n","def_pivoted_copy['shooter_angle_bin'] = pd.cut(def_pivoted_copy['shooter_angle_max'], bins=4)  # 9 bins\n","\n","# calculate median for weakside rebounders\n","median_weakside = def_pivoted_copy['off_within_10ft_weakside_sum'].median()\n","\n","# assign 'high' or 'low' based on the median\n","def_pivoted_copy['weakside_label'] = def_pivoted_copy['off_within_10ft_weakside_sum'].apply(lambda x: 'high' if x > median_weakside else 'low')\n","\n","# calculate offensive rebound percentage for each combination\n","grouped = def_pivoted_copy.groupby(['shooter_angle_bin', 'weakside_label'])\n","rebound_pct = grouped['is_oreb'].mean()\n","\n","# calculate the difference between 'high' and 'low' for each bin\n","rebound_diff = rebound_pct.unstack().apply(lambda x: x['high'] - x['low'], axis=1)\n","\n","# plot\n","fig, ax = plt.subplots(figsize=(10,6))\n","rebound_diff.plot(kind='bar', ax=ax, color='skyblue')\n","ax.set_title(\"Difference in Offensive Rebound Percentage by Shooter Angle with and without Weakside Off Rebounders within 10 Feet\")\n","ax.set_xlabel(\"Shooter Angle Bin\")\n","ax.set_ylabel(\"Difference in Offensive Rebound Percentage\")\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:17.523262Z","iopub.status.busy":"2023-09-01T20:04:17.521890Z","iopub.status.idle":"2023-09-01T20:04:17.533457Z","shell.execute_reply":"2023-09-01T20:04:17.531782Z","shell.execute_reply.started":"2023-09-01T20:04:17.523181Z"},"trusted":true},"outputs":[],"source":["# median of 0\n","median_weakside"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:17.752449Z","iopub.status.busy":"2023-09-01T20:04:17.751925Z","iopub.status.idle":"2023-09-01T20:04:17.764576Z","shell.execute_reply":"2023-09-01T20:04:17.762476Z","shell.execute_reply.started":"2023-09-01T20:04:17.752390Z"},"trusted":true},"outputs":[],"source":["# more instances without an offensive player on the weakside within 10 feet than with\n","def_pivoted_copy['off_within_10ft_weakside_sum'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["#### Key Takeaways from Shooter Angle Frequency Distribution\n","- Having weakside defensive rebounders for shots with greater shooting angles appears to improve the chances of an offensive rebound.\n","- This validates the assumption about the ball's path being most likely to continue at an equal opposite angle from its release."]},{"cell_type":"markdown","metadata":{},"source":["### Adding Features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:18.891711Z","iopub.status.busy":"2023-09-01T20:04:18.891191Z","iopub.status.idle":"2023-09-01T20:04:20.314876Z","shell.execute_reply":"2023-09-01T20:04:20.313075Z","shell.execute_reply.started":"2023-09-01T20:04:18.891672Z"},"trusted":true},"outputs":[],"source":["# creating behind_basket Column\n","def_pivoted['behind_basket'] = def_pivoted.apply(lambda x: 1 if x.shooter_angle_max > 92.5 else 0, axis=1)\n","def_pivoted_test['behind_basket'] = def_pivoted_test.apply(lambda x: 1 if x.shooter_angle_max > 92.5 else 0, axis=1)\n","# creating Fastbreak Probable Column\n","def_pivoted['Fastbreak Probable'] = def_pivoted.apply(lambda x: 1 if x.def_distance_to_hoop_max > 25 else 0, axis=1)\n","def_pivoted_test['Fastbreak Probable'] = def_pivoted_test.apply(lambda x: 1 if x.def_distance_to_hoop_mean > 25 else 0, axis=1)\n","def_pivoted = def_pivoted.merge(player_dists[['id', 'num_def_closer_than_closest_off', 'num_def_closer_than_second_closest_off', 'num_def_closer_than_third_closest_off']], on='id')\n","def_pivoted_test = def_pivoted_test.merge(player_dists_test[['id', 'num_def_closer_than_closest_off', 'num_def_closer_than_second_closest_off', 'num_def_closer_than_third_closest_off']], on='id')"]},{"cell_type":"markdown","metadata":{},"source":["#### Assessing the Impact of Weakside Rebounders\n","When analyzing the role of weakside rebounders, two key insights emerge:\n","\n","- Dependency on Shooter's Angle: As the angle of the shot increases, the influence of weakside rebounders appears to escalate.\n","\n","- Corner vs. Wing Shots: The data indicates that shots taken from the corner are more prone to bounce towards the weak side when compared to shots from the wing. It emphasizes the strategic importance of weakside positioning, especially during corner shots."]},{"cell_type":"markdown","metadata":{},"source":["#### Checking Correlations between Features and Offensive Rebounding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:55:01.315780Z","iopub.status.busy":"2023-09-01T20:55:01.315395Z","iopub.status.idle":"2023-09-01T20:55:02.305710Z","shell.execute_reply":"2023-09-01T20:55:02.302781Z","shell.execute_reply.started":"2023-09-01T20:55:01.315752Z"},"trusted":true},"outputs":[],"source":["def_pivoted_copy.corr()['is_oreb'].sort_values(ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["#### Insights on Correlation to Offensive Rebounding\n","\n","*Positive Correlations:*\n","\n","1. `off_within_10ft_sum` (0.138):\n","This feature has the strongest positive correlation with offensive rebounding. It suggests that the higher the number of offensive players within 10 feet of the basket, the more likely an offensive rebound will occur.\n","\n","2. `boxout_angle_std` (0.107):\n","The standard deviation of boxout angles has a positive correlation with offensive rebounds. A higher standard deviation might indicate variability in openings for the offense to get in rebounding position, possibly making it easier for the offense to grab rebounds.\n","\n","3. `betweenness_centrality_5` (0.101):\n","This is often 0 and defensive rebounds are more common. Let's eliminate betweenness_centrality_4-5 before modeling.\n","\n","4. `boxout_position_std` (0.100):\n","Similar to the `boxout_angle_std`, the variability in boxout positioning is positively correlated with offensive rebounds. Greater variability might indicate disorganization in the defense, benefiting the offense.\n","\n","*Negative Correlations:*\n","\n","1. `boxout_position_mean` (-0.140):\n","The average boxout position has the strongest negative correlation. This is a sign that boxout_position may be a strong predictor of offensive rebounding.\n","\n","2. `boxout_angle_mean` (-0.135):\n","The average boxout angle being negatively correlated suggests that certain angles are less effective for defensive players when trying to prevent offensive rebounds.\n","\n","3. `boxout_position_2` (-0.135):\n","The second player's boxout location seems to play a pivotal role in offensive rebounding.\n","\n","4. `log_boxout_angle_mean` (-0.124):\n","The logarithm of the average boxout angle also shows a negative correlation.\n","\n","\n","*General Insights:*\n","\n","- The presence of offensive players close to the basket (`off_within_10ft_sum`) is a crucial factor in offensive rebounding. It emphasizes the importance of positioning near the hoop during shots.\n","  \n","- Defensive positioning is vital in preventing offensive rebounds. Variabilities in boxout angles and positions might indicate a disorganized defense, which seems to favor the offense in terms of rebounding."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:21.293804Z","iopub.status.busy":"2023-09-01T20:04:21.293283Z","iopub.status.idle":"2023-09-01T20:04:21.314460Z","shell.execute_reply":"2023-09-01T20:04:21.311576Z","shell.execute_reply.started":"2023-09-01T20:04:21.293771Z"},"trusted":true},"outputs":[],"source":["# dropping these columns because they are commonly 0 and may correlate with offensive rebounding\n","def_pivoted.drop(columns=['betweenness_centrality_4', 'betweenness_centrality_5'], inplace=True)\n","def_pivoted_test.drop(columns=['betweenness_centrality_4', 'betweenness_centrality_5'], inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:21.317805Z","iopub.status.busy":"2023-09-01T20:04:21.317294Z","iopub.status.idle":"2023-09-01T20:04:21.333894Z","shell.execute_reply":"2023-09-01T20:04:21.331486Z","shell.execute_reply.started":"2023-09-01T20:04:21.317717Z"},"trusted":true},"outputs":[],"source":["def_pivoted['diff_spacing'] = def_pivoted['off_spacing'] - def_pivoted['def_spacing']\n","def_pivoted_test['diff_spacing'] = def_pivoted_test['off_spacing'] - def_pivoted_test['def_spacing']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:21.467657Z","iopub.status.busy":"2023-09-01T20:04:21.467285Z","iopub.status.idle":"2023-09-01T20:04:21.478627Z","shell.execute_reply":"2023-09-01T20:04:21.476887Z","shell.execute_reply.started":"2023-09-01T20:04:21.467631Z"},"trusted":true},"outputs":[],"source":["def_pivoted['diff_distance'] = def_pivoted['off_distance_to_hoop_mean'] - def_pivoted['def_distance_to_hoop_mean']\n","def_pivoted_test['diff_distance'] = def_pivoted_test['off_distance_to_hoop_mean'] - def_pivoted_test['def_distance_to_hoop_mean']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:22.453614Z","iopub.status.busy":"2023-09-01T20:04:22.453156Z","iopub.status.idle":"2023-09-01T20:04:22.551697Z","shell.execute_reply":"2023-09-01T20:04:22.550191Z","shell.execute_reply.started":"2023-09-01T20:04:22.453584Z"},"trusted":true},"outputs":[],"source":["def_pivoted.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:23.118875Z","iopub.status.busy":"2023-09-01T20:04:23.118209Z","iopub.status.idle":"2023-09-01T20:04:23.127971Z","shell.execute_reply":"2023-09-01T20:04:23.126513Z","shell.execute_reply.started":"2023-09-01T20:04:23.118844Z"},"trusted":true},"outputs":[],"source":["def_pivoted['shooter_is_closest'] = (def_pivoted['shot_distance_mean'] == def_pivoted['off_distance_to_hoop_min']).astype(int)\n","def_pivoted_test['shooter_is_closest'] = (def_pivoted_test['shot_distance_mean'] == def_pivoted_test['off_distance_to_hoop_min']).astype(int)"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["# **Model Experimentation**"]},{"cell_type":"markdown","metadata":{},"source":["#### **Scaling the Data**\n","- Once again, we fit the scaler on the training set and use the same scaler on the test set"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:24.710237Z","iopub.status.busy":"2023-09-01T20:04:24.709730Z","iopub.status.idle":"2023-09-01T20:04:24.848725Z","shell.execute_reply":"2023-09-01T20:04:24.846507Z","shell.execute_reply.started":"2023-09-01T20:04:24.710199Z"},"trusted":true},"outputs":[],"source":["# create a StandardScaler object\n","scaler = StandardScaler()\n","\n","# extract the continuous features from the DataFrame\n","ids_train = def_pivoted[['id', 'corner_max', 'Fastbreak Probable', 'behind_basket', 'shooter_is_closest']] # id and the one categorical feature\n","ids_test = def_pivoted_test[['id', 'corner_max', 'Fastbreak Probable', 'behind_basket', 'shooter_is_closest']]\n","\n","continuous_features = def_pivoted.drop(columns=['id', 'corner_max', 'Fastbreak Probable', 'behind_basket', 'shooter_is_closest'])\n","continuous_features_test = def_pivoted_test.drop(columns=['id', 'corner_max', 'Fastbreak Probable', 'behind_basket', 'shooter_is_closest'])\n","\n","# fit and transform the continuous features using the StandardScaler\n","scaled_continuous_features = scaler.fit_transform(continuous_features)\n","scaled_continuous_features_test = scaler.transform(continuous_features_test)\n","\n","# convert the scaled_continuous_features back to a DataFrame with the original column names\n","scaled_continuous_df = pd.DataFrame(scaled_continuous_features, columns=continuous_features.columns)\n","scaled_continuous_df_test = pd.DataFrame(scaled_continuous_features_test, columns=continuous_features_test.columns)\n","\n","# concatenate the scaled continuous features with the categorical features)\n","normalized_df = pd.concat([ids_train, scaled_continuous_df], axis=1)\n","normalized_df_test = pd.concat([ids_test, scaled_continuous_df_test], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:25.244111Z","iopub.status.busy":"2023-09-01T20:04:25.243582Z","iopub.status.idle":"2023-09-01T20:04:25.262113Z","shell.execute_reply":"2023-09-01T20:04:25.261021Z","shell.execute_reply.started":"2023-09-01T20:04:25.244063Z"},"trusted":true},"outputs":[],"source":["# dropping repeat columns\n","normalized_df.drop(columns=['def_distance_to_hoop_mean', 'off_distance_to_hoop_mean'], inplace=True)\n","normalized_df_test.drop(columns=['def_distance_to_hoop_mean', 'off_distance_to_hoop_mean'], inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:25.572243Z","iopub.status.busy":"2023-09-01T20:04:25.571858Z","iopub.status.idle":"2023-09-01T20:04:25.656506Z","shell.execute_reply":"2023-09-01T20:04:25.655513Z","shell.execute_reply.started":"2023-09-01T20:04:25.572215Z"},"trusted":true},"outputs":[],"source":["combined_datasets_3 = normalized_df.merge(X_dist_3bins, on='id', how='inner')\n","combined_datasets_test_3 = normalized_df_test.merge(X_test_dist_3bins, on='id', how='inner')\n","combined_datasets_5 = normalized_df.merge(X_dist_5bins, on='id', how='inner')\n","combined_datasets_test_5 = normalized_df_test.merge(X_test_dist_5bins, on='id', how='inner')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:25.908362Z","iopub.status.busy":"2023-09-01T20:04:25.907965Z","iopub.status.idle":"2023-09-01T20:04:25.954270Z","shell.execute_reply":"2023-09-01T20:04:25.953318Z","shell.execute_reply.started":"2023-09-01T20:04:25.908334Z"},"trusted":true},"outputs":[],"source":["X_3 = combined_datasets_3.drop(columns=['id', 'is_oreb'])\n","X_5 = combined_datasets_5.drop(columns=['id', 'is_oreb'])\n","X_3_holdout = combined_datasets_test_3.drop(columns=['id'])\n","X_5_holdout = combined_datasets_test_5.drop(columns=['id'])\n","y = combined_datasets_3['is_oreb']\n","y_cnn = combined_datasets_3[['id', 'is_oreb']]\n","holdout_ids = combined_datasets_test_3['id']"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Choices for the Project\n","\n","For this project, our goal is to effectively predict offensive rebounding events, a task that requires careful consideration of numerous variables and their interactions. To ensure a comprehensive approach and increase the likelihood of accurate predictions, we've selected three diverse and robust models:\n","\n","1. **XGBoost**: XGBoost, or Extreme Gradient Boosting, is a gradient boosting framework that builds on the principle of boosting weak learners. It's known for its efficiency and ability to handle a large set of features, especially when there are complex interactions between them. It also provides a regularized framework, which can help prevent overfitting.\n","\n","2. **RandomForestClassifier**: This ensemble method uses a 'forest' of decision trees, each trained on random subsets of the data and features, ensuring diversity in its predictions. Its ability to capture non-linear relationships, as well as feature interactions, makes it especially valuable for our problem. Additionally, RandomForest offers the benefit of interpretability through feature importance rankings.\n","\n","3. **Logistic Regression**: Though it might seem like a simple choice, Logistic Regression offers powerful benefits. It's a linear model that's particularly effective when relationships are somewhat linear or when we want to establish a baseline model. It's also very interpretable, as the coefficients can provide insights into the importance and directionality of each feature. \n","\n","By leveraging the diverse strengths of these models, we aim to capture the multifaceted nature of our prediction task. Whether it's the interpretability of Logistic Regression, the non-linear capturing capabilities of RandomForest, or the fine-tuned precision of XGBoost, each model brings unique value to our project.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:27.217584Z","iopub.status.busy":"2023-09-01T20:04:27.217199Z","iopub.status.idle":"2023-09-01T20:04:27.222483Z","shell.execute_reply":"2023-09-01T20:04:27.221569Z","shell.execute_reply.started":"2023-09-01T20:04:27.217558Z"},"trusted":true},"outputs":[],"source":["def cross_val_model_score(model, X_, y_):\n","    #perform cross-validation\n","    cross_val_scores = cross_val_score(model, X_, y_, cv=5, scoring='neg_log_loss')\n","\n","    # since cross_val_score returns negative log loss values, we take the negative to get the positive log loss\n","    log_loss_scores = -cross_val_scores\n","    return log_loss_scores.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:04:28.428435Z","iopub.status.busy":"2023-09-01T20:04:28.427475Z","iopub.status.idle":"2023-09-01T20:04:28.436783Z","shell.execute_reply":"2023-09-01T20:04:28.433934Z","shell.execute_reply.started":"2023-09-01T20:04:28.428385Z"},"trusted":true},"outputs":[],"source":["def evaluate_models(models_dict, X, y):\n","    \"\"\"\n","    Evaluates a dictionary of models using cross-validation.\n","\n","    Parameters:\n","    - models_dict: Dictionary with model name as key and model object as value\n","    - X: Feature matrix\n","    - y: Target variable\n","\n","    Returns:\n","    - DataFrame with models as rows and their corresponding log loss scores\n","    \"\"\"\n","    results = {}\n","    for name, model in models_dict.items():\n","        results[name] = cross_val_model_score(model, X, y)\n","\n","    # convert dictionary to DataFrame\n","    results_df = pd.DataFrame.from_dict(results, orient='index', columns=['Log Loss'])\n","\n","    return results_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T22:07:03.805369Z","iopub.status.busy":"2023-09-01T22:07:03.804789Z","iopub.status.idle":"2023-09-01T22:07:03.812521Z","shell.execute_reply":"2023-09-01T22:07:03.811507Z","shell.execute_reply.started":"2023-09-01T22:07:03.805318Z"},"trusted":true},"outputs":[],"source":["# XGB model score \n","# The hyperparameters have been tuned already; this cell is used for feature engineering experimentation\n","if RUN_CELL:\n","    cross_val_model_score(xgb.XGBClassifier(learning_rate=0.065, n_estimators=112, objective='binary:logistic', \n","                              eval_metric='logloss', max_depth=3, min_child_weight=5), X_3, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T22:07:06.236192Z","iopub.status.busy":"2023-09-01T22:07:06.235606Z","iopub.status.idle":"2023-09-01T22:07:06.242846Z","shell.execute_reply":"2023-09-01T22:07:06.240638Z","shell.execute_reply.started":"2023-09-01T22:07:06.236165Z"},"trusted":true},"outputs":[],"source":["if RUN_CELL:\n","    cross_val_model_score(LogisticRegression(penalty='l1', solver='saga', C=.05, max_iter=200), X_3, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T22:07:07.949795Z","iopub.status.busy":"2023-09-01T22:07:07.949287Z","iopub.status.idle":"2023-09-01T22:07:07.957223Z","shell.execute_reply":"2023-09-01T22:07:07.956045Z","shell.execute_reply.started":"2023-09-01T22:07:07.949766Z"},"trusted":true},"outputs":[],"source":["if RUN_CELL:\n","    cross_val_model_score(RandomForestClassifier(max_depth=8, max_features='auto', min_samples_leaf= 6, min_samples_split=15, n_estimators=200), X_3, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T21:39:01.227852Z","iopub.status.busy":"2023-09-01T21:39:01.227480Z","iopub.status.idle":"2023-09-01T21:44:52.894332Z","shell.execute_reply":"2023-09-01T21:44:52.891456Z","shell.execute_reply.started":"2023-09-01T21:39:01.227825Z"},"trusted":true},"outputs":[],"source":["models = {\n","    'XGBoost': xgb.XGBClassifier(learning_rate=0.065, n_estimators=112, objective='binary:logistic', \n","                          eval_metric='logloss', max_depth=3, min_child_weight=5),\n","    'Random Forest': RandomForestClassifier(max_depth=8, max_features='auto', min_samples_leaf= 6, min_samples_split=15, n_estimators=200),\n","    'Logistic Regression': LogisticRegression(penalty='l1', solver='saga', C=.05, max_iter=200)\n","}\n","df_results = evaluate_models(models, X_3, y)\n","print(df_results)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T21:44:52.897328Z","iopub.status.busy":"2023-09-01T21:44:52.896811Z","iopub.status.idle":"2023-09-01T21:44:53.184857Z","shell.execute_reply":"2023-09-01T21:44:53.182828Z","shell.execute_reply.started":"2023-09-01T21:44:52.897299Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(10, 6))\n","df_results['Log Loss'].plot(kind='bar', color=['blue', 'green', 'red'])\n","plt.ylabel('Log Loss')\n","plt.ylim(bottom=.575, top=.585)\n","plt.title('Model Performance Comparison')\n","plt.xticks(rotation=45)\n","plt.grid(axis='y')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Performance Comparison\n","- XGBoost has the best performance by log loss with a score of `.5781`\n","- This represents a significant improvement over the baseline model of `.0028`\n","- Given the capabilities of XGBoost, its top performance aligns with expectations.\n","- The next step will be to explore different hyperparameter combinations for XGB and RFC to improve the predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_submission(ids, preds, num_sub):\n","    submission = pd.DataFrame(ids)\n","    submission['pred'] = preds\n","    submission.to_csv(f'submission{num_sub}.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["## **Tuning Hyperparameters**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T22:07:13.384085Z","iopub.status.busy":"2023-09-01T22:07:13.383509Z","iopub.status.idle":"2023-09-01T22:07:13.391644Z","shell.execute_reply":"2023-09-01T22:07:13.390485Z","shell.execute_reply.started":"2023-09-01T22:07:13.384041Z"},"trusted":true},"outputs":[],"source":["# original parama grid:\n","# param_grid = {\n","#     'max_depth': [2, 3, 4],\n","#     'min_child_weight': [3, 4, 5],\n","#     'n_estimators': [50, 75, 100],\n","#     'learning_rate': [.05, .07, .09]\n","# }\n","if RUN_CELL:\n","    # this parameter grid was constructed after an initial run with the original parameter grid\n","    param_grid = {\n","        'max_depth': [3],\n","        'min_child_weight': [4, 5],\n","        'n_estimators': [87, 100, 112],\n","        'learning_rate': [.045, .055, .06, .065]\n","    }\n","\n","    # create an instance of the XGBClassifier with a fixed learning rate and number of boosting rounds\n","    model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')\n","\n","    # use GridSearchCV to search for the best combination of hyperparameters\n","    grid_search_xgb = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_log_loss', cv=5)\n","    grid_search_xgb.fit(X_3, y)\n","\n","    # get the best hyperparameters from the grid search\n","    best_params = grid_search_xgb.best_params_\n"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### Hyperparameter Optimization Results for XGBoost Classifier\n","\n","After running GridSearch cross-validation, we found the best hyperparameters for our XGBoost model. These are:\n","\n","- `max_depth`: 3\n","- `min_child_weight`: 5\n","\n","This means our model works best with decision trees that go 3 levels deep and have a minimum 'child' weight of 5. Keeping it simple like this helps us prevent overfitting.\n","\n","Here's a summary of our top 10 test scores:\n","\n","| `learning_rate` | `max_depth` | `min_child_weight` | `n_estimators` | `mean_test_score` |\n","|-----------------|-------------|--------------------|----------------|-------------------|\n","| 0.055           | 3           | 5                  | 100            | -0.5783233        |\n","| 0.06            | 3           | 5                  | 87             | -0.5783167        |\n","| 0.055           | 3           | 5                  | 112            | -0.5782977        |\n","| 0.06            | 3           | 5                  | 112            | -0.5782864        |\n","| 0.065           | 3           | 5                  | 100            | -0.5782833        |\n","| 0.055           | 3           | 4                  | 100            | -0.5782600        |\n","| 0.065           | 3           | 5                  | 87             | -0.5782431        |\n","| 0.045           | 3           | 5                  | 112            | -0.5782262        |\n","| 0.055           | 3           | 4                  | 112            | -0.5782046        |\n","| 0.065           | 3           | 5                  | 112            | -0.5781886        |\n","\n","Our selected hyperparameters closely match the settings that gave us the best test scores.\n","\n","---\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T22:08:07.059230Z","iopub.status.busy":"2023-09-01T22:08:07.058873Z","iopub.status.idle":"2023-09-01T22:08:07.067175Z","shell.execute_reply":"2023-09-01T22:08:07.065902Z","shell.execute_reply.started":"2023-09-01T22:08:07.059204Z"},"trusted":true},"outputs":[],"source":["if RUN_CELL:\n","    # hyperparameters to tune\n","    param_grid = {\n","        'n_estimators': [50, 100],  # Number of trees in the forest\n","        'max_depth': [4, 6, 8],  # Maximum depth of the trees\n","        'min_samples_split': [5, 10],  # Minimum number of samples required to split an internal node\n","        'min_samples_leaf': [2, 4],  # Minimum number of samples required to be at a leaf node\n","        'max_features': ['auto', 'sqrt'],  # Number of features to consider when looking for the best split\n","    }\n","\n","\n","    # create an instance of the RandomForestClassifier\n","    model = RandomForestClassifier()\n","\n","    # use GridSearchCV to search for the best combination of hyperparameters\n","    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_log_loss', cv=3, verbose=2, n_jobs=-1)\n","    grid_search.fit(X_3, y)\n","\n","    # get the best hyperparameters from the grid search\n","    best_params = grid_search.best_params_\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T22:08:23.896788Z","iopub.status.busy":"2023-09-01T22:08:23.896058Z","iopub.status.idle":"2023-09-01T22:08:23.906831Z","shell.execute_reply":"2023-09-01T22:08:23.903665Z","shell.execute_reply.started":"2023-09-01T22:08:23.896751Z"},"trusted":true},"outputs":[],"source":["if RUN_CELL:\n","    # hyperparameters to tune\n","    param_grid = {\n","        'n_estimators': [100, 200],  # Number of trees in the forest\n","        'max_depth': [8, 9, 10],  # Maximum depth of the trees\n","        'min_samples_split': [10, 15],  # Minimum number of samples required to split an internal node\n","        'min_samples_leaf': [4, 6, 8],  # Minimum number of samples required to be at a leaf node\n","        'max_features': ['auto']  # Number of features to consider when looking for the best split\n","    }\n","\n","\n","    # create an instance of the RandomForestClassifier\n","    model = RandomForestClassifier()\n","\n","    # use GridSearchCV to search for the best combination of hyperparameters\n","    grid_search_rfc2 = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_log_loss', cv=3, verbose=2, n_jobs=-1)\n","    grid_search_rfc2.fit(X_3, y)\n","\n","    # get the best hyperparameters from the grid search\n","    best_params = grid_search.best_params_\n"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### Hyperparameter Optimization Results for Random Forest Classifier (RFC)\n","\n","We used GridSearch cross-validation again, this time for our Random Forest Classifier. Here's what we found:\n","\n","- `max_depth`: **8**\n","- `max_features`: **'auto'**\n","- `min_samples_leaf`: **4**\n","- `min_samples_split`: **15**\n","- `n_estimators`: **200**\n","\n","Our updated results suggest that deeper trees with a maximum depth of 8 work better for this model. We also optimized other parameters like `min_samples_leaf`, `min_samples_split`, and the number of trees (`n_estimators`).\n","\n","Here's a quick look at the top 10 results:\n","\n","| `max_depth` | `max_features` | `min_samples_leaf` | `min_samples_split` | `n_estimators` | `mean_test_score` |\n","|-------------|----------------|--------------------|---------------------|----------------|-------------------|\n","| 8           | auto           | 4                  | 15                  | 200            | -0.5786333        |\n","| 10          | auto           | 8                  | 15                  | 200            | -0.5786322        |\n","| 8           | auto           | 4                  | 10                  | 200            | -0.5786281        |\n","| 9           | auto           | 4                  | 15                  | 200            | -0.5786052        |\n","| 10          | auto           | 6                  | 10                  | 100            | -0.5785893        |\n","| 10          | auto           | 6                  | 10                  | 200            | -0.5785707        |\n","| 8           | auto           | 8                  | 10                  | 200            | -0.5785330        |\n","| 8           | auto           | 6                  | 10                  | 200            | -0.5785275        |\n","| 9           | auto           | 8                  | 10                  | 200            | -0.5785232        |\n","| 8           | auto           | 6                  | 15                  | 200            | -0.5785012        |\n","\n","The best set of hyperparameters show a `max_depth` of 8, which implies that deeper trees are better at capturing the patterns in our dataset. The other parameters also help to fine-tune the model for better performance, as reflected in the mean test score.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Feature Importance**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T21:19:16.932798Z","iopub.status.busy":"2023-09-01T21:19:16.932233Z","iopub.status.idle":"2023-09-01T21:19:35.945357Z","shell.execute_reply":"2023-09-01T21:19:35.943302Z","shell.execute_reply.started":"2023-09-01T21:19:16.932756Z"},"trusted":true},"outputs":[],"source":["model = xgb.XGBClassifier(learning_rate=0.065, n_estimators=112, objective='binary:logistic', \n","                          eval_metric='logloss', max_depth=3, min_child_weight=5)\n","the_model = model.fit(X_3, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T21:19:35.948498Z","iopub.status.busy":"2023-09-01T21:19:35.948052Z","iopub.status.idle":"2023-09-01T21:19:35.960231Z","shell.execute_reply":"2023-09-01T21:19:35.958536Z","shell.execute_reply.started":"2023-09-01T21:19:35.948460Z"},"trusted":true},"outputs":[],"source":["feat_df = pd.DataFrame({'columns': X_3.columns, 'feat importances': the_model.feature_importances_}).sort_values(by='feat importances', ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T21:33:26.692275Z","iopub.status.busy":"2023-09-01T21:33:26.690728Z","iopub.status.idle":"2023-09-01T21:33:26.709128Z","shell.execute_reply":"2023-09-01T21:33:26.706959Z","shell.execute_reply.started":"2023-09-01T21:33:26.692181Z"},"trusted":true},"outputs":[],"source":["feat_df[:15]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T21:21:22.659925Z","iopub.status.busy":"2023-09-01T21:21:22.659348Z","iopub.status.idle":"2023-09-01T21:21:23.043693Z","shell.execute_reply":"2023-09-01T21:21:23.042467Z","shell.execute_reply.started":"2023-09-01T21:21:22.659894Z"},"trusted":true},"outputs":[],"source":["plot_feat_importances(feat_df['columns'].values[:15], feat_df['feat importances'].values[:15])"]},{"cell_type":"markdown","metadata":{},"source":["### **Feature Importance Analysis**\n","\n","1. **`off_distance_mean`: 0.066**\n","   - This feature, which represents the average distance of offensive players from the hoop, has emerged as the most influential in our model. It underscores the critical role that the proximity of players to the hoop plays in successful rebounds.\n","\n","2. **`boxout_position_mean`: 0.058**\n","   - Coming in second, the average boxout position feature confirms that the positioning of players in relation to their assigned defenders is highly impactful.\n","\n","3. **`second_closest_off_to_hoop`: 0.055**\n","   - This feature signifies the distance of the second closest offensive player to the hoop. It points to the importance of having more than one player near the hoop during plays.\n","\n","4. **`log_boxout_angle_mean`: 0.025**\n","   - The logarithmic mean of boxout angles reveals the significance of the angular positioning between players and possibly hints at non-linear relationships.\n","\n","5. **`off_within_10ft_weakside_sum`: 0.019**\n","   - This feature reflects the sum of offensive players within 10 feet on the weak side of the play, suggesting it has an important role in the model.\n","\n","6. **`off_distance_to_hoop_3`: 0.018**\n","   - The distance of the third closest offensive player to the hoop stresses the importance of not just the primary players, but the surrounding teammates as well.\n","\n","7. **`off_spacing`: 0.018**\n","   - This feature suggests that the spatial distribution of offensive players on the court has a notable impact on the rebounds's outcomes.\n","\n","8. **`boxout_angle_mean`: 0.017**\n","   - The average boxout angle adds weight to the argument that positioning in terms of angles is essential for successful offensive rebounding.\n","\n","9. **`boxout_angle_2`: 0.013**\n","   - The boxout angle of the second-best positioned player reinforces the collective importance of player positioning during boxouts.\n","\n","10. **`num_def_closer_than_second_closest_off`: 0.013**\n","    - This feature highlights the relevance of how many defenders are closer to the hoop than the second closest offensive player, indicating a team strategy impact.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["# **Stacking Classifier for Model Ensembling**\n","\n","When building machine learning models, one popular strategy to enhance the prediction performance is by combining multiple models, a technique commonly known as **ensembling**. One advanced ensembling technique is **stacking**. In this report, we will discuss the choice and implementation of a `StackingClassifier` for a given task.\n","\n","## What is Stacking?\n","\n","Stacking involves using multiple base models (first-level models) to make predictions. These predictions are then used as input features for a second-level model (or meta-model) to make the final predictions. This layered structure allows the model to learn from the strengths of each base model, potentially improving overall performance.\n","\n","## Implementation Details\n","\n","### Base Models:\n","1. *XGBoost Classifier*: A gradient boosting model, it's known for high performance and versatility. It's often a go-to algorithm for structured data tasks. The provided parameters include a learning rate of 0.1, max depth of 2, and an evaluation metric of log loss.\n","\n","    ```python\n","    XGBClassifier(learning_rate=0.065, n_estimators=112, objective='binary:logistic', \n","                  eval_metric='logloss', max_depth=3, min_child_weight=5)\n","    ```\n","   \n","2. *Logistic Regression*: A fundamental algorithm suitable for binary classification tasks. It's parametric and provides probabilities which can be crucial for tasks requiring understanding of uncertainty. The l1 penalty serves as feature selection to address the high dimensionality of our dataset.\n","   \n","    ```python\n","    LogisticRegression(penalty='l1', solver='saga', C=.05, max_iter=500)\n","    ```\n","\n","3. *Random Forest Classifier*: An ensemble method itself, built on decision trees. It offers high accuracy and can work on large data without overfitting.\n","\n","    ```python\n","    RandomForestClassifier(max_depth=8, max_features='auto', min_samples_leaf= 6, min_samples_split=15, n_estimators=200)\n","    ```\n","\n","### Meta-model:\n","\n","- *Logistic Regression*: It is used as a final estimator in our stacked model. Given that the outputs of our base models are probabilities (since we set `stack_method` to 'predict_proba'), logistic regression can weigh these probabilities to make the final prediction.\n","\n","    ```python\n","    LogisticRegression(max_iter=500)\n","    ```\n","\n","### Evaluation:\n","\n","- *Stratified K-Fold Cross-Validation*: A variant of K-Fold CV, it ensures that each fold has the same proportion of observations with a given label. It's especially useful when dealing with imbalanced datasets.\n","\n","    ```python\n","    StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","    ```\n","\n","- *Log Loss*: This metric is chosen because it takes into account the probability scores of classifications, which can provide a more nuanced understanding of model performance, especially in cases where understanding model uncertainty is crucial.\n","\n","### Results:\n","\n","The average log loss from the 5-fold cross-validation of our stacking model can be computed as:\n","\n","```python\n","average_log_loss = -np.mean(scores)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T22:09:07.603544Z","iopub.status.busy":"2023-09-01T22:09:07.602983Z","iopub.status.idle":"2023-09-01T22:09:07.614737Z","shell.execute_reply":"2023-09-01T22:09:07.613167Z","shell.execute_reply.started":"2023-09-01T22:09:07.603491Z"},"trusted":true},"outputs":[],"source":["if RUN_CELL:\n","    # Define base models\n","    estimators = [\n","        ('xgb', xgb.XGBClassifier(learning_rate=0.065, n_estimators=112, objective='binary:logistic', \n","                              eval_metric='logloss', max_depth=3, min_child_weight=5)),\n","        ('logistic', LogisticRegression(penalty='l1', solver='saga', C=.05, max_iter=500)),\n","        ('rfc8', RandomForestClassifier(max_depth=8, max_features='auto', min_samples_leaf= 6, min_samples_split=15, n_estimators=200))\n","    ]\n","\n","    # Build stacking classifier\n","    stacked_model = StackingClassifier(estimators=estimators, \n","                                       final_estimator=LogisticRegression(max_iter=500), \n","                                       stack_method='predict_proba')\n","\n","    # Use StratifiedKFold cross-validation\n","    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","    # Score model using log loss\n","    scores = cross_val_score(stacked_model, X_3, y, cv=kf, scoring=make_scorer(log_loss, greater_is_better=False, needs_proba=True))\n","\n","    average_log_loss = -np.mean(scores)\n","\n","    print(\"Average Log Loss from CV:\", average_log_loss)"]},{"cell_type":"markdown","metadata":{},"source":["#### Assessing StackingClassifier Performance\n","- The mean log loss of `.5781` is the same as the best mean log loss achieved by the best XGBoost model to date\n","- Potential future experimentation: using additional models to increase model diversity may improve the ensemble's performance."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T22:16:03.656560Z","iopub.status.busy":"2023-09-01T22:16:03.656165Z","iopub.status.idle":"2023-09-01T22:16:03.664999Z","shell.execute_reply":"2023-09-01T22:16:03.663550Z","shell.execute_reply.started":"2023-09-01T22:16:03.656533Z"},"trusted":true},"outputs":[],"source":["# Define base models\n","estimators = [\n","    ('xgb', xgb.XGBClassifier(learning_rate=0.065, n_estimators=112, objective='binary:logistic', \n","                          eval_metric='logloss', max_depth=3, min_child_weight=5)),\n","    ('logistic', LogisticRegression(penalty='l1', solver='saga', C=.05, max_iter=500)),\n","    ('rfc8', RandomForestClassifier(max_depth=8, max_features='auto', min_samples_leaf= 6, min_samples_split=15, n_estimators=200))\n","]\n","\n","# Build stacking classifier\n","stacked_model = StackingClassifier(estimators=estimators, \n","                                   final_estimator=LogisticRegression(max_iter=500), \n","                                   stack_method='predict_proba')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T22:17:33.869994Z","iopub.status.busy":"2023-09-01T22:17:33.869387Z","iopub.status.idle":"2023-09-01T22:27:28.493739Z","shell.execute_reply":"2023-09-01T22:27:28.490534Z","shell.execute_reply.started":"2023-09-01T22:17:33.869948Z"},"trusted":true},"outputs":[],"source":["stacked_model.fit(X_3, y)\n","y_pred = stacked_model.predict_proba(X_3_holdout)[:, 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-01T22:27:28.495984Z","iopub.status.idle":"2023-09-01T22:27:28.496795Z","shell.execute_reply":"2023-09-01T22:27:28.496535Z","shell.execute_reply.started":"2023-09-01T22:27:28.496509Z"},"trusted":true},"outputs":[],"source":["create_submission(holdout_ids, y_pred, '')"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["# **Feature Selection with Baruta Algorithm**\n","\n","The Boruta algorithm is an all-relevant feature selection method, meaning it aims to find, within a dataset, all features carrying information usable for prediction, rather than just the irreducible minimum. Here's a breakdown of how it operates and why it's significant:\n","\n","1. *Random Shadow Features Creation:* Boruta works by first duplicating the dataset, then shuffling the values in each feature. These shuffled features are termed \"shadow\" features. \n","\n","2. *Model Importance Calculation:* A model is trained on the dataset with the added shadow features. After training, feature importances are derived. Typically, tree-based models like Random Forest or XGBoost (as in our case) are employed due to their inherent ability to provide feature importance scores.\n","\n","3. *Feature Ranking:* Boruta compares the importance of real features with the highest importance among shadow features. Features deemed more important than the top shadow feature are tagged as relevant.\n","\n","4. *Iterative Selection:* This process is iteratively performed, where after each iteration, features deemed unimportant are removed, and shadow features are regenerated for the next cycle. This is done until all features in the dataset are either confirmed or rejected, or a predefined limit of iterations is reached.\n","\n","5. *Significance:* By leveraging the Boruta algorithm, we can robustly determine which features in our dataset are truly meaningful for our predictive task, thereby enhancing model interpretability and potentially improving generalization performance.\n","\n","Below, we'll be integrating the Boruta feature selection process with our XGBoost classifier to streamline our feature set for optimal predictive performance.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T22:09:53.238057Z","iopub.status.busy":"2023-09-01T22:09:53.237151Z","iopub.status.idle":"2023-09-01T22:09:53.248527Z","shell.execute_reply":"2023-09-01T22:09:53.246203Z","shell.execute_reply.started":"2023-09-01T22:09:53.238011Z"},"trusted":true},"outputs":[],"source":["if RUN_CELL:\n","    #Define the XGBoost model\n","    model = xgb.XGBClassifier(learning_rate=0.1, n_estimators=100, objective='binary:logistic', \n","                              eval_metric='logloss', max_depth=3, min_child_weight=3)\n","    np.bool = bool\n","    np.int = int\n","    np.float = float\n","    # Convert X and y to numpy arrays\n","    X_np = np.array(X_3)\n","    y_np = np.array(y).ravel()  # Boruta prefers the targets as a 1D array.\n","\n","    # Initialize Boruta\n","    boruta_selector = BorutaPy(model, n_estimators='auto', verbose=0, random_state=42)\n","\n","    # Fit Boruta\n","    boruta_selector.fit(X_np, y_np)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T22:10:06.128770Z","iopub.status.busy":"2023-09-01T22:10:06.128161Z","iopub.status.idle":"2023-09-01T22:10:06.135018Z","shell.execute_reply":"2023-09-01T22:10:06.133990Z","shell.execute_reply.started":"2023-09-01T22:10:06.128736Z"},"trusted":true},"outputs":[],"source":["if RUN_CELL:\n","    # Check selected features\n","    selected_features = X_3.columns[boruta_selector.support_]\n","    print('Selected Features:')\n","    print(selected_features)\n","\n","    # Optionally, you can also get features that Boruta is unsure about\n","    tentative_features = X_3.columns[boruta_selector.support_weak_]\n","    print('\\nTentative (Unsure) Features:')\n","    print(tentative_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T22:10:23.971171Z","iopub.status.busy":"2023-09-01T22:10:23.970767Z","iopub.status.idle":"2023-09-01T22:10:23.978037Z","shell.execute_reply":"2023-09-01T22:10:23.976995Z","shell.execute_reply.started":"2023-09-01T22:10:23.971140Z"},"trusted":true},"outputs":[],"source":["if RUN_CELL:\n","    # Define the XGBoost model with your architecture\n","    model = xgb.XGBClassifier(learning_rate=0.1, n_estimators=100, objective='binary:logistic', \n","                              eval_metric='logloss', max_depth=3, min_child_weight=3)\n","\n","    # Convert X and y to numpy arrays (if they aren't already)\n","    X_np = np.array(X_3[selected_features])\n","    y_np = np.array(y).ravel()  # Boruta prefers the targets as a 1D array.\n","\n","    # Select the important features\n","    X_filtered = X_np.copy()\n","\n","    # Perform cross-validation using the selected features\n","    cross_val_scores = cross_val_score(model, X_filtered, y_np, cv=5, scoring='neg_log_loss')\n","\n","    # Convert negative log loss values to positive log loss\n","    log_loss_scores = -cross_val_scores\n","\n","    # Print the average log loss across all folds\n","    print('Average Log Loss after Boruta feature selection:', log_loss_scores.mean())\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Assessing Model Performance after Feature Selection\n","- The model with only the important features selected achieves a log loss of `.5806` which is not an improvement over the previous best XGB model.\n","- Moving forward the model without feature selection using the Stacking Classifier remains our best predictor."]},{"cell_type":"markdown","metadata":{},"source":["# **Oversampling Offensive Rebound Examples**\n","\n","#### Handling Class Imbalance with SMOTE and XGBoost\n","\n","Given the nature of our dataset, where defensive rebounds significantly outnumber offensive rebounds (our target variable), we need to adopt strategies to mitigate this class imbalance. Imbalanced datasets can often lead to biased models, as they tend to predict the majority class more frequently.\n","\n","To address this, we'll implement the following methodology:\n","\n","1. *Model Selection:* We're utilizing the XGBoost classifier.\n","\n","2. *Cross-Validation Scheme:* We employ StratifiedKFold cross-validation, ensuring each fold retains the same percentage of samples for each class as the entire dataset. This is particularly crucial when dealing with imbalanced data.\n","\n","3. *Oversampling with SMOTE:* The Synthetic Minority Over-sampling Technique (SMOTE) is an oversampling approach. Instead of replicating the minority samples, SMOTE generates synthetic examples. It operates by selecting two or more similar instances and perturbing an instance one attribute at a time by a random amount within the difference of the instances. We apply SMOTE only to the training data to prevent data leakage.\n","\n","4. *Evaluation Metric:* Log loss is chosen as the evaluation metric. It provides a robust measure for classification problems, particularly in scenarios where probabilities of class memberships are of interest.\n","\n","Let's now dive into the implementation and evaluate our approach's effectiveness."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T22:10:36.038176Z","iopub.status.busy":"2023-09-01T22:10:36.037556Z","iopub.status.idle":"2023-09-01T22:10:36.050807Z","shell.execute_reply":"2023-09-01T22:10:36.048508Z","shell.execute_reply.started":"2023-09-01T22:10:36.038131Z"},"trusted":true},"outputs":[],"source":["if RUN_CELL:\n","    # Create the XGBoost model\n","    model = xgb.XGBClassifier(learning_rate=0.1, n_estimators=100, objective='binary:logistic', \n","                              eval_metric='logloss', max_depth=3, min_child_weight=5)\n","\n","    # Splitting and cross-validation settings\n","    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","    smote = SMOTE(random_state=42)\n","    log_loss_scores = []\n","\n","    # Performing cross-validation and oversampling within each fold\n","    for train_idx, test_idx in cv.split(X_3, y):\n","        X_train, X_test = X_3.iloc[train_idx], X_3.iloc[test_idx]\n","        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n","\n","        # Apply SMOTE to the training data only\n","        X_res, y_res = smote.fit_resample(X_train, y_train)\n","\n","        model.fit(X_res, y_res)\n","        predictions = model.predict_proba(X_test)[:, 1]  # probabilities of the positive class\n","        score = log_loss(y_test, predictions)\n","        log_loss_scores.append(score)\n","\n","    # Convert the list of log loss scores to a numpy array\n","    log_loss_scores = np.array(log_loss_scores)\n","\n","    # Print the average log loss across all folds\n","    print('Average Log Loss:', log_loss_scores.mean())\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Evaluating the Results Post-Oversampling\n","\n","Upon implementing the Synthetic Minority Over-sampling Technique (SMOTE) to address class imbalance, our anticipated improvement in model performance did not materialize as expected. Let's take a closer look at the observed results:\n","\n","- *Pre-Oversampling Log Loss:* `.5788`\n","- *Post-Oversampling Log Loss:* `.5966`\n","\n","From the above results, it's evident that the log loss has deteriorated post-oversampling, implying a reduction in the model's predictive accuracy.\n","\n","#### Potential Explanation:\n","\n","*Inherent Data Distribution:* The original dataset captures the real-world distribution of offensive and defensive rebounds. This natural distribution inherently makes the model more conservative about predicting offensive rebounds given their rarity. When we use SMOTE, we might be inadvertently nudging the model away from this real-world distribution, causing it to be less discerning in its predictions.\n","\n","In conclusion, while oversampling is a powerful tool, it's not a guaranteed solution for all imbalanced datasets.\n"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["The code from here down represents my attempt at using CNNs and GNNs. The models developed from here forward were not used in the competition. The promising results using tabular data led me to spend less time experimenting with these deep neural nets, but I figured I would include my preprocessing steps and thought process. [Skip to Conclusion](#Conclusion)"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"d_iqoBwvDgX1"},"source":["# **Convolutional Neural Network (CNN) for Spatial Analysis**\n","\n","In analyzing basketball plays, understanding the spatial configurations of players on the court is pivotal. Positioning, in relation to both teammates and the ball, sheds light on the dynamics of the game. Hence, traditional tabular data might miss out on the essence of these spatial intricacies. Let's explore a method that's tailored for this spatial context.\n","\n","## Convolutional Neural Networks (CNN)\n","\n","CNNs have a remarkable track record for processing and interpreting visual data. At its heart, the magic of CNNs lies in its convolutional layers that deftly scan local spatial patterns. In the context of basketball, think of these patterns as arrangements on the court, making CNNs a fitting choice for our analysis.\n","\n","Our objective in this section is to utilize CNNs for gleaning insights and predicting outcomes based on players' spatial configurations during plays.\n","\n","## Data Preprocessing\n","\n","For an effective CNN analysis, our data needs to mirror the spatial nature of the game. This means representing basketball courts as high-res grids, each with channels focusing on specific game aspects:\n","\n","- *Shooter Channel*: Pinpoints the player making the shot.\n","- *Offense Channel*: Charts the positions of players on the offense.\n","- *Defense Channel*: Captures the defensive player positions.\n","- *Hoop Channel*:    Places the hoop on a grid.\n","\n","### Steps:\n","1. **Creating the Court Grid**: The `create_court_grid` function lets us showcase the basketball court in heightened resolutions, say inches. This is like having a blank slate to sketch our plays.\n","2. **Placing Player Positions**: Using `place_player_positions`, we sketch the player outlines on our slate. This categorization divides players as the shooter, on the offense, or the defense, segregating this info across distinct channels.\n","\n","This preprocessing sequence transforms our traditional play-by-play data, making it ready for CNN interpretations.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NNISVVNdVpsg"},"outputs":[],"source":["def create_court_grid(court_width, court_height):\n","    '''\n","    Create an empty court grid with higher resolution and multiple channels for each play.\n","\n","    Parameters\n","    ----------\n","    court_width : int\n","        The width of the court grid in the desired higher resolution. For example, the width in inches or feet.\n","\n","    court_height : int\n","        The height of the court grid in the desired higher resolution. For example, the height in inches or feet.\n","\n","    Returns\n","    -------\n","    numpy.ndarray\n","        A 3D NumPy array representing the court grid with high resolution and three channels.\n","        The dimensions of the array are (court_height, court_width, 3),\n","        where the three channels represent shooter, offense, and defense.\n","\n","    Example\n","    --------\n","    >>> court_width_inches = 500\n","    >>> court_height_inches = 940\n","    >>> grid = create_court_grid(court_width_inches, court_height_inches)\n","    >>> print(grid.shape)\n","    (940, 500, 3)\n","    '''\n","    return np.zeros((court_height, court_width, 4))\n","\n","\n","\n","def place_player_positions(court_grid, player_positions, shooter_index, offense_indices, defense_indices, coordinate_multiplier, court_width, court_height):\n","    '''\n","    Place player positions on the court grid with higher resolution and channels for shooter, offense, and defense.\n","\n","    Parameters\n","    ----------\n","    court_grid : numpy.ndarray\n","        A 3D NumPy array representing the court grid with higher resolution and three channels.\n","        The array has dimensions (court_height_inches, court_width_inches, 3), where the three channels\n","        represent shooter, offense, and defense.\n","\n","    player_positions : numpy.ndarray\n","        A 2D NumPy array containing the X and Y coordinates of the player positions.\n","\n","    shooter_index : int\n","        The index of the shooter in the player_positions array.\n","\n","    offense_indices : list\n","        A list of indices representing the players on offense in the player_positions array.\n","\n","    defense_indices : list\n","        A list of indices representing the players on defense in the player_positions array.\n","\n","    coordinate_multiplier : float\n","        The multiplier to convert the player positions from feet to the desired higher resolution (e.g., inches).\n","\n","    Returns\n","    -------\n","    None\n","        This function modifies the court_grid in place, updating the shooter, offense, and defense channels\n","        based on the player_positions and corresponding indices.\n","    '''\n","    for i, (x, y) in enumerate(player_positions):\n","        x_dist = x * coordinate_multiplier\n","        y_dist = y * coordinate_multiplier\n","        if 0 <= x_dist < court_width and 0 <= y_dist < court_height:\n","            # finding the index of the shooter\n","            if i == np.argmax(shooter_index):\n","                court_grid[int(y_dist)][int(x_dist)][0] = 1  # Shooter channel\n","            # finding the indices of offensive players and comparing to the index\n","            if i in np.where(offense_indices == 1)[0]:\n","                court_grid[int(y_dist)][int(x_dist)][1] = 1  # Offense channel\n","            if i in np.where(defense_indices == 1)[0]:\n","                court_grid[int(y_dist)][int(x_dist)][2] = 1  # Defense channel\n","    return court_grid"]},{"cell_type":"markdown","metadata":{},"source":["#### Resolution Choice\n","- Due to runtime and memory concerns, we will use square foot granularity\n","- With access to more resources, inches might be a more optimal granularity\n","- Higher resolution, however, likely would not significantly improve performance because the square foot a player in is a fairly precise representation of their court position"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UkA81-iyVpsh"},"outputs":[],"source":["# define the dimensions of the court grid with medium resolution\n","# depending on runtime, using lower resolution images may be a better approach here, but let's start with feet\n","\n","coordinate_multiplier = 1\n","court_width = 94 * coordinate_multiplier\n","court_height = 50 * coordinate_multiplier\n","\n","# derive parameters from the data table\n","player_positions_train = training_data[['court_x', 'court_y']].values\n","shooter_indices_train = training_data['shooter'].values\n","offense_indices_train = training_data['offense'].values\n","defense_indices_train = training_data['offense'].apply(lambda x: 0 if x == 1 else 1).values # Complement of 'offense' column gives 'defense' indices\n","which_hoop_train = training_data['which_hoop'].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# derive parameters from the data table\n","player_positions_test = testing_data[['court_x', 'court_y']].values\n","shooter_indices_test = testing_data['shooter'].values\n","offense_indices_test = testing_data['offense'].values\n","defense_indices_test = testing_data['offense'].apply(lambda x: 0 if x == 1 else 1).values # Complement of 'offense' column gives 'defense' indices\n","which_hoop_test = testing_data['which_hoop'].values"]},{"cell_type":"markdown","metadata":{},"source":["#### Building Images"]},{"cell_type":"markdown","metadata":{},"source":["These cells will take 10+ minutes to run. npz files are provided for convenience."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UDpRGqMtBgzX"},"outputs":[],"source":["# # create image-like training examples with higher resolution and multiple channels\n","# X_train_images = []\n","# # reshaping organizes the positions into a list of list of coordinates, so there is one training example per play\n","# for index, (player_positions, shooter_index, offense_indices, defense_indices, which_hoop_indices) in enumerate(zip(player_positions_train.reshape(-1, 10, 2), shooter_indices_train.reshape(-1, 10), offense_indices_train.reshape(-1, 10), defense_indices_train.reshape(-1, 10), which_hoop_train.reshape(-1, 10))):\n","#     court_grid = create_court_grid(court_width, court_height)\n","#     place_player_positions(court_grid, player_positions, shooter_index, offense_indices, defense_indices, coordinate_multiplier, court_width, court_height)\n","#     which_hoop = which_hoop_indices[0]\n","#     if which_hoop == 0:\n","#         court_grid[25][4][3] = 1 # basketball hoop channel\n","#     else:\n","#         court_grid[25][90][3] = 1\n","#     X_train_images.append(court_grid)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # create image-like training examples with higher resolution and multiple channels\n","# X_test_images = []\n","# # reshaping organizes the positions into a list of list of coordinates, so there is one training example per play\n","# for index, (player_positions, shooter_index, offense_indices, defense_indices, which_hoop_indices) in enumerate(zip(player_positions_test.reshape(-1, 10, 2), shooter_indices_test.reshape(-1, 10), offense_indices_test.reshape(-1, 10), defense_indices_test.reshape(-1, 10), which_hoop_test.reshape(-1, 10))):\n","#     court_grid = create_court_grid(court_width, court_height)\n","#     place_player_positions(court_grid, player_positions, shooter_index, offense_indices, defense_indices, coordinate_multiplier, court_width, court_height)\n","#     which_hoop = which_hoop_indices[0]\n","#     if which_hoop == 0:\n","#         court_grid[25][4][3] = 1 # basketball hoop channel\n","#     else:\n","#         court_grid[25][90][3] = 1\n","#     X_test_images.append(court_grid)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uePOCtR7L4mw"},"outputs":[],"source":["# # Define the file path for saving the data\n","# save_path = 'X_train_images_with_hoop.npz'\n","\n","# # Save the data to the file\n","# np.savez_compressed(save_path, X_train_images=X_train_images)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Define the file path for saving the data\n","# save_path = 'X_test_images_with_hoop.npz'\n","\n","# # Save the data to the file\n","# np.savez_compressed(save_path, X_test_images=X_test_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:02:58.714590Z","iopub.status.busy":"2023-09-01T20:02:58.714138Z","iopub.status.idle":"2023-09-01T20:03:12.496147Z","shell.execute_reply":"2023-09-01T20:03:12.495124Z","shell.execute_reply.started":"2023-09-01T20:02:58.714563Z"},"id":"MI2llzEZQ2UT","trusted":true},"outputs":[],"source":["# Load the data from the file\n","save_path = '/data/X_train_images_with_hoop.npz'\n","loaded_data = np.load(save_path)\n","X_train_images = loaded_data['X_train_images']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:03:12.498489Z","iopub.status.busy":"2023-09-01T20:03:12.497832Z","iopub.status.idle":"2023-09-01T20:03:18.413861Z","shell.execute_reply":"2023-09-01T20:03:18.411468Z","shell.execute_reply.started":"2023-09-01T20:03:12.498463Z"},"trusted":true},"outputs":[],"source":["# Load the data from the file\n","save_path = '/data/X_test_images_with_hoop.npz'\n","loaded_data = np.load(save_path)\n","X_test_images = loaded_data['X_test_images']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T20:03:18.416808Z","iopub.status.busy":"2023-09-01T20:03:18.416290Z","iopub.status.idle":"2023-09-01T20:03:20.351158Z","shell.execute_reply":"2023-09-01T20:03:20.348984Z","shell.execute_reply.started":"2023-09-01T20:03:18.416765Z"},"id":"hok-0OToj6r0","trusted":true},"outputs":[],"source":["# converting DataFrames to NumPy arrays\n","X_train_images = np.array(X_train_images)\n","X_test_images = np.array(X_test_images)"]},{"cell_type":"markdown","metadata":{},"source":["#### Image Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"guTqLOsVaPgX","outputId":"1e14c3cb-0d21-433c-813d-fa3d5df722fe"},"outputs":[],"source":["sample_index = 1\n","# visualize the shooter channel\n","plt.imshow(X_train_images[sample_index, :, :, 0], cmap='gray')\n","plt.title('Shooter Channel')\n","plt.show()\n","\n","# visualize the offense channel\n","plt.imshow(X_train_images[sample_index, :, :, 1], cmap='gray')\n","plt.title('Offense Channel')\n","plt.show()\n","\n","# visualize the defense channel\n","plt.imshow(X_train_images[sample_index, :, :, 2], cmap='gray')\n","plt.title('Defense Channel')\n","plt.show()\n","\n","# visualize the basketball hoop channel\n","plt.imshow(X_train_images[sample_index, :, :, 3], cmap='gray')\n","plt.title('Hoop Channel')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["The example above illustrates what the different channel images look like for a single play."]},{"cell_type":"markdown","metadata":{},"source":["## **CNN Model**\n","\n","### Model Architecture:\n","- *Convolutional Layers*: The model starts with 32 filters of size 3x3, which should capture basic spatial features. We then double the number of filters to 64 in the next layer, enabling the model to detect more complex patterns and relationships.\n","- *Pooling Layers*: MaxPooling layers of size 2x2 are used to reduce spatial dimensions, focusing on the most important features and aiding computational efficiency.\n","- *Regularization*: L2 regularization is applied in the dense layer to mitigate the potential for overfitting, penalizing large weight values that might make the model overly specific to the training data.\n","- *Output Layer*: A single neuron with a sigmoid activation function is used for our binary classification task, predicting whether a play will result in an offensive rebound or not.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T23:05:07.326629Z","iopub.status.busy":"2023-09-01T23:05:07.321183Z","iopub.status.idle":"2023-09-01T23:05:07.352867Z","shell.execute_reply":"2023-09-01T23:05:07.349883Z","shell.execute_reply.started":"2023-09-01T23:05:07.326477Z"},"trusted":true},"outputs":[],"source":["# Split the data into training and validation sets\n","if RUN_CELL:\n","    X_train, X_val, y_train, y_val = train_test_split(X_train_images, train_pbp['is_oreb'], test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T22:11:05.862333Z","iopub.status.busy":"2023-09-01T22:11:05.861295Z","iopub.status.idle":"2023-09-01T22:11:05.877775Z","shell.execute_reply":"2023-09-01T22:11:05.874619Z","shell.execute_reply.started":"2023-09-01T22:11:05.862297Z"},"id":"iEoPk2HDlG1E","outputId":"0516dded-0d20-459d-e73f-cdb3eba7b2c1","trusted":true},"outputs":[],"source":["if RUN_CELL:   \n","    # define the CNN model\n","    model = models.Sequential()\n","    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 94, 4)))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(.01)))\n","    model.add(layers.Dense(1, activation='sigmoid'))  # sigmoid activation for binary classification\n","\n","    # compile the model with log loss (binary cross-entropy)\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    # train the model\n","    batch_size = 32\n","    epochs = 10\n","\n","    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))\n","\n","    # evaluate the model\n","    loss, accuracy = model.evaluate(X_val, y_val)\n","    print(f'Validation Loss (Log Loss): {loss:.4f}, Validation Accuracy: {accuracy:.4f}')\n"]},{"cell_type":"markdown","metadata":{},"source":["#### CNN Training Results\n","\n","The Convolutional Neural Network (CNN) model was trained over 10 epochs. The results from each epoch are outlined below:\n","\n","| Epoch | Training Loss | Training Accuracy | Validation Loss | Validation Accuracy |\n","|-------|---------------|-------------------|-----------------|---------------------|\n","| 1     | 0.6178        | 71.76%            | 0.5969          | 71.81%              |\n","| 2     | 0.5953        | 71.81%            | 0.5915          | 71.81%              |\n","| 3     | 0.5918        | 71.81%            | 0.5894          | 71.81%              |\n","| 4     | 0.5900        | 71.81%            | 0.5906          | 71.81%              |\n","| 5     | 0.5893        | 71.81%            | 0.5882          | 71.81%              |\n","| 6     | 0.5886        | 71.81%            | 0.5873          | 71.81%              |\n","| 7     | 0.5881        | 71.81%            | 0.5901          | 71.81%              |\n","| 8     | 0.5878        | 71.81%            | 0.5854          | 71.81%              |\n","| 9     | 0.5881        | 71.81%            | 0.5874          | 71.81%              |\n","| 10    | 0.5873        | 71.81%            | 0.5866          | 71.81%              |\n","\n","Upon final evaluation after the 10th epoch, the model achieved:\n","- **Validation Loss (Log Loss)**: 0.5866\n","- **Validation Accuracy**: 71.81%\n","\n","#### Future Steps\n","\n","1. *Further Experimentation with Complexity and Architecture*:\n","    - My approach to this point has been to continuously readjust the architecture.\n","    - The current architecture might be too simplistic for the complexity of the task (it does not overfit).\n","    - **Potential Experiment**: Introduce more convolutional layers, experiment with different filter sizes, or consider deeper architectures. Dropout layers could also be introduced to reduce overfitting.\n","\n","2. *Further Hyperparameter Tuning*:\n","    - My approach to this point has been to iteratively adjust the hyperparameters to avoid overfitting and minimize validation loss.\n","    - Fine-tuning the model's hyperparameters could yield improvements in performance.\n","    - **Potential Experiment**: Utilize grid search or random search strategies with tools like Keras Tuner or Scikit-learn's GridSearchCV for exhaustive searches. Bayesian optimization libraries like Optuna may also be useful.\n","\n","3. *Data Augmentation through Image Rotation*:\n","    - One common bottleneck in training deep learning models, especially CNNs, is the lack of sufficient training data.\n","    - Data augmentation is a well-established technique to artificially increase the size of the training dataset. By applying minor transformations to the input images, we can create \"new\" training examples without actually collecting new data.\n","    - **Potential Experiment**: Implement image rotation as a form of augmentation. Rotating the images by various degrees can provide different perspectives and increase the robustness of the model.\n","\n","These future steps would be more realistic with more compute power, as hyperparameter searches can take hours on end."]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["# **Graph Neural Networks (GNNs) for Spatial Analysis**\n","\n","Graph Neural Networks (GNNs) provide an alternative paradigm to traditional deep learning techniques by focusing on graph-structured data. In the context of basketball plays, players can be represented as nodes, and their relationships as edges. GNNs can help exploit the intricate inter-player interactions and relationships present on the court. The presented code offers an insight into the usage of GNNs for this problem. Below are some highlights and rationale behind the choices made:\n","\n","### Data Preprocessing:\n","1. *Normalization*: All coordinates (both for the court and the hoop) are normalized to ensure consistent scaling, which aids in convergence and model training. This is crucial when computing distances and relationships.\n","2. *Data Construction*: Each play is transformed into a graph representation. The attributes like 'offense', 'shooter', 'which_hoop', etc., serve as node features. The pairwise Euclidean distances between players help form the adjacency matrix, highlighting player-player spatial relationships.\n","\n","### GNN Model Architecture:\n","1. *Graph Attention (GAT)*: The model employs Graph Attention Layers (GATConv from PyTorch Geometric) that allow nodes to focus on their more influential neighbors, thus capturing intricate local and global patterns.\n","2. *Pooling Layer*: A Set2Set layer acts as a pooling mechanism. It aggregates node features to generate a graph-level representation, making it suitable for graph classification tasks.\n","3. *Output Layer*: A single output neuron is employed since this is a binary classification task. The model's goal is to predict if a play will result in an offensive rebound.\n","\n","### Training & Testing:\n","- *Adam Optimizer*: A popular optimization technique for deep learning tasks, ensuring efficient and effective convergence.\n","- *Model Evaluation*: The model's performance is monitored using the loss computed on both training and test datasets. By observing these values over epochs, we can see the model's progression in learning the underlying patterns.\n","\n","### Insights:\n","1. *Graphs in Sports Analytics*: Employing GNNs in sports analytics, as shown, can offer unique insights that might be missed by traditional models. By treating players as interconnected nodes, we can capture strategies, formations, and patterns that emerge during plays.\n","2. *Flexibility & Expansion*: While the provided architecture offers a starting point, GNNs are flexible. Adding more layers, varying attention mechanisms, or incorporating other node/edge features can further improve performance and insights.\n","\n","In conclusion, this application of GNNs can revolutionize how we analyze and understand basketball plays, shedding light on patterns and strategies beyond raw stats.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["graph_training = training_data.copy()\n","graph_testing = testing_data.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["graph_training['hoop_x'] = graph_training['which_hoop'].apply(lambda x: 90 if x == 1 else 4)\n","graph_training['hoop_y'] = 25\n","graph_testing['hoop_x'] = graph_testing['which_hoop'].apply(lambda x: 90 if x == 1 else 4)\n","graph_testing['hoop_y'] = 25\n","graph_training = graph_training.merge(train_pbp[['id', 'is_oreb']], on='id', how='left')"]},{"cell_type":"markdown","metadata":{},"source":["#### **Scaling the Data**\n","- Once again, we fit the scaler on the training data and transform the test.\n","- We use a MinMaxScaler because we are working with coordinate data.\n","- We only fit on the player coordinates, so that the hoop remains in its relative position to the players after scaling."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["graph_scaler = MinMaxScaler()\n","normalized_coords = pd.DataFrame()\n","normalized_coords_test = pd.DataFrame()\n","\n","normalized_coords[['court_x', 'court_y']] = graph_scaler.fit_transform(graph_training[['court_x', 'court_y']].values)\n","normalized_coords[['hoop_x', 'hoop_y']] = graph_scaler.transform(graph_training[['hoop_x', 'hoop_y']])\n","normalized_coords_test[['court_x', 'court_y']] = graph_scaler.transform(graph_testing[['court_x', 'court_y']])\n","normalized_coords_test[['hoop_x', 'hoop_y']] = graph_scaler.transform(graph_testing[['hoop_x', 'hoop_y']])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["graph_training[['court_x', 'court_y', 'hoop_x', 'hoop_y']] = normalized_coords\n","graph_testing[['court_x', 'court_y', 'hoop_x', 'hoop_y']] = normalized_coords_test"]},{"cell_type":"markdown","metadata":{},"source":["#### **Compiling the Graph**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["graph_training['hoop'] = 0"]},{"cell_type":"markdown","metadata":{},"source":["This cell will takes 10+ minutes to run. The code from here down is not used in submissions."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"source":[" if RUN_CELL:   \n","    plays = graph_training['id'].unique()\n","    data_list = []\n","\n","    for play in plays:\n","        play_df = graph_training[graph_training['id'] == play]\n","\n","        # Add hoop as a node\n","        hoop_node = {'court_x': play_df['hoop_x'].iloc[0], 'court_y': play_df['hoop_y'].iloc[0], 'offense': 0, 'shooter': 0, 'hoop': 1}\n","        play_df = play_df.append(hoop_node, ignore_index=True)\n","\n","        x = torch.tensor(play_df[['court_x', 'court_y', 'offense', 'shooter', 'hoop']].values, dtype=torch.float)\n","        y = torch.tensor([play_df['is_oreb'].values[0]], dtype=torch.float)\n","\n","        # Calculate pairwise Euclidean distances including the hoop\n","        distances = squareform(pdist(play_df[['court_x', 'court_y']].values))\n","\n","        # Take inverse of distances for non-zero entries\n","        with np.errstate(divide='ignore'):  # Ignore divide by zero warning, will handle inf values next\n","            inv_distances = 1.0 / distances\n","        inv_distances[inv_distances == np.inf] = 0  # Set diagonal (infinite values) to 0\n","\n","        # Form the edge_index and edge_weight tensors\n","        edge_index = torch.tensor(np.where(inv_distances), dtype=torch.long)\n","        edge_weights = torch.tensor(inv_distances[edge_index[0], edge_index[1]], dtype=torch.float)\n","\n","        data = Data(x=x, edge_index=edge_index, edge_attr=edge_weights, y=y)\n","        data_list.append(data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if RUN_CELL:  \n","    # Split data into train and test\n","    train_data_list, test_data_list = train_test_split(data_list, test_size=0.2, random_state=42)\n","    train_loader = DataLoader(train_data_list, batch_size=32, shuffle=True)\n","    test_loader = DataLoader(test_data_list, batch_size=32)"]},{"cell_type":"markdown","metadata":{},"source":["#### Defining the Architecture"]},{"cell_type":"markdown","metadata":{},"source":["The torch-scatter library would not cooperate with Kaggle, so the architecture will not run in Kaggle."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if RUN_CELL:\n","    class AttentivePooling(torch.nn.Module):\n","        def __init__(self, in_dim, global_context_dim):\n","            super(AttentivePooling, self).__init__()\n","            \n","            self.global_context = torch.nn.Linear(in_dim, global_context_dim)\n","            # print(\"Global context layer weights:\", self.global_context.weight.shape)\n","\n","            self.attention_weights = torch.nn.Linear(global_context_dim + in_dim, 1)\n","            # print(\"Attention weights layer shape:\", self.attention_weights.weight.shape)\n","\n","\n","        def forward(self, x, batch):\n","            # Compute the global context\n","            gc = scatter_mean(x, batch, dim=0)\n","            # print(\"Mean features per graph:\", gc.shape)\n","            # print(\"Contents of gc:\", gc[:5])\n","\n","\n","            #print(\"Global context per graph:\", gc)\n","            gc = torch.tanh(self.global_context(gc))\n","            # print(\"Transformed global context:\", gc.shape)\n","            # print(\"Contents of gc after activation:\", gc[:5])\n","\n","                \n","            # Broadcast the global context to every node in the batch\n","            gc_broadcasted = gc[batch]\n","            # print(\"Broadcasted global context:\", gc_broadcasted.shape)\n","            # print(\"Contents of gc_broadcast:\", gc_broadcasted[:5])\n","                \n","            # Concatenate the global context with node features\n","            concat = torch.cat([x, gc_broadcasted], dim=1)\n","            # print(\"Concatenated feature shape:\", concat.shape)\n","            # print(\"Contents of concat:\", concat[:5])\n","\n","            # print(self.attention_weights(concat)) \n","            # Compute attention scores\n","            att_scores = torch.nn.functional.softmax(self.attention_weights(concat), dim=1)\n","            # print(\"Shape of attention scores:\", att_scores.shape)\n","            # print(\"Attention scores for each node:\", att_scores[:25])\n","                \n","            # Compute the pooled representation for the entire graph\n","            pooled_representation = scatter_add(att_scores.view(-1, 1) * x, batch, dim=0)\n","            # print(\"Shape of pooled representation\", pooled_representation.shape)\n","            \n","            return pooled_representation\n","\n","\n","    class MyGCNModel(torch.nn.Module):\n","        def __init__(self, input_dim, hidden_dim, global_context_dim, output_dim=1):\n","            super(MyGCNModel, self).__init__()\n","\n","            self.conv1 = GCNConv(input_dim, hidden_dim)\n","            self.conv2 = GCNConv(hidden_dim, hidden_dim)\n","            self.pooling = AttentivePooling(hidden_dim, hidden_dim)\n","            self.fc = torch.nn.Linear(hidden_dim, output_dim)\n","\n","        def forward(self, data):\n","            x, edge_index, batch = data.x, data.edge_index, data.batch\n","            edge_weight = data.edge_attr.squeeze(-1)  # Assuming edge_attr is [num_edges, 1]\n","            \n","            x = F.relu(self.conv1(x, edge_index, edge_weight))\n","            # print(\"Shape of x after first conv:\", x.shape)\n","\n","            x = F.relu(self.conv2(x, edge_index, edge_weight))\n","            # print(\"Shape of x after second conv:\", x.shape)\n","\n","            x = self.pooling(x, batch)\n","            x = self.fc(x)\n","            \n","            return x\n","\n","\n","    class MyGNNModel(torch.nn.Module):\n","        def __init__(self, input_dim, hidden_dim, global_context_dim, output_dim=1):\n","            super(MyGNNModel, self).__init__()\n","\n","            self.conv1 = GATConv(input_dim, hidden_dim)\n","            self.conv2 = GATConv(hidden_dim, hidden_dim)\n","            self.pooling = AttentivePooling(hidden_dim, hidden_dim)\n","            self.fc = torch.nn.Linear(hidden_dim, output_dim)\n","\n","        def forward(self, data):\n","            x, edge_index, batch = data.x, data.edge_index, data.batch\n","            \n","            x = F.relu(self.conv1(x, edge_index))\n","            x = F.relu(self.conv2(x, edge_index))\n","            x = self.pooling(x, batch)\n","            x = self.fc(x)\n","            return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if RUN_CELL:    \n","    input_dim = 5  #court_x, court_y, offense, shooter, hoop\n","    hidden_dim = 6\n","    global_context_dim = 4 \n","\n","    model = MyGCNModel(input_dim=input_dim, hidden_dim=hidden_dim, global_context_dim=global_context_dim)\n","\n","\n","    criterion = BCEWithLogitsLoss()\n","    optimizer = Adam(model.parameters(), lr=0.1)"]},{"cell_type":"markdown","metadata":{},"source":["#### Train and Evaluate the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"source":["if RUN_CELL:\n","    # Train the model\n","    def train(model, loader, criterion, optimizer):\n","        model.train()\n","\n","        total_loss = 0\n","        for data in loader:\n","            # print(data.edge_attr)\n","            optimizer.zero_grad()\n","            out = model(data)\n","            loss = criterion(out.view(-1), data.y.view(-1))\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item() * data.num_graphs\n","\n","        return total_loss / len(loader.dataset)\n","\n","    # Test the model\n","    def test(model, loader):\n","        model.eval()\n","\n","        total_loss = 0\n","        for data in loader:\n","            with torch.no_grad():\n","                out = model(data).view(-1)\n","                loss = criterion(out.view(-1), data.y.view(-1))\n","                total_loss += loss.item() * data.num_graphs\n","                #output = torch.sigmoid(out)\n","        return total_loss / len(loader.dataset)\n","\n","if RUN_CELL:\n","    # Run the training process\n","    for epoch in range(25):\n","        train_loss = train(model, train_loader, criterion, optimizer)\n","        test_loss = test(model, test_loader)\n","        print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Test Loss: {test_loss}')"]},{"cell_type":"markdown","metadata":{},"source":["#### GNN Results and Analysis\n","\n","- *Consistent Test Loss*: Over the epochs, the test loss remained consistent without any significant improvements. Specifically, starting from a loss of `0.5955` in the first epoch, the loss wavered around the `0.595` mark, with no discernible decline.\n","\n","- *Stagnant Training Loss*: The training loss showcased a similar trend, hovering around `0.595` throughout the epochs. This indicates that the GNN struggles to identify patterns in the graph data, and the network's learning is static.\n","\n","- *Uniform Predictions*: A concerning observation is that the GNN produces nearly identical predictions for all graphs. This behavior suggests that the model might be converging to a naive solution, simply predicting the probability that minimizes the log loss when applied uniformly to all examples.\n","\n","#### Future Considerations\n","\n","1. *Model Architecture & Complexity*: The current GNN might be too simplistic or might not be the right fit for the intricacies of the graph data. It's worth revisiting the architecture, experimenting with additional layers, or even considering other graph neural network variants.\n"," \n","2. *Training Strategy*: Since the model seems to converge to a single probability for all graphs, it might be helpful to modify the training regimen. Techniques such as different initialization methods, learning rate schedules, or alternative optimization algorithms could potentially help the model escape this local minimum.\n","\n","3. *Feature Engineering*: Investigate the node and edge features of the graph. There might be an opportunity to improve the model's performance by introducing new features or optimizing the existing ones.\n","\n","Given the observations and challenges faced with the GNN, further experimentation and alternative approaches are recommended to achieve better results.\n"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","# **Conclusion**\n","\n","Throughout this extensive analysis, we have employed a series of advanced methodologies to unravel insights and enhance the predictive capability of our models. Let's reflect on our journey:\n","\n","1. **Exploratory Data Analysis & Data Preprocessing**: The foundation of our work, this stage provided us with invaluable insights about the dataset and guided subsequent stages of modeling.\n","\n","2. **Complex Feature Engineering**: Incorporating features like the boxout position added a layer of depth to our analysis, potentially enabling our models to uncover intricate relationships within the data.\n","\n","3. **Model Experimentation**: Different models showcased diverse strengths and challenges. While the XGBoost model benefited from more compact tree structures, emphasizing the risk of overfitting in our dataset, the Random Forest Classifier favored slightly deeper trees, suggesting underlying complexities in the data.\n","\n","4. **Convolutional Neural Network (CNN) for Spatial Analysis**: A groundbreaking approach for this data, the CNN's potential wasn't fully realized, suggesting that perhaps spatial patterns weren't as defining for our target variable or the model architecture needed further refinement.\n","\n","5. **Graph Neural Networks (GNNs) for Spatial Analysis**: Our foray into GNNs showcased the challenges of adopting novel methods. The model’s inability to learn the graph patterns highlighted the need for more intricate preprocessing or tuning. Yet, it set the foundation for potential future investigations. Spatio-temporal features have been critical to the success of other sports GNNs, so this is worth revisiting with more granular data.\n","\n","6. **Stacking Classifier for Model Ensembling**: A robust technique, this showcased the power of combining models to capitalize on their individual strengths.\n","\n","7. **Feature Selection with the Boruta Algorithm**: By trimming the fat and focusing on impactful features, we saw which features were most helpful in predicting offensive rebounding.\n","\n","8. **Oversampling Offensive Rebound Examples**: Addressing the imbalance in our dataset was not helpful in improving model performance. The use of the SMOTE technique upset the natural distribution of offensive rebounding\n","\n","In summation, this analysis underscores the significance of iterative experimentation in data science. While certain techniques like XGBoost and Random Forest showed promise, others like CNNs and GNNs demand further scrutiny. This project serves as a testament to the fact that, in the realm of data science, both successes and failures pave the way for deeper understanding and innovation.\n","\n","## Key Basketball Strategy Insights\n","- This investigation uncovered the significance of having multiple players near the basket. At every stage of modeling, the positioning of the second best positioned offensive player was more important than the best positioned offensive player's positioning.\n","- Coaches may find this information valuable and do the following:\n","    - Run more plays with someone in the dunker spot.\n","    - Design plays that designate players to crash the boards anticipating when a shot will go up.\n","\n","## Potential Basketball Statistic\n","- `Boxout Position` was among the best features developed and was instrumental in achieving the best model scores in this notebook.\n","- **OFFREB+** could be a valuable statistic that multiplies the offensive player's offensive rebounding rate by a normalizing factor for their average boxout position faced.\n","- This statistic would be invaluable in assessing individual performance against expectation when it comes to offensive rebounding.\n","\n","---\n","$$ \\text{OFFREB+} =  \\text{Offensive Rebounding Rate} \\times \\frac{\\text{Player Boxout Position Average}}{\\text{Global Boxout Position Average}} $$\n","---\n","\n","\n","\n","---\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
